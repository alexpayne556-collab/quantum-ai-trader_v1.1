{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfcef12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CELL 1: SETUP ===\n",
    "!pip install -q yfinance ta\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "from copy import deepcopy\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"üîÆ Forecast Evolution Optimizer Ready\")\n",
    "print(f\"üìÖ {datetime.now().strftime('%Y-%m-%d %H:%M')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be219a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CELL 2: R&D DISCOVERY MODE - FORECASTER EVOLUTION ===\n",
    "# üî¨ EXPERIMENTAL - Let the AI discover new forecasting approaches!\n",
    "\n",
    "EVOLUTION_CONFIG = {\n",
    "    'population_size': 100,     # Big population for diversity\n",
    "    'generations': 60,          # Long exploration\n",
    "    'mutation_rate': 0.5,       # HIGH mutation - try wild ideas!\n",
    "    'crossover_rate': 0.5,      # Balance\n",
    "    'elite_keep': 2,            # Force exploration\n",
    "    'tournament_size': 3,       # More randomness\n",
    "    'restart_every': 12,        # Inject chaos\n",
    "    'wild_card_pct': 0.1,       # 10% random each gen\n",
    "}\n",
    "\n",
    "# === ULTRA-WIDE FORECASTER PARAMETERS ===\n",
    "# Let AI discover optimal indicator combinations and thresholds\n",
    "FORECAST_PARAMS = {\n",
    "    # === INDICATOR WEIGHTS (which indicators matter?) ===\n",
    "    'w_rsi': [0.0, 3.0, 1.0],              # Can go to 3x!\n",
    "    'w_macd': [0.0, 3.0, 1.0],             \n",
    "    'w_ema_trend': [0.0, 3.0, 1.0],        \n",
    "    'w_volume': [0.0, 3.0, 0.5],           \n",
    "    'w_momentum': [0.0, 3.0, 1.0],         \n",
    "    'w_volatility': [0.0, 3.0, 0.5],       \n",
    "    \n",
    "    # NEW: Experimental indicator weights\n",
    "    'w_rsi_divergence': [0.0, 2.0, 0.5],   # RSI divergence signal\n",
    "    'w_consolidation': [0.0, 2.0, 0.5],    # Consolidation breakout\n",
    "    'w_trend_structure': [0.0, 2.0, 0.5],  # Higher highs/lows\n",
    "    \n",
    "    # === RSI THRESHOLDS (explore extremes) ===\n",
    "    'rsi_oversold': [10, 50, 30],          # Maybe 10? Maybe 50?\n",
    "    'rsi_overbought': [50, 95, 70],        \n",
    "    'rsi_neutral_low': [25, 55, 40],       \n",
    "    'rsi_neutral_high': [45, 75, 60],      \n",
    "    \n",
    "    # === CONFIDENCE MECHANICS ===\n",
    "    'base_confidence': [0.3, 0.8, 0.55],   # Starting confidence\n",
    "    'confidence_boost': [0.0, 0.4, 0.15],  # Boost for strong signals\n",
    "    'confidence_decay': [0.7, 0.99, 0.92], # Daily decay\n",
    "    'confidence_floor': [0.2, 0.5, 0.3],   # Minimum confidence\n",
    "    \n",
    "    # === FORECAST DRIFT (price movement expectations) ===\n",
    "    'drift_bull': [0.0005, 0.015, 0.002],  # Daily bullish drift (up to 1.5%!)\n",
    "    'drift_bear': [-0.015, -0.0005, -0.002], # Daily bearish drift\n",
    "    'drift_neutral': [-0.002, 0.002, 0.0], # Neutral drift (can be non-zero!)\n",
    "    'volatility_scale': [0.1, 2.0, 0.5],   # Vol impact\n",
    "    \n",
    "    # === SIGNAL TIMING ===\n",
    "    'decay_start_day': [1, 21, 10],        # When to start decaying\n",
    "    'max_daily_move': [0.02, 0.15, 0.05],  # Max daily move (2-15%)\n",
    "    'forecast_horizon': [3, 14, 7],        # Days to forecast\n",
    "    \n",
    "    # === MULTI-TIMEFRAME ===\n",
    "    'ema_short_period': [3, 21, 8],        # Short EMA\n",
    "    'ema_long_period': [13, 89, 34],       # Long EMA (up to 89!)\n",
    "    'momentum_lookback': [2, 21, 5],       # Momentum calc\n",
    "    'rsi_period': [7, 21, 14],             # RSI period itself!\n",
    "    \n",
    "    # === SIGNAL THRESHOLDS (when to act) ===\n",
    "    'signal_buy_threshold': [0.1, 0.8, 0.5],   # Lower = more buys\n",
    "    'signal_sell_threshold': [-0.8, -0.1, -0.5], # Higher = more sells\n",
    "    'signal_strong_mult': [1.0, 2.0, 1.3],     # Strong signal multiplier\n",
    "    \n",
    "    # === EXPERIMENTAL: ADAPTIVE PARAMETERS ===\n",
    "    'vol_adjustment': [0.5, 2.0, 1.0],     # Adjust for volatility\n",
    "    'trend_confirmation': [0.0, 1.0, 0.5], # Require trend alignment\n",
    "    'mean_reversion_weight': [0.0, 1.0, 0.3], # Mean reversion factor\n",
    "}\n",
    "\n",
    "WATCHLIST = [\n",
    "    # High volatility targets\n",
    "    'IONQ', 'RGTI', 'QUBT', 'SMR', 'OKLO', 'LEU',\n",
    "    # Tech\n",
    "    'NVDA', 'AMD', 'MRVL', 'CRDO', 'MU', 'APLD', 'SERV',\n",
    "    # Momentum\n",
    "    'TSLA', 'META', 'GOOGL', 'HOOD', 'SNOW', 'LUNR',\n",
    "    # Recovery\n",
    "    'RIVN', 'LYFT', 'UUUU', 'CCJ',\n",
    "    # Benchmarks\n",
    "    'SPY', 'QQQ', 'TQQQ'\n",
    "]\n",
    "\n",
    "print(\"üî¨ R&D DISCOVERY MODE - FORECASTER EVOLUTION\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"   Population: {EVOLUTION_CONFIG['population_size']}\")\n",
    "print(f\"   Generations: {EVOLUTION_CONFIG['generations']}\")\n",
    "print(f\"   Mutation Rate: {EVOLUTION_CONFIG['mutation_rate']} (HIGH)\")\n",
    "print(f\"   Parameters: {len(FORECAST_PARAMS)} (many experimental)\")\n",
    "print(f\"   Tickers: {len(WATCHLIST)}\")\n",
    "print(f\"\\nüéØ GOAL: Discover better forecasting methods\")\n",
    "print(f\"   - Which indicators actually predict direction?\")\n",
    "print(f\"   - What RSI thresholds work best?\")\n",
    "print(f\"   - How should confidence decay?\")\n",
    "print(f\"   - Can we find unconventional combinations?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79814101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CELL 3: LOAD DATA ===\n",
    "print(\"üì• Loading data...\")\n",
    "\n",
    "data_dict = {}\n",
    "for ticker in WATCHLIST:\n",
    "    try:\n",
    "        df = yf.download(ticker, period='2y', progress=False)\n",
    "        if isinstance(df.columns, pd.MultiIndex):\n",
    "            df.columns = df.columns.get_level_values(0)\n",
    "        df = df.reset_index()\n",
    "        for col in ['Open', 'High', 'Low', 'Close', 'Volume']:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        if len(df) > 100:\n",
    "            data_dict[ticker] = df\n",
    "            print(f\"   ‚úì {ticker}: {len(df)} days\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚úó {ticker}: {e}\")\n",
    "\n",
    "# Split 70/30 train/test\n",
    "train_data = {}\n",
    "test_data = {}\n",
    "for ticker, df in data_dict.items():\n",
    "    split = int(len(df) * 0.7)\n",
    "    train_data[ticker] = df.iloc[:split].reset_index(drop=True)\n",
    "    test_data[ticker] = df.iloc[split:].reset_index(drop=True)\n",
    "\n",
    "print(f\"\\n‚úÖ Train: {len(train_data[list(train_data.keys())[0]])} days\")\n",
    "print(f\"‚úÖ Test: {len(test_data[list(test_data.keys())[0]])} days\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6a6464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CELL 4: ENHANCED FEATURE ENGINE FOR FORECASTING ===\n",
    "def compute_forecast_features(df, params=None):\n",
    "    \"\"\"Compute features with EXPERIMENTAL additions for forecasting\"\"\"\n",
    "    if params is None:\n",
    "        params = {name: best for name, (_, _, best) in FORECAST_PARAMS.items()}\n",
    "    \n",
    "    df = df.copy()\n",
    "    c = df['Close'].astype(float)\n",
    "    h = df['High'].astype(float)\n",
    "    l = df['Low'].astype(float)\n",
    "    v = df['Volume'].astype(float)\n",
    "    \n",
    "    # === RSI (with evolved period) ===\n",
    "    rsi_period = int(params.get('rsi_period', 14))\n",
    "    delta = c.diff()\n",
    "    gain = delta.where(delta > 0, 0).rolling(rsi_period).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(rsi_period).mean()\n",
    "    df['rsi'] = 100 - (100 / (1 + gain / (loss + 1e-10)))\n",
    "    \n",
    "    # Multi-period RSI for divergence detection\n",
    "    for p in [7, 14, 21]:\n",
    "        gain_p = delta.where(delta > 0, 0).rolling(p).mean()\n",
    "        loss_p = (-delta.where(delta < 0, 0)).rolling(p).mean()\n",
    "        df[f'rsi_{p}'] = 100 - (100 / (1 + gain_p / (loss_p + 1e-10)))\n",
    "    \n",
    "    # === EMAs (evolved periods) ===\n",
    "    short_ema = int(params.get('ema_short_period', 8))\n",
    "    long_ema = int(params.get('ema_long_period', 34))\n",
    "    df['ema_short'] = c.ewm(span=short_ema).mean()\n",
    "    df['ema_long'] = c.ewm(span=long_ema).mean()\n",
    "    \n",
    "    # Standard EMAs for ribbon\n",
    "    for p in [5, 8, 13, 21, 34, 55, 89]:\n",
    "        df[f'ema_{p}'] = c.ewm(span=p).mean()\n",
    "    \n",
    "    # EMA trend signal\n",
    "    df['ema_bullish'] = (df['ema_short'] > df['ema_long']).astype(float)\n",
    "    df['ema_spread'] = (df['ema_short'] - df['ema_long']) / c * 100\n",
    "    df['ema_spread_expanding'] = (df['ema_spread'].abs() > df['ema_spread'].abs().shift(3)).astype(float)\n",
    "    \n",
    "    # === MACD (standard + custom) ===\n",
    "    df['macd'] = c.ewm(span=12).mean() - c.ewm(span=26).mean()\n",
    "    df['macd_signal'] = df['macd'].ewm(span=9).mean()\n",
    "    df['macd_hist'] = df['macd'] - df['macd_signal']\n",
    "    df['macd_bullish'] = (df['macd'] > df['macd_signal']).astype(float)\n",
    "    df['macd_hist_rising'] = (df['macd_hist'] > df['macd_hist'].shift(1)).astype(float)\n",
    "    \n",
    "    # Custom MACD periods\n",
    "    df['macd_fast'] = c.ewm(span=5).mean() - c.ewm(span=13).mean()\n",
    "    df['macd_fast_signal'] = df['macd_fast'].ewm(span=5).mean()\n",
    "    \n",
    "    # === Momentum (evolved lookback) ===\n",
    "    mom_days = int(params.get('momentum_lookback', 5))\n",
    "    df['momentum'] = c.pct_change(mom_days) * 100\n",
    "    df['momentum_5d'] = c.pct_change(5) * 100\n",
    "    df['momentum_10d'] = c.pct_change(10) * 100\n",
    "    df['momentum_21d'] = c.pct_change(21) * 100\n",
    "    \n",
    "    # Momentum acceleration\n",
    "    df['mom_accel'] = df['momentum'] - df['momentum'].shift(3)\n",
    "    df['mom_accel_pos'] = (df['mom_accel'] > 0).astype(float)\n",
    "    \n",
    "    # === Volatility ===\n",
    "    tr1 = h - l\n",
    "    tr2 = abs(h - c.shift(1))\n",
    "    tr3 = abs(l - c.shift(1))\n",
    "    tr = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)\n",
    "    df['atr'] = tr.rolling(14).mean()\n",
    "    df['atr_pct'] = df['atr'] / c * 100\n",
    "    df['volatility'] = c.pct_change().rolling(20).std() * np.sqrt(252) * 100\n",
    "    df['vol_expanding'] = (df['atr_pct'] > df['atr_pct'].rolling(20).mean()).astype(float)\n",
    "    df['vol_squeeze'] = (df['atr_pct'] < df['atr_pct'].rolling(50).mean() * 0.7).astype(float)\n",
    "    \n",
    "    # === Volume ===\n",
    "    df['vol_sma'] = v.rolling(20).mean()\n",
    "    df['vol_ratio'] = v / (df['vol_sma'] + 1)\n",
    "    df['vol_spike'] = (df['vol_ratio'] > 2).astype(float)\n",
    "    df['vol_trend'] = v.rolling(5).mean() / (v.rolling(20).mean() + 1)\n",
    "    \n",
    "    # OBV (On Balance Volume)\n",
    "    df['obv'] = (np.sign(c.diff()) * v).cumsum()\n",
    "    df['obv_trend'] = np.sign(df['obv'].diff(5))\n",
    "    \n",
    "    # === Price Position ===\n",
    "    df['high_20d'] = h.rolling(20).max()\n",
    "    df['low_20d'] = l.rolling(20).min()\n",
    "    df['price_position'] = (c - df['low_20d']) / (df['high_20d'] - df['low_20d'] + 1e-10)\n",
    "    \n",
    "    df['high_52w'] = h.rolling(252).max()\n",
    "    df['low_52w'] = l.rolling(252).min()\n",
    "    df['price_position_52w'] = (c - df['low_52w']) / (df['high_52w'] - df['low_52w'] + 1e-10)\n",
    "    \n",
    "    # === Trend Strength ===\n",
    "    df['trend_5d'] = np.sign(c.diff(5))\n",
    "    df['trend_10d'] = np.sign(c.diff(10))\n",
    "    df['trend_21d'] = np.sign(c.diff(21))\n",
    "    df['trend_align'] = (df['trend_5d'] + df['trend_10d'] + df['trend_21d']) / 3\n",
    "    \n",
    "    # === EXPERIMENTAL FEATURES ===\n",
    "    \n",
    "    # RSI Divergence\n",
    "    df['price_low_5d'] = c.rolling(5).min()\n",
    "    df['rsi_at_low'] = df['rsi'].rolling(5).min()\n",
    "    df['bullish_divergence'] = ((c <= df['price_low_5d'] * 1.02) & \n",
    "                                 (df['rsi'] > df['rsi_at_low'] + 5)).astype(float)\n",
    "    \n",
    "    df['price_high_5d'] = c.rolling(5).max()\n",
    "    df['rsi_at_high'] = df['rsi'].rolling(5).max()\n",
    "    df['bearish_divergence'] = ((c >= df['price_high_5d'] * 0.98) & \n",
    "                                 (df['rsi'] < df['rsi_at_high'] - 5)).astype(float)\n",
    "    \n",
    "    # Consolidation\n",
    "    df['range_10d'] = (h.rolling(10).max() - l.rolling(10).min()) / c * 100\n",
    "    df['consolidating'] = (df['range_10d'] < df['range_10d'].rolling(30).mean() * 0.6).astype(float)\n",
    "    \n",
    "    # Higher Highs / Higher Lows\n",
    "    df['higher_low'] = (l > l.shift(5)).astype(float)\n",
    "    df['higher_high'] = (h > h.shift(5)).astype(float)\n",
    "    df['uptrend_structure'] = (df['higher_low'] + df['higher_high']) / 2\n",
    "    df['lower_low'] = (l < l.shift(5)).astype(float)\n",
    "    df['lower_high'] = (h < h.shift(5)).astype(float)\n",
    "    df['downtrend_structure'] = (df['lower_low'] + df['lower_high']) / 2\n",
    "    \n",
    "    # Support/Resistance proximity\n",
    "    df['near_support'] = (c < df['low_20d'] * 1.03).astype(float)\n",
    "    df['near_resistance'] = (c > df['high_20d'] * 0.97).astype(float)\n",
    "    \n",
    "    # Mean Reversion potential\n",
    "    df['distance_from_ema21'] = (c / df['ema_21'] - 1) * 100\n",
    "    df['overextended_up'] = (df['distance_from_ema21'] > 10).astype(float)\n",
    "    df['overextended_down'] = (df['distance_from_ema21'] < -10).astype(float)\n",
    "    \n",
    "    df = df.replace([np.inf, -np.inf], np.nan).ffill().bfill().fillna(0)\n",
    "    return df\n",
    "\n",
    "print(\"üß† Computing ENHANCED forecast features...\")\n",
    "train_features = {t: compute_forecast_features(df) for t, df in train_data.items()}\n",
    "test_features = {t: compute_forecast_features(df) for t, df in test_data.items()}\n",
    "print(f\"‚úÖ Features ready - {len(train_features[list(train_features.keys())[0]].columns)} total features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c093529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CELL 5: FORECAST DNA CLASS ===\n",
    "\n",
    "class ForecastDNA:\n",
    "    \"\"\"A forecasting strategy's genetic code\"\"\"\n",
    "    \n",
    "    def __init__(self, params=None):\n",
    "        if params:\n",
    "            self.params = params\n",
    "        else:\n",
    "            # Random initialization\n",
    "            self.params = {}\n",
    "            for name, (min_v, max_v, _) in FORECAST_PARAMS.items():\n",
    "                if isinstance(min_v, int) and isinstance(max_v, int):\n",
    "                    self.params[name] = random.randint(min_v, max_v)\n",
    "                else:\n",
    "                    self.params[name] = random.uniform(min_v, max_v)\n",
    "        \n",
    "        self.fitness = 0\n",
    "        self.accuracy = 0\n",
    "        self.direction_accuracy = 0\n",
    "    \n",
    "    def mutate(self):\n",
    "        \"\"\"Randomly mutate one parameter\"\"\"\n",
    "        param = random.choice(list(self.params.keys()))\n",
    "        min_v, max_v, _ = FORECAST_PARAMS[param]\n",
    "        \n",
    "        # Mutation: adjust by 10-30%\n",
    "        current = self.params[param]\n",
    "        range_size = max_v - min_v\n",
    "        mutation = random.uniform(-0.3, 0.3) * range_size\n",
    "        new_val = current + mutation\n",
    "        \n",
    "        # Clamp to bounds\n",
    "        new_val = max(min_v, min(max_v, new_val))\n",
    "        \n",
    "        if isinstance(min_v, int) and isinstance(max_v, int):\n",
    "            new_val = int(new_val)\n",
    "        \n",
    "        self.params[param] = new_val\n",
    "    \n",
    "    @staticmethod\n",
    "    def crossover(parent1, parent2):\n",
    "        \"\"\"Breed two forecasters\"\"\"\n",
    "        child_params = {}\n",
    "        for param in parent1.params:\n",
    "            if random.random() < 0.5:\n",
    "                child_params[param] = parent1.params[param]\n",
    "            else:\n",
    "                child_params[param] = parent2.params[param]\n",
    "            \n",
    "            # 20% chance to blend\n",
    "            if random.random() < 0.2:\n",
    "                blend = (parent1.params[param] + parent2.params[param]) / 2\n",
    "                min_v, max_v, _ = FORECAST_PARAMS[param]\n",
    "                if isinstance(min_v, int) and isinstance(max_v, int):\n",
    "                    blend = int(blend)\n",
    "                child_params[param] = blend\n",
    "        \n",
    "        return ForecastDNA(child_params)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"ForecastDNA(fitness={self.fitness:.1f}, acc={self.accuracy:.1f}%)\"\n",
    "\n",
    "print(\"‚úÖ ForecastDNA class ready\")\n",
    "# Test\n",
    "test_dna = ForecastDNA()\n",
    "print(f\"   Sample DNA params: {len(test_dna.params)} genes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b172b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CELL 6: EXPERIMENTAL EVOLVED FORECASTER ===\n",
    "\n",
    "class EvolvedForecaster:\n",
    "    \"\"\"\n",
    "    Forecaster using evolved parameters.\n",
    "    EXPERIMENTAL - includes unconventional signal combinations.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, dna):\n",
    "        self.p = dna.params if hasattr(dna, 'params') else dna\n",
    "    \n",
    "    def compute_signal_score(self, row):\n",
    "        \"\"\"\n",
    "        Compute weighted signal score from ALL indicators.\n",
    "        Returns: score from -1 (very bearish) to +1 (very bullish)\n",
    "        \"\"\"\n",
    "        score = 0\n",
    "        total_weight = 0\n",
    "        signals = {}  # Track individual signals for analysis\n",
    "        \n",
    "        # === RSI Signal ===\n",
    "        rsi = row.get('rsi', 50)\n",
    "        rsi_signal = 0\n",
    "        if rsi < self.p['rsi_oversold']:\n",
    "            rsi_signal = 1.0  # Oversold = bullish\n",
    "        elif rsi > self.p['rsi_overbought']:\n",
    "            rsi_signal = -1.0  # Overbought = bearish\n",
    "        elif rsi < self.p['rsi_neutral_low']:\n",
    "            rsi_signal = 0.5\n",
    "        elif rsi > self.p['rsi_neutral_high']:\n",
    "            rsi_signal = -0.5\n",
    "        else:\n",
    "            # Gradient in neutral zone\n",
    "            rsi_signal = (50 - rsi) / 50 * 0.3\n",
    "        \n",
    "        signals['rsi'] = rsi_signal\n",
    "        score += rsi_signal * self.p['w_rsi']\n",
    "        total_weight += self.p['w_rsi']\n",
    "        \n",
    "        # === MACD Signal ===\n",
    "        macd_bullish = row.get('macd_bullish', 0.5)\n",
    "        macd_hist = row.get('macd_hist', 0)\n",
    "        macd_hist_rising = row.get('macd_hist_rising', 0.5)\n",
    "        \n",
    "        macd_signal = (macd_bullish - 0.5) * 2\n",
    "        if macd_hist > 0 and macd_hist_rising > 0:\n",
    "            macd_signal = min(1.0, macd_signal + 0.4)\n",
    "        elif macd_hist < 0 and macd_hist_rising < 1:\n",
    "            macd_signal = max(-1.0, macd_signal - 0.4)\n",
    "        \n",
    "        signals['macd'] = macd_signal\n",
    "        score += macd_signal * self.p['w_macd']\n",
    "        total_weight += self.p['w_macd']\n",
    "        \n",
    "        # === EMA Trend Signal ===\n",
    "        ema_bullish = row.get('ema_bullish', 0.5)\n",
    "        ema_spread = row.get('ema_spread', 0)\n",
    "        ema_expanding = row.get('ema_spread_expanding', 0)\n",
    "        \n",
    "        ema_signal = (ema_bullish - 0.5) * 2\n",
    "        # Amplify if spread is large and expanding\n",
    "        if abs(ema_spread) > 2 and ema_expanding > 0:\n",
    "            ema_signal *= 1.5\n",
    "        ema_signal = np.clip(ema_signal, -1, 1)\n",
    "        \n",
    "        signals['ema'] = ema_signal\n",
    "        score += ema_signal * self.p['w_ema_trend']\n",
    "        total_weight += self.p['w_ema_trend']\n",
    "        \n",
    "        # === Volume Signal ===\n",
    "        vol_ratio = row.get('vol_ratio', 1)\n",
    "        vol_trend = row.get('vol_trend', 1)\n",
    "        obv_trend = row.get('obv_trend', 0)\n",
    "        momentum = row.get('momentum', 0)\n",
    "        \n",
    "        if vol_ratio > 1.5:\n",
    "            vol_signal = np.sign(momentum) * min(1.0, (vol_ratio - 1) / 2)\n",
    "            # OBV confirmation\n",
    "            if obv_trend == np.sign(momentum):\n",
    "                vol_signal *= 1.3\n",
    "        else:\n",
    "            vol_signal = obv_trend * 0.3\n",
    "        \n",
    "        signals['volume'] = vol_signal\n",
    "        score += vol_signal * self.p['w_volume']\n",
    "        total_weight += self.p['w_volume']\n",
    "        \n",
    "        # === Momentum Signal ===\n",
    "        mom_5d = row.get('momentum_5d', 0)\n",
    "        mom_10d = row.get('momentum_10d', 0)\n",
    "        mom_accel = row.get('mom_accel', 0)\n",
    "        \n",
    "        # Multi-timeframe momentum\n",
    "        mom_signal = np.clip((mom_5d + mom_10d * 0.5) / 15, -1, 1)\n",
    "        # Acceleration bonus\n",
    "        if mom_accel > 0 and mom_signal > 0:\n",
    "            mom_signal = min(1.0, mom_signal * 1.3)\n",
    "        elif mom_accel < 0 and mom_signal < 0:\n",
    "            mom_signal = max(-1.0, mom_signal * 1.3)\n",
    "        \n",
    "        signals['momentum'] = mom_signal\n",
    "        score += mom_signal * self.p['w_momentum']\n",
    "        total_weight += self.p['w_momentum']\n",
    "        \n",
    "        # === Volatility Signal ===\n",
    "        atr_pct = row.get('atr_pct', 2)\n",
    "        vol_squeeze = row.get('vol_squeeze', 0)\n",
    "        vol_expanding = row.get('vol_expanding', 0)\n",
    "        \n",
    "        # High vol = uncertainty, low vol = potential breakout\n",
    "        vol_adj = self.p.get('vol_adjustment', 1.0)\n",
    "        if vol_squeeze > 0:\n",
    "            vol_signal = 0.3 * np.sign(momentum)  # Potential breakout\n",
    "        elif vol_expanding > 0 and atr_pct > 4:\n",
    "            vol_signal = -0.2  # High uncertainty\n",
    "        else:\n",
    "            vol_signal = 0\n",
    "        \n",
    "        signals['volatility'] = vol_signal\n",
    "        score += vol_signal * self.p['w_volatility']\n",
    "        total_weight += self.p['w_volatility']\n",
    "        \n",
    "        # === EXPERIMENTAL SIGNALS ===\n",
    "        \n",
    "        # RSI Divergence\n",
    "        bull_div = row.get('bullish_divergence', 0)\n",
    "        bear_div = row.get('bearish_divergence', 0)\n",
    "        div_signal = bull_div - bear_div\n",
    "        signals['divergence'] = div_signal\n",
    "        w_div = self.p.get('w_rsi_divergence', 0.5)\n",
    "        score += div_signal * w_div\n",
    "        total_weight += w_div\n",
    "        \n",
    "        # Consolidation Breakout\n",
    "        consolidating = row.get('consolidating', 0)\n",
    "        consol_signal = consolidating * np.sign(momentum) * 0.5\n",
    "        signals['consolidation'] = consol_signal\n",
    "        w_consol = self.p.get('w_consolidation', 0.5)\n",
    "        score += consol_signal * w_consol\n",
    "        total_weight += w_consol\n",
    "        \n",
    "        # Trend Structure\n",
    "        uptrend = row.get('uptrend_structure', 0)\n",
    "        downtrend = row.get('downtrend_structure', 0)\n",
    "        structure_signal = uptrend - downtrend\n",
    "        signals['structure'] = structure_signal\n",
    "        w_struct = self.p.get('w_trend_structure', 0.5)\n",
    "        score += structure_signal * w_struct\n",
    "        total_weight += w_struct\n",
    "        \n",
    "        # Mean Reversion\n",
    "        dist_from_ema = row.get('distance_from_ema21', 0)\n",
    "        mr_weight = self.p.get('mean_reversion_weight', 0.3)\n",
    "        if abs(dist_from_ema) > 8:\n",
    "            mr_signal = -np.sign(dist_from_ema) * min(1.0, abs(dist_from_ema) / 15)\n",
    "            score += mr_signal * mr_weight\n",
    "            total_weight += mr_weight\n",
    "            signals['mean_reversion'] = mr_signal\n",
    "        \n",
    "        # Normalize score\n",
    "        if total_weight > 0:\n",
    "            score = score / total_weight\n",
    "        \n",
    "        # Trend confirmation requirement\n",
    "        trend_conf = self.p.get('trend_confirmation', 0.5)\n",
    "        trend_align = row.get('trend_align', 0)\n",
    "        if trend_conf > 0.5 and np.sign(score) != np.sign(trend_align) and abs(trend_align) > 0.3:\n",
    "            score *= (1 - trend_conf * 0.5)  # Reduce confidence if against trend\n",
    "        \n",
    "        return np.clip(score, -1, 1), signals\n",
    "    \n",
    "    def generate_signal(self, row):\n",
    "        \"\"\"Generate BUY/SELL/HOLD signal with confidence.\"\"\"\n",
    "        score, signals = self.compute_signal_score(row)\n",
    "        \n",
    "        strong_mult = self.p.get('signal_strong_mult', 1.3)\n",
    "        conf_floor = self.p.get('confidence_floor', 0.3)\n",
    "        \n",
    "        if score > self.p['signal_buy_threshold']:\n",
    "            signal = 'BUY'\n",
    "            # Strong signal bonus\n",
    "            if score > self.p['signal_buy_threshold'] * strong_mult:\n",
    "                confidence = self.p['base_confidence'] + self.p['confidence_boost'] * 1.5\n",
    "            else:\n",
    "                confidence = self.p['base_confidence'] + self.p['confidence_boost'] * abs(score)\n",
    "        elif score < self.p['signal_sell_threshold']:\n",
    "            signal = 'SELL'\n",
    "            if score < self.p['signal_sell_threshold'] * strong_mult:\n",
    "                confidence = self.p['base_confidence'] + self.p['confidence_boost'] * 1.5\n",
    "            else:\n",
    "                confidence = self.p['base_confidence'] + self.p['confidence_boost'] * abs(score)\n",
    "        else:\n",
    "            signal = 'HOLD'\n",
    "            confidence = self.p['base_confidence']\n",
    "        \n",
    "        confidence = max(conf_floor, min(0.95, confidence))\n",
    "        \n",
    "        return signal, confidence, score, signals\n",
    "    \n",
    "    def forecast_price(self, current_price, signal, confidence, day, volatility):\n",
    "        \"\"\"Generate price forecast for a specific day.\"\"\"\n",
    "        # Decay confidence over time\n",
    "        decay_start = int(self.p.get('decay_start_day', 10))\n",
    "        decay_factor = 1.0\n",
    "        if day > decay_start:\n",
    "            decay_factor = self.p['confidence_decay'] ** (day - decay_start)\n",
    "        \n",
    "        conf_floor = self.p.get('confidence_floor', 0.3)\n",
    "        effective_conf = max(conf_floor, confidence * decay_factor)\n",
    "        \n",
    "        # Determine drift\n",
    "        if signal == 'BUY':\n",
    "            drift = self.p['drift_bull'] * effective_conf\n",
    "        elif signal == 'SELL':\n",
    "            drift = self.p['drift_bear'] * effective_conf\n",
    "        else:\n",
    "            drift = self.p.get('drift_neutral', 0)\n",
    "        \n",
    "        # Volatility adjustment\n",
    "        vol_adj = self.p.get('vol_adjustment', 1.0)\n",
    "        vol_scale = self.p['volatility_scale'] * vol_adj\n",
    "        random_component = np.random.normal(0, volatility * vol_scale / 100)\n",
    "        \n",
    "        # Price change\n",
    "        price_change = drift + random_component\n",
    "        price_change = np.clip(price_change, -self.p['max_daily_move'], self.p['max_daily_move'])\n",
    "        \n",
    "        new_price = current_price * (1 + price_change)\n",
    "        \n",
    "        return new_price, effective_conf\n",
    "\n",
    "print(\"‚úÖ EXPERIMENTAL EvolvedForecaster class ready\")\n",
    "print(\"   - Multi-indicator fusion\")\n",
    "print(\"   - Divergence detection\")\n",
    "print(\"   - Mean reversion overlay\")\n",
    "print(\"   - Trend confirmation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270c317e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CELL 7: FITNESS EVALUATOR ===\n",
    "\n",
    "def evaluate_forecast_fitness(dna, features_dict, data_dict, forecast_days=7):\n",
    "    \"\"\"\n",
    "    Evaluate forecaster accuracy.\n",
    "    \n",
    "    Fitness based on:\n",
    "    - Direction accuracy (did we predict up/down correctly?)\n",
    "    - Magnitude accuracy (how close was our forecast?)\n",
    "    - Signal quality (did BUY signals lead to gains?)\n",
    "    \"\"\"\n",
    "    forecaster = EvolvedForecaster(dna)\n",
    "    \n",
    "    direction_correct = 0\n",
    "    direction_total = 0\n",
    "    magnitude_errors = []\n",
    "    signal_returns = {'BUY': [], 'SELL': [], 'HOLD': []}\n",
    "    \n",
    "    tickers = list(features_dict.keys())\n",
    "    \n",
    "    for ticker in tickers:\n",
    "        df = features_dict[ticker]\n",
    "        data = data_dict[ticker]\n",
    "        \n",
    "        # Test on multiple points\n",
    "        test_points = range(60, len(df) - forecast_days - 1, 5)  # Every 5 days\n",
    "        \n",
    "        for start_idx in test_points:\n",
    "            try:\n",
    "                row = df.iloc[start_idx].to_dict()\n",
    "                current_price = float(data['Close'].iloc[start_idx])\n",
    "                \n",
    "                # Generate signal\n",
    "                signal, confidence, score = forecaster.generate_signal(row)\n",
    "                \n",
    "                # Get actual future prices\n",
    "                future_prices = []\n",
    "                for d in range(1, forecast_days + 1):\n",
    "                    if start_idx + d < len(data):\n",
    "                        future_prices.append(float(data['Close'].iloc[start_idx + d]))\n",
    "                \n",
    "                if len(future_prices) < forecast_days:\n",
    "                    continue\n",
    "                \n",
    "                # Actual return over forecast period\n",
    "                actual_return = (future_prices[-1] / current_price - 1) * 100\n",
    "                \n",
    "                # Direction accuracy\n",
    "                predicted_direction = 1 if signal == 'BUY' else (-1 if signal == 'SELL' else 0)\n",
    "                actual_direction = 1 if actual_return > 1 else (-1 if actual_return < -1 else 0)\n",
    "                \n",
    "                if predicted_direction != 0:  # Only count non-HOLD predictions\n",
    "                    direction_total += 1\n",
    "                    if predicted_direction == actual_direction:\n",
    "                        direction_correct += 1\n",
    "                \n",
    "                # Signal quality (did signal lead to profit?)\n",
    "                signal_returns[signal].append(actual_return)\n",
    "                \n",
    "                # Generate forecast and measure error\n",
    "                volatility = float(row.get('atr_pct', 2))\n",
    "                forecasted_price = current_price\n",
    "                \n",
    "                for d in range(forecast_days):\n",
    "                    forecasted_price, _ = forecaster.forecast_price(\n",
    "                        forecasted_price, signal, confidence, d + 1, volatility\n",
    "                    )\n",
    "                \n",
    "                forecast_return = (forecasted_price / current_price - 1) * 100\n",
    "                magnitude_error = abs(forecast_return - actual_return)\n",
    "                magnitude_errors.append(magnitude_error)\n",
    "                \n",
    "            except Exception as e:\n",
    "                continue\n",
    "    \n",
    "    # Calculate metrics\n",
    "    direction_accuracy = (direction_correct / max(direction_total, 1)) * 100\n",
    "    avg_magnitude_error = np.mean(magnitude_errors) if magnitude_errors else 100\n",
    "    \n",
    "    # Signal quality scores\n",
    "    buy_avg = np.mean(signal_returns['BUY']) if signal_returns['BUY'] else 0\n",
    "    sell_avg = np.mean(signal_returns['SELL']) if signal_returns['SELL'] else 0\n",
    "    \n",
    "    # Good BUY signals should have positive returns\n",
    "    # Good SELL signals should have negative returns (or we avoided losses)\n",
    "    buy_quality = max(0, buy_avg)  # Reward positive returns on BUY\n",
    "    sell_quality = max(0, -sell_avg)  # Reward avoided losses on SELL\n",
    "    signal_quality = buy_quality + sell_quality\n",
    "    \n",
    "    # FITNESS FORMULA:\n",
    "    # High direction accuracy + low magnitude error + good signal quality\n",
    "    fitness = (\n",
    "        direction_accuracy * 2 +              # Weight direction accuracy heavily\n",
    "        max(0, 50 - avg_magnitude_error) +    # Penalty for large errors\n",
    "        signal_quality * 10                    # Reward good signals\n",
    "    )\n",
    "    \n",
    "    return fitness, direction_accuracy, avg_magnitude_error, buy_avg, sell_avg\n",
    "\n",
    "print(\"‚úÖ Fitness evaluator ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064f4c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CELL 8: EVOLUTION ENGINE ===\n",
    "\n",
    "def evolve_forecasters(population, features, data):\n",
    "    \"\"\"One generation of evolution\"\"\"\n",
    "    \n",
    "    # Evaluate all\n",
    "    for dna in population:\n",
    "        dna.fitness, dna.accuracy, _, _, _ = evaluate_forecast_fitness(dna, features, data)\n",
    "    \n",
    "    # Sort by fitness\n",
    "    population.sort(key=lambda x: x.fitness, reverse=True)\n",
    "    \n",
    "    # Keep elite\n",
    "    new_pop = population[:EVOLUTION_CONFIG['elite_keep']]\n",
    "    \n",
    "    # Fill rest with offspring\n",
    "    while len(new_pop) < EVOLUTION_CONFIG['population_size']:\n",
    "        # Tournament selection\n",
    "        def tournament():\n",
    "            contestants = random.sample(population[:25], EVOLUTION_CONFIG['tournament_size'])\n",
    "            return max(contestants, key=lambda x: x.fitness)\n",
    "        \n",
    "        parent1 = tournament()\n",
    "        parent2 = tournament()\n",
    "        \n",
    "        # Crossover\n",
    "        if random.random() < EVOLUTION_CONFIG['crossover_rate']:\n",
    "            child = ForecastDNA.crossover(parent1, parent2)\n",
    "        else:\n",
    "            child = ForecastDNA(deepcopy(parent1.params))\n",
    "        \n",
    "        # Mutation\n",
    "        if random.random() < EVOLUTION_CONFIG['mutation_rate']:\n",
    "            child.mutate()\n",
    "        \n",
    "        new_pop.append(child)\n",
    "    \n",
    "    return new_pop\n",
    "\n",
    "print(\"‚úÖ Evolution engine ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e92a065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CELL 9: R&D EVOLUTION RUN ===\n",
    "print(\"=\" * 70)\n",
    "print(\"üî¨ R&D DISCOVERY MODE - FORECASTER EVOLUTION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Initialize population\n",
    "population = [ForecastDNA() for _ in range(EVOLUTION_CONFIG['population_size'])]\n",
    "\n",
    "# Seed with human baseline\n",
    "human_params = {name: best for name, (_, _, best) in FORECAST_PARAMS.items()}\n",
    "population[0] = ForecastDNA(human_params)\n",
    "\n",
    "# Seed extreme variants\n",
    "rsi_heavy = human_params.copy()\n",
    "rsi_heavy['w_rsi'] = 2.5\n",
    "rsi_heavy['w_macd'] = 0.5\n",
    "rsi_heavy['w_momentum'] = 0.5\n",
    "population[1] = ForecastDNA(rsi_heavy)\n",
    "\n",
    "momentum_heavy = human_params.copy()\n",
    "momentum_heavy['w_momentum'] = 2.5\n",
    "momentum_heavy['w_rsi'] = 0.5\n",
    "momentum_heavy['w_macd'] = 0.5\n",
    "population[2] = ForecastDNA(momentum_heavy)\n",
    "\n",
    "trend_heavy = human_params.copy()\n",
    "trend_heavy['w_ema_trend'] = 2.5\n",
    "trend_heavy['w_trend_structure'] = 1.5\n",
    "population[3] = ForecastDNA(trend_heavy)\n",
    "\n",
    "mean_reversion = human_params.copy()\n",
    "mean_reversion['mean_reversion_weight'] = 0.8\n",
    "mean_reversion['signal_buy_threshold'] = 0.3\n",
    "population[4] = ForecastDNA(mean_reversion)\n",
    "\n",
    "best_ever = None\n",
    "history = []\n",
    "discoveries = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "print(f\"\\nüöÄ Starting with {EVOLUTION_CONFIG['population_size']} forecasters\")\n",
    "print(f\"   Seeded: Human, RSI-Heavy, Momentum-Heavy, Trend-Heavy, Mean-Reversion\\n\")\n",
    "\n",
    "for gen in range(EVOLUTION_CONFIG['generations']):\n",
    "    # Evolve on TRAINING data\n",
    "    population = evolve_forecasters(population, train_features, train_data)\n",
    "    \n",
    "    best = population[0]\n",
    "    avg_fitness = np.mean([d.fitness for d in population[:10]])\n",
    "    diversity = np.std([d.fitness for d in population])\n",
    "    \n",
    "    # Track best ever\n",
    "    if best_ever is None or best.fitness > best_ever.fitness:\n",
    "        best_ever = ForecastDNA(deepcopy(best.params))\n",
    "        best_ever.fitness = best.fitness\n",
    "        best_ever.accuracy = best.accuracy\n",
    "        \n",
    "        discoveries.append({\n",
    "            'gen': gen,\n",
    "            'fitness': best.fitness,\n",
    "            'accuracy': best.accuracy,\n",
    "            'params': best.params.copy()\n",
    "        })\n",
    "        marker = \"üÜï NEW BEST!\"\n",
    "    else:\n",
    "        marker = \"\"\n",
    "    \n",
    "    history.append({\n",
    "        'gen': gen,\n",
    "        'best_fitness': best.fitness,\n",
    "        'best_accuracy': best.accuracy,\n",
    "        'avg_fitness': avg_fitness,\n",
    "        'diversity': diversity\n",
    "    })\n",
    "    \n",
    "    # Chaos injection\n",
    "    restart_every = EVOLUTION_CONFIG.get('restart_every', 12)\n",
    "    if gen > 0 and gen % restart_every == 0:\n",
    "        num_replace = int(EVOLUTION_CONFIG['population_size'] * 0.25)\n",
    "        for i in range(-num_replace, 0):\n",
    "            population[i] = ForecastDNA()\n",
    "        print(f\"   üîÑ Gen {gen}: Injected {num_replace} wild cards\")\n",
    "    \n",
    "    # Wild cards each generation\n",
    "    wild_pct = EVOLUTION_CONFIG.get('wild_card_pct', 0.1)\n",
    "    num_wild = max(1, int(EVOLUTION_CONFIG['population_size'] * wild_pct))\n",
    "    for i in range(num_wild):\n",
    "        idx = random.randint(EVOLUTION_CONFIG['elite_keep'], len(population) - 1)\n",
    "        population[idx] = ForecastDNA()\n",
    "    \n",
    "    if gen % 5 == 0:\n",
    "        elapsed = time.time() - start_time\n",
    "        print(f\"Gen {gen:3d} | Fit: {best.fitness:8.1f} | Acc: {best.accuracy:5.1f}% | Avg: {avg_fitness:7.1f} | {elapsed:.0f}s {marker}\")\n",
    "\n",
    "print(\"-\" * 70)\n",
    "print(f\"\\nüèÜ R&D COMPLETE in {time.time()-start_time:.0f}s\")\n",
    "print(f\"   Best Fitness: {best_ever.fitness:.1f}\")\n",
    "print(f\"   Best Accuracy: {best_ever.accuracy:.1f}%\")\n",
    "print(f\"   Discoveries: {len(discoveries)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1144f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CELL 10: TEST ON UNSEEN DATA ===\n",
    "print(\"=\" * 70)\n",
    "print(\"üß™ TESTING EVOLVED FORECASTER ON UNSEEN DATA\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Test evolved best\n",
    "evolved_fit, evolved_acc, evolved_err, evolved_buy, evolved_sell = evaluate_forecast_fitness(\n",
    "    best_ever, test_features, test_data\n",
    ")\n",
    "\n",
    "# Test human baseline\n",
    "human_dna = ForecastDNA(human_params)\n",
    "human_fit, human_acc, human_err, human_buy, human_sell = evaluate_forecast_fitness(\n",
    "    human_dna, test_features, test_data\n",
    ")\n",
    "\n",
    "print(f\"\\n{'Metric':<25} {'Human':>15} {'Evolved':>15} {'Winner':>10}\")\n",
    "print(\"-\" * 65)\n",
    "print(f\"{'Direction Accuracy':<25} {human_acc:>14.1f}% {evolved_acc:>14.1f}% {'üß¨' if evolved_acc > human_acc else 'üë§'}\")\n",
    "print(f\"{'Magnitude Error':<25} {human_err:>14.1f}% {evolved_err:>14.1f}% {'üß¨' if evolved_err < human_err else 'üë§'}\")\n",
    "print(f\"{'BUY Signal Avg Return':<25} {human_buy:>+14.2f}% {evolved_buy:>+14.2f}% {'üß¨' if evolved_buy > human_buy else 'üë§'}\")\n",
    "print(f\"{'SELL Signal Avg Return':<25} {human_sell:>+14.2f}% {evolved_sell:>+14.2f}% {'üß¨' if evolved_sell < human_sell else 'üë§'}\")\n",
    "print(f\"{'Fitness Score':<25} {human_fit:>15.1f} {evolved_fit:>15.1f} {'üß¨' if evolved_fit > human_fit else 'üë§'}\")\n",
    "\n",
    "improvement = evolved_acc - human_acc\n",
    "print(f\"\\nüìà Direction accuracy improved by {improvement:+.1f} percentage points\")\n",
    "\n",
    "# Show discoveries\n",
    "print(f\"\\nüî¨ R&D DISCOVERIES ({len(discoveries)} breakthroughs):\")\n",
    "for d in discoveries[:5]:\n",
    "    print(f\"   Gen {d['gen']:3d}: Fitness {d['fitness']:.1f}, Accuracy {d['accuracy']:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b89eb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CELL 11: SHOW EVOLVED PARAMETERS ===\n",
    "print(\"=\" * 70)\n",
    "print(\"üß¨ EVOLVED OPTIMAL FORECASTER PARAMETERS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\n{'Parameter':<30} {'Human':>12} {'Evolved':>12} {'Change':>12}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for param in FORECAST_PARAMS:\n",
    "    human_val = human_params[param]\n",
    "    evolved_val = best_ever.params[param]\n",
    "    \n",
    "    if isinstance(human_val, float):\n",
    "        if human_val != 0:\n",
    "            change = (evolved_val - human_val) / abs(human_val) * 100\n",
    "        else:\n",
    "            change = evolved_val * 100\n",
    "        print(f\"{param:<30} {human_val:>12.3f} {evolved_val:>12.3f} {change:>+11.1f}%\")\n",
    "    else:\n",
    "        change = evolved_val - human_val\n",
    "        print(f\"{param:<30} {human_val:>12} {evolved_val:>12} {change:>+12}\")\n",
    "\n",
    "# Group by category\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üìã KEY INSIGHTS FROM R&D EVOLUTION:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Classic indicator weights\n",
    "print(\"\\nüéöÔ∏è CLASSIC INDICATOR WEIGHTS:\")\n",
    "classic_weights = ['w_rsi', 'w_macd', 'w_ema_trend', 'w_volume', 'w_momentum', 'w_volatility']\n",
    "for name in classic_weights:\n",
    "    val = best_ever.params[name]\n",
    "    indicator = name.replace('w_', '').upper()\n",
    "    bar = '‚ñà' * int(val * 8)\n",
    "    print(f\"   {indicator:<15} {bar:<20} {val:.2f}\")\n",
    "\n",
    "# Experimental indicator weights\n",
    "print(\"\\nüß™ EXPERIMENTAL INDICATOR WEIGHTS:\")\n",
    "exp_weights = ['w_rsi_divergence', 'w_consolidation', 'w_trend_structure', 'w_mean_reversion']\n",
    "for name in exp_weights:\n",
    "    val = best_ever.params.get(name, 0)\n",
    "    indicator = name.replace('w_', '').upper()\n",
    "    bar = '‚ñà' * int(val * 8)\n",
    "    status = \"üî•\" if val > 1.0 else \"‚úÖ\" if val > 0.5 else \"‚ùì\"\n",
    "    print(f\"   {indicator:<18} {bar:<16} {val:.2f} {status}\")\n",
    "\n",
    "# Thresholds\n",
    "print(\"\\nüéØ EVOLVED THRESHOLDS:\")\n",
    "print(f\"   RSI Oversold: < {best_ever.params['rsi_oversold']:.0f}\")\n",
    "print(f\"   RSI Overbought: > {best_ever.params['rsi_overbought']:.0f}\")\n",
    "print(f\"   Signal Buy Threshold: {best_ever.params['signal_buy_threshold']:.2f}\")\n",
    "print(f\"   Signal Sell Threshold: {best_ever.params['signal_sell_threshold']:.2f}\")\n",
    "\n",
    "# Forecast mechanics\n",
    "print(\"\\n‚öôÔ∏è FORECAST MECHANICS:\")\n",
    "print(f\"   Daily Bull Drift: {best_ever.params['drift_bull']*100:.2f}%\")\n",
    "print(f\"   Daily Bear Drift: {best_ever.params['drift_bear']*100:.2f}%\")\n",
    "print(f\"   Max Daily Move: {best_ever.params['max_daily_move']*100:.1f}%\")\n",
    "print(f\"   Confidence Decay: {best_ever.params['confidence_decay']:.2f} per day\")\n",
    "print(f\"   Decay Start Day: {int(best_ever.params['decay_start_day'])}\")\n",
    "\n",
    "# New R&D parameters\n",
    "print(\"\\nüî¨ R&D DISCOVERIES:\")\n",
    "print(f\"   Mean Reversion Weight: {best_ever.params.get('mean_reversion_weight', 0):.2f}\")\n",
    "print(f\"   Trend Continuation Bias: {best_ever.params.get('trend_continuation_bias', 0):.2f}\")\n",
    "print(f\"   Signal Smoothing: {best_ever.params.get('signal_smoothing', 0):.2f}\")\n",
    "print(f\"   Confidence Floor: {best_ever.params.get('confidence_floor', 0):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eefae27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CELL 12: LIVE FORECAST DEMO ===\n",
    "print(\"=\" * 70)\n",
    "print(\"üîÆ LIVE FORECAST DEMO (Using Evolved Parameters)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Pick top quantum/AI tickers to forecast\n",
    "demo_tickers = ['RGTI', 'IONQ', 'SMR', 'OKLO', 'TSLA', 'NVDA', 'AMD', 'PLTR'][:8]\n",
    "\n",
    "evolved_forecaster = EvolvedForecaster(best_ever)\n",
    "\n",
    "print(f\"\\n{'Ticker':<8} {'Price':>10} {'Signal':>8} {'Conf':>8} {'Score':>8} {'7d Fcst':>10} {'Expected':>10}\")\n",
    "print(\"-\" * 75)\n",
    "\n",
    "forecasts = []\n",
    "for ticker in demo_tickers:\n",
    "    if ticker not in test_features:\n",
    "        continue\n",
    "    \n",
    "    df = test_features[ticker]\n",
    "    data = test_data[ticker]\n",
    "    \n",
    "    row = df.iloc[-1].to_dict()\n",
    "    current_price = float(data['Close'].iloc[-1])\n",
    "    volatility = row.get('atr_pct', 2)\n",
    "    \n",
    "    signal, confidence, score = evolved_forecaster.generate_signal(row)\n",
    "    \n",
    "    # 7-day forecast\n",
    "    forecast_price = current_price\n",
    "    for d in range(7):\n",
    "        forecast_price, _ = evolved_forecaster.forecast_price(\n",
    "            forecast_price, signal, confidence, d + 1, volatility\n",
    "        )\n",
    "    \n",
    "    expected_return = (forecast_price / current_price - 1) * 100\n",
    "    \n",
    "    signal_emoji = 'üü¢' if signal == 'BUY' else 'üî¥' if signal == 'SELL' else 'üü°'\n",
    "    \n",
    "    print(f\"{ticker:<8} ${current_price:>9.2f} {signal_emoji} {signal:<6} {confidence*100:>6.0f}% {score:>+7.2f} ${forecast_price:>9.2f} {expected_return:>+9.1f}%\")\n",
    "    \n",
    "    forecasts.append({\n",
    "        'ticker': ticker,\n",
    "        'current_price': current_price,\n",
    "        'signal': signal,\n",
    "        'confidence': confidence,\n",
    "        'raw_score': score,\n",
    "        'forecast_7d': forecast_price,\n",
    "        'expected_return': expected_return\n",
    "    })\n",
    "\n",
    "print(\"\\n\" + \"-\" * 75)\n",
    "buys = [f for f in forecasts if f['signal'] == 'BUY']\n",
    "sells = [f for f in forecasts if f['signal'] == 'SELL']\n",
    "holds = len(forecasts) - len(buys) - len(sells)\n",
    "\n",
    "print(f\"   üü¢ BUY signals: {len(buys)}\")\n",
    "for b in sorted(buys, key=lambda x: -x['expected_return']):\n",
    "    print(f\"      {b['ticker']}: {b['expected_return']:+.1f}% expected\")\n",
    "    \n",
    "print(f\"   üî¥ SELL signals: {len(sells)}\")\n",
    "for s in sorted(sells, key=lambda x: x['expected_return']):\n",
    "    print(f\"      {s['ticker']}: {s['expected_return']:+.1f}% expected\")\n",
    "\n",
    "print(f\"   üü° HOLD signals: {holds}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd553c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CELL 13: SAVE R&D RESULTS ===\n",
    "results = {\n",
    "    'generated_at': datetime.now().isoformat(),\n",
    "    'mode': 'R&D_DISCOVERY',\n",
    "    'evolution_config': EVOLUTION_CONFIG,\n",
    "    'generations_run': EVOLUTION_CONFIG['generations'],\n",
    "    'human_baseline': {\n",
    "        'params': human_params,\n",
    "        'test_direction_accuracy': human_acc,\n",
    "        'test_magnitude_error': human_err,\n",
    "        'test_buy_avg': human_buy,\n",
    "        'test_sell_avg': human_sell,\n",
    "        'fitness': human_fit\n",
    "    },\n",
    "    'evolved_best': {\n",
    "        'params': best_ever.params,\n",
    "        'test_direction_accuracy': evolved_acc,\n",
    "        'test_magnitude_error': evolved_err,\n",
    "        'test_buy_avg': evolved_buy,\n",
    "        'test_sell_avg': evolved_sell,\n",
    "        'fitness': evolved_fit\n",
    "    },\n",
    "    'improvement': {\n",
    "        'direction_accuracy_pct': evolved_acc - human_acc,\n",
    "        'magnitude_error_reduction': human_err - evolved_err,\n",
    "        'fitness_improvement': evolved_fit - human_fit,\n",
    "        'verdict': 'EVOLVED_WINS' if evolved_acc > human_acc + 3 else 'MARGINAL' if evolved_acc > human_acc else 'HUMAN_WINS'\n",
    "    },\n",
    "    'r_and_d_discoveries': discoveries,\n",
    "    'evolution_history': history,\n",
    "    'demo_forecasts': forecasts,\n",
    "    'experimental_weights': {\n",
    "        'rsi_divergence': best_ever.params.get('w_rsi_divergence', 0),\n",
    "        'consolidation': best_ever.params.get('w_consolidation', 0),\n",
    "        'trend_structure': best_ever.params.get('w_trend_structure', 0),\n",
    "        'mean_reversion': best_ever.params.get('mean_reversion_weight', 0)\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('forecast_evolution_results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2, default=str)\n",
    "\n",
    "print(\"‚úÖ R&D Results saved to forecast_evolution_results.json\")\n",
    "\n",
    "# Also save just the optimal parameters for easy import\n",
    "optimal_params = {\n",
    "    'source': 'FORECAST_EVOLUTION_R&D',\n",
    "    'generated_at': datetime.now().isoformat(),\n",
    "    'direction_accuracy': evolved_acc,\n",
    "    'params': best_ever.params\n",
    "}\n",
    "\n",
    "with open('evolved_forecast_params.json', 'w') as f:\n",
    "    json.dump(optimal_params, f, indent=2, default=str)\n",
    "\n",
    "print(\"‚úÖ Optimal params saved to evolved_forecast_params.json\")\n",
    "\n",
    "try:\n",
    "    from google.colab import files\n",
    "    files.download('forecast_evolution_results.json')\n",
    "    files.download('evolved_forecast_params.json')\n",
    "    print(\"üì• Downloads started!\")\n",
    "except:\n",
    "    print(\"(Not in Colab - files saved locally)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42023f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CELL 14: FINAL RECOMMENDATIONS ===\n",
    "print(\"=\" * 70)\n",
    "print(\"üìã FINAL FORECASTER RECOMMENDATIONS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if evolved_acc > human_acc + 5:  # 5% better\n",
    "    print(\"\\nüß¨ USE EVOLVED FORECASTER!\")\n",
    "    print(f\"   Direction accuracy improved by {evolved_acc - human_acc:.1f}%\")\n",
    "    rec = best_ever.params\n",
    "else:\n",
    "    print(\"\\n‚öñÔ∏è BLEND EVOLVED + HUMAN PARAMETERS\")\n",
    "    print(\"   Evolution found minor improvements.\")\n",
    "    rec = best_ever.params\n",
    "\n",
    "print(\"\\nüéØ OPTIMAL INDICATOR WEIGHTS:\")\n",
    "print(\"-\" * 50)\n",
    "for name in ['w_rsi', 'w_macd', 'w_ema_trend', 'w_volume', 'w_momentum', 'w_volatility']:\n",
    "    indicator = name.replace('w_', '').upper()\n",
    "    val = rec[name]\n",
    "    importance = 'HIGH' if val > 1.3 else 'MEDIUM' if val > 0.7 else 'LOW'\n",
    "    print(f\"   {indicator:<15} {val:.2f} ({importance})\")\n",
    "\n",
    "print(\"\\nüîß COPY THESE SETTINGS TO YOUR FORECASTER:\")\n",
    "print(\"-\" * 50)\n",
    "print(json.dumps(rec, indent=2))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚úÖ FORECAST EVOLUTION COMPLETE!\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
