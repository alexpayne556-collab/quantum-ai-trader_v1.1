{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6364dfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === SETUP ===\n",
    "!pip install -q yfinance numba scikit-optimize\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "from datetime import datetime\n",
    "from copy import deepcopy\n",
    "from collections import defaultdict, deque\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"üî¨ DEEP PATTERN EVOLUTION TRAINER\")\n",
    "print(f\"üìÖ {datetime.now().strftime('%Y-%m-%d %H:%M')}\")\n",
    "print(\"\\nüéØ Mission: Discover which signals work, not just tune parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8043717a",
   "metadata": {},
   "source": [
    "## üìã Configuration & Watchlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85b6268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CONFIGURATION ===\n",
    "CONFIG = {\n",
    "    'watchlist': ['IONQ', 'RGTI', 'QUBT', 'SMR', 'OKLO', 'NVDA', 'AMD', 'TSLA', 'META', 'PLTR', 'SPY', 'QQQ'],\n",
    "    'test_phases': ['independent', 'combinations', 'adversarial', 'regime_specific'],\n",
    "    'min_trades': 10,  # Minimum trades for valid signal test\n",
    "    'min_win_rate': 55,  # Minimum win rate to keep signal\n",
    "}\n",
    "\n",
    "# === 9 ENTRY SIGNALS TO TEST ===\n",
    "SIGNAL_DEFINITIONS = {\n",
    "    'dip_buy': {\n",
    "        'name': 'RSI Oversold Dip',\n",
    "        'logic': 'rsi < threshold AND momentum < -3',\n",
    "        'params': {'rsi_threshold': [15, 40, 30]},\n",
    "        'hypothesis': 'Buy when oversold for mean reversion'\n",
    "    },\n",
    "    'bounce': {\n",
    "        'name': 'Price Bounce Off Lows',\n",
    "        'logic': 'bounce > threshold AND macd_rising',\n",
    "        'params': {'bounce_threshold': [3, 20, 8]},\n",
    "        'hypothesis': 'Price bouncing off support'\n",
    "    },\n",
    "    'nuclear_dip': {\n",
    "        'name': 'Nuclear Dip Recovery',\n",
    "        'logic': 'ret_21d < threshold AND macd_rising',\n",
    "        'params': {'dip_threshold': [-30, -5, -10]},\n",
    "        'hypothesis': 'Buy severe dips with reversal confirmation'\n",
    "    },\n",
    "    'momentum': {\n",
    "        'name': 'Strong Momentum',\n",
    "        'logic': 'momentum > threshold AND macd_rising AND bounce_signal',\n",
    "        'params': {'momentum_threshold': [0, 15, 5]},\n",
    "        'hypothesis': 'Ride strong momentum with confirmation'\n",
    "    },\n",
    "    'trend': {\n",
    "        'name': 'Trend Following',\n",
    "        'logic': 'trend_align > threshold AND ribbon_bullish',\n",
    "        'params': {'trend_threshold': [0.3, 0.8, 0.5]},\n",
    "        'hypothesis': 'Follow established trends'\n",
    "    },\n",
    "    'rsi_divergence': {\n",
    "        'name': 'RSI Divergence',\n",
    "        'logic': 'price_low BUT rsi_higher (bullish divergence)',\n",
    "        'params': {'divergence_sensitivity': [0.5, 2.0, 1.0]},\n",
    "        'hypothesis': 'RSI showing strength when price weak'\n",
    "    },\n",
    "    'vol_squeeze': {\n",
    "        'name': 'Volatility Squeeze Breakout',\n",
    "        'logic': 'low_volatility AND volume_spike',\n",
    "        'params': {'vol_threshold': [1.5, 4.0, 2.5]},\n",
    "        'hypothesis': 'Low vol followed by breakout'\n",
    "    },\n",
    "    'consolidation': {\n",
    "        'name': 'Consolidation Breakout',\n",
    "        'logic': 'tight_range AND momentum_increasing',\n",
    "        'params': {'range_threshold': [0.02, 0.10, 0.05]},\n",
    "        'hypothesis': 'Breaking out of consolidation'\n",
    "    },\n",
    "    'uptrend_pullback': {\n",
    "        'name': 'Uptrend Pullback',\n",
    "        'logic': 'uptrend AND short_term_pullback',\n",
    "        'params': {'pullback_threshold': [0.02, 0.08, 0.04]},\n",
    "        'hypothesis': 'Buy dips in uptrends'\n",
    "    }\n",
    "}\n",
    "\n",
    "print(f\"‚úÖ Config loaded: {len(CONFIG['watchlist'])} tickers, {len(SIGNAL_DEFINITIONS)} signals to test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7addf7",
   "metadata": {},
   "source": [
    "## üì• Data Loading & Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678e6ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === LOAD DATA ===\n",
    "print(\"üì• Loading market data...\")\n",
    "data_dict = {}\n",
    "for ticker in CONFIG['watchlist']:\n",
    "    try:\n",
    "        df = yf.download(ticker, period='2y', progress=False)\n",
    "        if isinstance(df.columns, pd.MultiIndex):\n",
    "            df.columns = df.columns.get_level_values(0)\n",
    "        df = df.reset_index()\n",
    "        for col in ['Open', 'High', 'Low', 'Close', 'Volume']:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        if len(df) > 100:\n",
    "            data_dict[ticker] = df\n",
    "            print(f\"   ‚úì {ticker}: {len(df)} days\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚úó {ticker}: {e}\")\n",
    "\n",
    "# Split train/val/test (50/25/25)\n",
    "train_data, val_data, test_data = {}, {}, {}\n",
    "for ticker, df in data_dict.items():\n",
    "    n = len(df)\n",
    "    split1 = int(n * 0.5)\n",
    "    split2 = int(n * 0.75)\n",
    "    train_data[ticker] = df.iloc[:split1].reset_index(drop=True)\n",
    "    val_data[ticker] = df.iloc[split1:split2].reset_index(drop=True)\n",
    "    test_data[ticker] = df.iloc[split2:].reset_index(drop=True)\n",
    "\n",
    "print(f\"\\n‚úÖ Loaded {len(data_dict)} tickers\")\n",
    "print(f\"   Train: {len(train_data[list(train_data.keys())[0]])} days\")\n",
    "print(f\"   Val: {len(val_data[list(val_data.keys())[0]])} days\")\n",
    "print(f\"   Test: {len(test_data[list(test_data.keys())[0]])} days\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8dfebc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === COMPREHENSIVE FEATURE ENGINE ===\n",
    "def compute_features(df):\n",
    "    \"\"\"Extract ALL features needed for signal testing\"\"\"\n",
    "    df = df.copy()\n",
    "    c = df['Close'].astype(float)\n",
    "    h, l, v = df['High'].astype(float), df['Low'].astype(float), df['Volume'].astype(float)\n",
    "    \n",
    "    # Returns\n",
    "    for p in [1, 5, 10, 21]: df[f'ret_{p}d'] = c.pct_change(p) * 100\n",
    "    \n",
    "    # EMAs\n",
    "    for p in [8, 13, 21, 34, 55]: df[f'ema_{p}'] = c.ewm(span=p).mean()\n",
    "    df['ema_8_rising'] = (df['ema_8'] > df['ema_8'].shift(3)).astype(float)\n",
    "    \n",
    "    # Ribbon\n",
    "    df['ribbon_bullish'] = ((df['ema_8'] > df['ema_13']) & (df['ema_13'] > df['ema_21'])).astype(float)\n",
    "    df['ribbon_range'] = (df[['ema_8','ema_13','ema_21']].max(axis=1) - df[['ema_8','ema_13','ema_21']].min(axis=1)) / c * 100\n",
    "    df['ribbon_tight'] = (df['ribbon_range'] < 3).astype(float)\n",
    "    \n",
    "    # RSI\n",
    "    delta = c.diff()\n",
    "    gain = delta.where(delta > 0, 0).rolling(14).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(14).mean()\n",
    "    df['rsi'] = 100 - (100 / (1 + gain / (loss + 1e-10)))\n",
    "    \n",
    "    # MACD\n",
    "    df['macd'] = c.ewm(span=12).mean() - c.ewm(span=26).mean()\n",
    "    df['macd_signal'] = df['macd'].ewm(span=9).mean()\n",
    "    df['macd_rising'] = (df['macd'] > df['macd_signal']).astype(float)\n",
    "    \n",
    "    # Volume\n",
    "    df['vol_ratio'] = v / (v.rolling(20).mean() + 1)\n",
    "    df['vol_spike'] = (df['vol_ratio'] > 2).astype(float)\n",
    "    \n",
    "    # Momentum\n",
    "    df['mom_5d'] = c.pct_change(5) * 100\n",
    "    df['mom_accel'] = df['mom_5d'] - df['mom_5d'].shift(3)\n",
    "    \n",
    "    # Bounce\n",
    "    df['low_5d'] = l.rolling(5).min()\n",
    "    df['bounce'] = (c / (df['low_5d'] + 1e-10) - 1) * 100\n",
    "    df['bounce_signal'] = ((df['bounce'] > 3) & (df['ema_8_rising'] > 0)).astype(float)\n",
    "    \n",
    "    # Trend\n",
    "    df['trend_align'] = (np.sign(df['ret_5d']) + np.sign(df['ret_10d']) + np.sign(df['ret_21d'])) / 3\n",
    "    \n",
    "    # RSI Divergence\n",
    "    df['price_low_5d'] = c.rolling(5).min()\n",
    "    df['rsi_at_low'] = df['rsi'].rolling(5).min()\n",
    "    df['rsi_divergence'] = ((c <= df['price_low_5d'] * 1.02) & (df['rsi'] > df['rsi_at_low'] + 5)).astype(float)\n",
    "    \n",
    "    # Volatility\n",
    "    df['atr'] = (h - l).rolling(14).mean()\n",
    "    df['atr_pct'] = df['atr'] / c * 100\n",
    "    df['vol_squeeze'] = (df['atr_pct'] < df['atr_pct'].rolling(50).mean() * 0.7).astype(float)\n",
    "    \n",
    "    # Consolidation\n",
    "    df['range_10d'] = (h.rolling(10).max() - l.rolling(10).min()) / c * 100\n",
    "    df['consolidating'] = (df['range_10d'] < df['range_10d'].rolling(30).mean() * 0.6).astype(float)\n",
    "    \n",
    "    # Uptrend structure\n",
    "    df['higher_low'] = (l > l.shift(5)).astype(float)\n",
    "    df['higher_high'] = (h > h.shift(5)).astype(float)\n",
    "    df['uptrend'] = (df['higher_low'] + df['higher_high']) / 2\n",
    "    \n",
    "    # Market regime classification\n",
    "    df['regime_bull'] = ((df['ret_21d'] > 5) & (df['ribbon_bullish'] > 0)).astype(float)\n",
    "    df['regime_bear'] = ((df['ret_21d'] < -5) & (df['ribbon_bullish'] == 0)).astype(float)\n",
    "    df['regime_sideways'] = ((abs(df['ret_21d']) < 5)).astype(float)\n",
    "    \n",
    "    return df.replace([np.inf, -np.inf], np.nan).ffill().bfill().fillna(0)\n",
    "\n",
    "print(\"üß† Computing comprehensive features...\")\n",
    "train_features = {t: compute_features(df) for t, df in train_data.items()}\n",
    "val_features = {t: compute_features(df) for t, df in val_data.items()}\n",
    "test_features = {t: compute_features(df) for t, df in test_data.items()}\n",
    "print(f\"‚úÖ Features ready: {len(train_features[list(train_features.keys())[0]].columns)} total features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ca537c",
   "metadata": {},
   "source": [
    "## üî¨ PHASE 1: Independent Signal Testing\n",
    "\n",
    "Test each signal **independently** to see if it works on its own.\n",
    "\n",
    "**Key Question:** Does this signal generate profitable trades when used alone?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520c92c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === PHASE 1: TEST EACH SIGNAL INDEPENDENTLY ===\n",
    "\n",
    "def test_single_signal(signal_name, signal_def, features_dict, data_dict, params=None):\n",
    "    \"\"\"\n",
    "    Test a SINGLE signal in isolation.\n",
    "    Returns: performance metrics + trade log\n",
    "    \"\"\"\n",
    "    if params is None:\n",
    "        params = {k: v[2] for k, v in signal_def.get('params', {}).items()}  # Use defaults\n",
    "    \n",
    "    trades = []\n",
    "    balance = 100000\n",
    "    positions = {}\n",
    "    \n",
    "    for ticker in features_dict.keys():\n",
    "        df_feat = features_dict[ticker]\n",
    "        df_price = data_dict[ticker]\n",
    "        \n",
    "        for i in range(60, len(df_feat) - 1):\n",
    "            price = df_price['Close'].iloc[i]\n",
    "            \n",
    "            # Check exits first\n",
    "            if ticker in positions:\n",
    "                entry_price = positions[ticker]['entry']\n",
    "                days_held = positions[ticker]['days']\n",
    "                positions[ticker]['days'] += 1\n",
    "                \n",
    "                pnl_pct = (price / entry_price - 1) * 100\n",
    "                \n",
    "                # Simple exit rules\n",
    "                exit = False\n",
    "                if pnl_pct >= 20: exit = True  # Take profit\n",
    "                elif pnl_pct <= -10: exit = True  # Stop loss\n",
    "                elif days_held > 30: exit = True  # Time stop\n",
    "                \n",
    "                if exit:\n",
    "                    balance += positions[ticker]['shares'] * price\n",
    "                    trades.append({\n",
    "                        'signal': signal_name,\n",
    "                        'ticker': ticker,\n",
    "                        'pnl_pct': pnl_pct,\n",
    "                        'days': days_held,\n",
    "                        'exit_reason': 'profit' if pnl_pct > 0 else 'loss'\n",
    "                    })\n",
    "                    del positions[ticker]\n",
    "                continue\n",
    "            \n",
    "            # Check entry signal\n",
    "            if balance < 1000 or ticker in positions:\n",
    "                continue\n",
    "            \n",
    "            entry_signal = False\n",
    "            \n",
    "            # === SIGNAL-SPECIFIC LOGIC ===\n",
    "            if signal_name == 'dip_buy':\n",
    "                rsi = df_feat['rsi'].iloc[i]\n",
    "                mom = df_feat['mom_5d'].iloc[i]\n",
    "                entry_signal = (rsi < params.get('rsi_threshold', 30)) and (mom < -3)\n",
    "            \n",
    "            elif signal_name == 'bounce':\n",
    "                bounce = df_feat['bounce'].iloc[i]\n",
    "                macd_rising = df_feat['macd_rising'].iloc[i]\n",
    "                entry_signal = (bounce > params.get('bounce_threshold', 8)) and (macd_rising > 0)\n",
    "            \n",
    "            elif signal_name == 'nuclear_dip':\n",
    "                ret21 = df_feat['ret_21d'].iloc[i]\n",
    "                macd_rising = df_feat['macd_rising'].iloc[i]\n",
    "                entry_signal = (ret21 < params.get('dip_threshold', -10)) and (macd_rising > 0)\n",
    "            \n",
    "            elif signal_name == 'momentum':\n",
    "                mom = df_feat['mom_5d'].iloc[i]\n",
    "                macd_rising = df_feat['macd_rising'].iloc[i]\n",
    "                bounce_sig = df_feat['bounce_signal'].iloc[i]\n",
    "                entry_signal = (mom > params.get('momentum_threshold', 5)) and (macd_rising > 0) and (bounce_sig > 0)\n",
    "            \n",
    "            elif signal_name == 'trend':\n",
    "                trend = df_feat['trend_align'].iloc[i]\n",
    "                ribbon = df_feat['ribbon_bullish'].iloc[i]\n",
    "                entry_signal = (trend > params.get('trend_threshold', 0.5)) and (ribbon > 0)\n",
    "            \n",
    "            elif signal_name == 'rsi_divergence':\n",
    "                rsi_div = df_feat['rsi_divergence'].iloc[i]\n",
    "                macd_rising = df_feat['macd_rising'].iloc[i]\n",
    "                entry_signal = (rsi_div > 0) and (macd_rising > 0)\n",
    "            \n",
    "            elif signal_name == 'vol_squeeze':\n",
    "                vol_sq = df_feat['vol_squeeze'].iloc[i]\n",
    "                vol_spike = df_feat['vol_spike'].iloc[i]\n",
    "                mom = df_feat['mom_5d'].iloc[i]\n",
    "                entry_signal = (vol_sq > 0) and (vol_spike > 0) and (mom > 0)\n",
    "            \n",
    "            elif signal_name == 'consolidation':\n",
    "                consol = df_feat['consolidating'].iloc[i]\n",
    "                mom = df_feat['mom_5d'].iloc[i]\n",
    "                ribbon = df_feat['ribbon_bullish'].iloc[i]\n",
    "                entry_signal = (consol > 0) and (mom > params.get('momentum_threshold', 3)) and (ribbon > 0)\n",
    "            \n",
    "            elif signal_name == 'uptrend_pullback':\n",
    "                uptrend = df_feat['uptrend'].iloc[i]\n",
    "                rsi = df_feat['rsi'].iloc[i]\n",
    "                entry_signal = (uptrend > 0.5) and (35 < rsi < 50)  # Pullback in uptrend\n",
    "            \n",
    "            # Execute entry\n",
    "            if entry_signal:\n",
    "                shares = int(balance * 0.20 / price)  # 20% position size\n",
    "                if shares > 0:\n",
    "                    balance -= shares * price\n",
    "                    positions[ticker] = {'entry': price, 'shares': shares, 'days': 0}\n",
    "    \n",
    "    # Calculate metrics\n",
    "    if len(trades) == 0:\n",
    "        return {'trades': 0, 'win_rate': 0, 'avg_pnl': 0, 'total_pnl': 0, 'status': 'NO_TRADES'}\n",
    "    \n",
    "    wins = len([t for t in trades if t['pnl_pct'] > 0])\n",
    "    win_rate = wins / len(trades) * 100\n",
    "    avg_pnl = np.mean([t['pnl_pct'] for t in trades])\n",
    "    total_pnl = np.sum([t['pnl_pct'] for t in trades])\n",
    "    \n",
    "    return {\n",
    "        'signal': signal_name,\n",
    "        'trades': len(trades),\n",
    "        'wins': wins,\n",
    "        'win_rate': win_rate,\n",
    "        'avg_pnl': avg_pnl,\n",
    "        'total_pnl': total_pnl,\n",
    "        'trade_log': trades,\n",
    "        'status': 'VALID'\n",
    "    }\n",
    "\n",
    "# === RUN PHASE 1 ===\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üî¨ PHASE 1: INDEPENDENT SIGNAL TESTING\")\n",
    "print(\"=\"*70)\n",
    "print(\"Testing each signal alone to see if it works...\\n\")\n",
    "\n",
    "phase1_results = {}\n",
    "for signal_name, signal_def in SIGNAL_DEFINITIONS.items():\n",
    "    print(f\"Testing: {signal_def['name']}...\")\n",
    "    result = test_single_signal(signal_name, signal_def, val_features, val_data)\n",
    "    phase1_results[signal_name] = result\n",
    "    \n",
    "    if result['trades'] >= CONFIG['min_trades']:\n",
    "        status = \"‚úÖ\" if result['win_rate'] >= CONFIG['min_win_rate'] and result['avg_pnl'] > 0 else \"‚ö†Ô∏è\"\n",
    "        print(f\"   {status} Trades: {result['trades']:3d} | Win Rate: {result['win_rate']:5.1f}% | Avg PnL: {result['avg_pnl']:+6.2f}%\")\n",
    "    else:\n",
    "        print(f\"   ‚ùå Only {result['trades']} trades - INSUFFICIENT DATA\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìä PHASE 1 SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Sort by avg PnL\n",
    "valid_signals = {k: v for k, v in phase1_results.items() if v['trades'] >= CONFIG['min_trades']}\n",
    "sorted_signals = sorted(valid_signals.items(), key=lambda x: x[1]['avg_pnl'], reverse=True)\n",
    "\n",
    "print(f\"\\n{'Rank':<6} {'Signal':<25} {'Trades':>8} {'Win%':>8} {'Avg PnL':>10} {'Status':>10}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for rank, (name, result) in enumerate(sorted_signals, 1):\n",
    "    wr = result['win_rate']\n",
    "    pnl = result['avg_pnl']\n",
    "    \n",
    "    if wr >= CONFIG['min_win_rate'] and pnl > 0:\n",
    "        status = \"‚úÖ USE\"\n",
    "    elif wr >= 50 and pnl > -1:\n",
    "        status = \"‚ö†Ô∏è OK\"\n",
    "    else:\n",
    "        status = \"‚ùå DROP\"\n",
    "    \n",
    "    print(f\"{rank:<6} {SIGNAL_DEFINITIONS[name]['name']:<25} {result['trades']:>8} {wr:>7.1f}% {pnl:>+9.2f}% {status:>10}\")\n",
    "\n",
    "# Signals that never fired\n",
    "zero_trade_signals = [k for k, v in phase1_results.items() if v['trades'] == 0]\n",
    "if zero_trade_signals:\n",
    "    print(f\"\\n‚ùå SIGNALS THAT NEVER FIRE (0 trades): {', '.join(zero_trade_signals)}\")\n",
    "\n",
    "print(\"\\nüí° INTERPRETATION:\")\n",
    "print(\"   - Signals marked ‚ùå DROP should be disabled in your code\")\n",
    "print(\"   - Signals marked ‚úÖ USE are your core moneymakers\")\n",
    "print(\"   - Signals with 0 trades have logic errors or impossible conditions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28964fac",
   "metadata": {},
   "source": [
    "## üß¨ PHASE 2: DoCL - Dynamics-Optimized Curriculum Learning\n",
    "\n",
    "**Goal:** Discover which patterns are MOST INFORMATIVE for learning.\n",
    "\n",
    "**Method:** Score each trade by: `residual √ó gradient √ó novelty`\n",
    "\n",
    "High scores = patterns that teach the model the most."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba435c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === PHASE 2: DYNAMICS-OPTIMIZED CURRICULUM LEARNING (DoCL) ===\n",
    "\n",
    "class DoCLAnalyzer:\n",
    "    \"\"\"Analyzes which patterns are most informative for learning\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.pattern_scores = defaultdict(list)\n",
    "        self.seen_patterns = set()\n",
    "    \n",
    "    def compute_pattern_signature(self, features, idx):\n",
    "        \"\"\"Create unique signature for pattern\"\"\"\n",
    "        # Discretize features into buckets\n",
    "        rsi_bucket = int(features['rsi'].iloc[idx] / 10)\n",
    "        mom_bucket = int(features['mom_5d'].iloc[idx] / 5)\n",
    "        trend_bucket = int((features['trend_align'].iloc[idx] + 1) * 2)  # -1 to 1 ‚Üí 0 to 4\n",
    "        return f\"rsi{rsi_bucket}_mom{mom_bucket}_trend{trend_bucket}\"\n",
    "    \n",
    "    def compute_novelty(self, signature):\n",
    "        \"\"\"How novel is this pattern?\"\"\"\n",
    "        if signature not in self.seen_patterns:\n",
    "            self.seen_patterns.add(signature)\n",
    "            return 1.0  # Completely novel\n",
    "        else:\n",
    "            # Less novel each time we see it\n",
    "            count = len([s for s in self.seen_patterns if s == signature])\n",
    "            return 1.0 / (1 + count * 0.1)\n",
    "    \n",
    "    def compute_docl_score(self, residual, gradient_mag, novelty):\n",
    "        \"\"\"DoCL Score = how much this pattern helps learning\"\"\"\n",
    "        return abs(residual) * gradient_mag * novelty\n",
    "    \n",
    "    def analyze_trades(self, trade_log, features_dict):\n",
    "        \"\"\"Analyze which trades were most informative\"\"\"\n",
    "        scored_trades = []\n",
    "        \n",
    "        for trade in trade_log:\n",
    "            ticker = trade['ticker']\n",
    "            # Simulate: residual = how unexpected was the outcome\n",
    "            # If we expected 5% but got 15%, residual = 10%\n",
    "            expected_pnl = 5.0  # Baseline expectation\n",
    "            residual = abs(trade['pnl_pct'] - expected_pnl)\n",
    "            \n",
    "            # Gradient magnitude = how much correction is needed\n",
    "            gradient_mag = abs(trade['pnl_pct']) / 20.0  # Normalize\n",
    "            \n",
    "            # Novelty\n",
    "            # signature = self.compute_pattern_signature(features_dict[ticker], trade_idx)\n",
    "            # novelty = self.compute_novelty(signature)\n",
    "            novelty = random.uniform(0.5, 1.0)  # Simplified for now\n",
    "            \n",
    "            docl_score = self.compute_docl_score(residual, gradient_mag, novelty)\n",
    "            \n",
    "            scored_trades.append({\n",
    "                **trade,\n",
    "                'docl_score': docl_score,\n",
    "                'residual': residual,\n",
    "                'novelty': novelty\n",
    "            })\n",
    "        \n",
    "        return sorted(scored_trades, key=lambda x: x['docl_score'], reverse=True)\n",
    "\n",
    "# === RUN PHASE 2 ===\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üß¨ PHASE 2: DOCL - PATTERN INFORMATIVENESS ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "print(\"Analyzing which patterns teach the model the most...\\n\")\n",
    "\n",
    "docl_analyzer = DoCLAnalyzer()\n",
    "\n",
    "for signal_name, result in phase1_results.items():\n",
    "    if result['trades'] < 5:\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\nSignal: {SIGNAL_DEFINITIONS[signal_name]['name']}\")\n",
    "    scored_trades = docl_analyzer.analyze_trades(result['trade_log'], val_features)\n",
    "    \n",
    "    # Show top 5 most informative trades\n",
    "    print(f\"   Top 5 Most Informative Trades:\")\n",
    "    for i, trade in enumerate(scored_trades[:5], 1):\n",
    "        print(f\"   {i}. {trade['ticker']:6s} | PnL: {trade['pnl_pct']:+6.2f}% | DoCL Score: {trade['docl_score']:.3f}\")\n",
    "\n",
    "print(\"\\nüí° INSIGHT:\")\n",
    "print(\"   - High DoCL scores = unexpected outcomes that teach the model new patterns\")\n",
    "print(\"   - These are the trades to focus on when improving your strategy\")\n",
    "print(\"   - Low novelty trades are redundant - model already knows this pattern\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc31adc",
   "metadata": {},
   "source": [
    "## üéØ PHASE 3: DIH - Dynamic Instance Hardness\n",
    "\n",
    "**Goal:** Identify patterns that are consistently HARD to learn.\n",
    "\n",
    "**Method:** Track which patterns have high historical loss.\n",
    "\n",
    "**Result:** Focus training on hard patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a019523a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === PHASE 3: DYNAMIC INSTANCE HARDNESS (DIH) ===\n",
    "\n",
    "class DIHTracker:\n",
    "    \"\"\"Tracks which patterns are hardest to learn\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.pattern_losses = defaultdict(list)\n",
    "        self.gradient_momentum = defaultdict(float)\n",
    "    \n",
    "    def update(self, pattern_id, loss):\n",
    "        \"\"\"Update loss history for pattern\"\"\"\n",
    "        self.pattern_losses[pattern_id].append(loss)\n",
    "        \n",
    "        # Gradient momentum: is learning stable or erratic?\n",
    "        if len(self.pattern_losses[pattern_id]) > 1:\n",
    "            prev_loss = self.pattern_losses[pattern_id][-2]\n",
    "            gradient = loss - prev_loss\n",
    "            self.gradient_momentum[pattern_id] = (\n",
    "                0.9 * self.gradient_momentum[pattern_id] + 0.1 * gradient\n",
    "            )\n",
    "    \n",
    "    def get_dih(self, pattern_id):\n",
    "        \"\"\"Compute DIH score = avg loss + instability\"\"\"\n",
    "        if pattern_id not in self.pattern_losses:\n",
    "            return 0\n",
    "        \n",
    "        recent_losses = self.pattern_losses[pattern_id][-20:]  # Last 20 observations\n",
    "        avg_loss = np.mean(recent_losses)\n",
    "        instability = abs(self.gradient_momentum[pattern_id])\n",
    "        \n",
    "        return avg_loss + instability\n",
    "    \n",
    "    def get_hardest_patterns(self, top_k=10):\n",
    "        \"\"\"Return patterns with highest DIH\"\"\"\n",
    "        all_dihs = [(pid, self.get_dih(pid)) for pid in self.pattern_losses.keys()]\n",
    "        return sorted(all_dihs, key=lambda x: x[1], reverse=True)[:top_k]\n",
    "\n",
    "# === SIMULATE DIH TRACKING ===\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üéØ PHASE 3: DIH - DYNAMIC INSTANCE HARDNESS\")\n",
    "print(\"=\"*70)\n",
    "print(\"Identifying patterns that are consistently hard to learn...\\n\")\n",
    "\n",
    "dih_tracker = DIHTracker()\n",
    "\n",
    "# Simulate learning history\n",
    "for signal_name, result in phase1_results.items():\n",
    "    if result['trades'] < 5:\n",
    "        continue\n",
    "    \n",
    "    for trade in result['trade_log']:\n",
    "        pattern_id = f\"{signal_name}_{trade['ticker']}\"\n",
    "        # Loss = absolute deviation from expected\n",
    "        expected = 5.0\n",
    "        loss = abs(trade['pnl_pct'] - expected)\n",
    "        dih_tracker.update(pattern_id, loss)\n",
    "\n",
    "# Show hardest patterns\n",
    "hardest = dih_tracker.get_hardest_patterns(top_k=15)\n",
    "\n",
    "print(f\"{'Rank':<6} {'Pattern':<30} {'DIH Score':>12} {'Status':>15}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for rank, (pattern_id, dih_score) in enumerate(hardest, 1):\n",
    "    if dih_score > 10:\n",
    "        status = \"‚ö†Ô∏è VERY HARD\"\n",
    "    elif dih_score > 5:\n",
    "        status = \"üî¥ HARD\"\n",
    "    else:\n",
    "        status = \"üü° MODERATE\"\n",
    "    \n",
    "    print(f\"{rank:<6} {pattern_id:<30} {dih_score:>12.2f} {status:>15}\")\n",
    "\n",
    "print(\"\\nüí° RECOMMENDATION:\")\n",
    "print(\"   - High DIH patterns need more training focus\")\n",
    "print(\"   - These are where your model struggles most\")\n",
    "print(\"   - Consider: Are these patterns truly predictive, or just noisy?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a07538",
   "metadata": {},
   "source": [
    "## ‚öîÔ∏è PHASE 4: Adversarial Robustness Testing\n",
    "\n",
    "**Goal:** Test if signals work when data is corrupted/manipulated.\n",
    "\n",
    "**Method:** Add noise, outliers, temporal jitter to features.\n",
    "\n",
    "**Result:** Identify which signals are ROBUST vs FRAGILE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7abf7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === PHASE 4: ADVERSARIAL ROBUSTNESS TESTING ===\n",
    "\n",
    "def inject_noise(features, noise_type='gaussian', intensity=0.1):\n",
    "    \"\"\"Corrupt features to test robustness\"\"\"\n",
    "    corrupted = features.copy()\n",
    "    \n",
    "    if noise_type == 'gaussian':\n",
    "        # Add Gaussian noise to all numeric columns\n",
    "        for col in ['rsi', 'mom_5d', 'ret_21d', 'bounce']:\n",
    "            if col in corrupted.columns:\n",
    "                noise = np.random.randn(len(corrupted)) * intensity * corrupted[col].std()\n",
    "                corrupted[col] = corrupted[col] + noise\n",
    "    \n",
    "    elif noise_type == 'outliers':\n",
    "        # Inject random outliers\n",
    "        for col in ['rsi', 'mom_5d', 'ret_21d']:\n",
    "            if col in corrupted.columns:\n",
    "                n_outliers = int(len(corrupted) * intensity)\n",
    "                outlier_indices = np.random.choice(len(corrupted), n_outliers, replace=False)\n",
    "                corrupted.loc[corrupted.index[outlier_indices], col] *= np.random.uniform(0.5, 2.0, n_outliers)\n",
    "    \n",
    "    elif noise_type == 'jitter':\n",
    "        # Temporal misalignment\n",
    "        shift = int(len(corrupted) * intensity * 0.05)  # Small shift\n",
    "        for col in ['rsi', 'mom_5d']:\n",
    "            if col in corrupted.columns:\n",
    "                corrupted[col] = corrupted[col].shift(shift).fillna(method='bfill')\n",
    "    \n",
    "    return corrupted\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚öîÔ∏è PHASE 4: ADVERSARIAL ROBUSTNESS TESTING\")\n",
    "print(\"=\"*70)\n",
    "print(\"Testing how signals perform with corrupted/manipulated data...\\n\")\n",
    "\n",
    "noise_types = ['gaussian', 'outliers', 'jitter']\n",
    "adversarial_results = {}\n",
    "\n",
    "for noise_type in noise_types:\n",
    "    print(f\"\\nüî¨ Testing with {noise_type.upper()} noise...\")\n",
    "    \n",
    "    # Corrupt features\n",
    "    corrupted_features = {}\n",
    "    for ticker, feat in val_features.items():\n",
    "        corrupted_features[ticker] = inject_noise(feat, noise_type=noise_type, intensity=0.15)\n",
    "    \n",
    "    # Test top 3 signals\n",
    "    top_signals = sorted_signals[:3]\n",
    "    \n",
    "    for signal_name, orig_result in top_signals:\n",
    "        signal_def = SIGNAL_DEFINITIONS[signal_name]\n",
    "        \n",
    "        # Test with corrupted data\n",
    "        corrupted_result = test_single_signal(signal_name, signal_def, corrupted_features, val_data)\n",
    "        \n",
    "        if corrupted_result['trades'] >= 5:\n",
    "            orig_wr = orig_result['win_rate']\n",
    "            corrupt_wr = corrupted_result['win_rate']\n",
    "            degradation = orig_wr - corrupt_wr\n",
    "            \n",
    "            if degradation < 5:\n",
    "                status = \"‚úÖ ROBUST\"\n",
    "            elif degradation < 15:\n",
    "                status = \"‚ö†Ô∏è MODERATE\"\n",
    "            else:\n",
    "                status = \"‚ùå FRAGILE\"\n",
    "            \n",
    "            print(f\"   {signal_def['name']:<25} | Original WR: {orig_wr:5.1f}% | Corrupted WR: {corrupt_wr:5.1f}% | {status}\")\n",
    "            \n",
    "            if signal_name not in adversarial_results:\n",
    "                adversarial_results[signal_name] = []\n",
    "            adversarial_results[signal_name].append({\n",
    "                'noise_type': noise_type,\n",
    "                'degradation': degradation,\n",
    "                'status': status\n",
    "            })\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìä ADVERSARIAL ROBUSTNESS SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for signal_name, tests in adversarial_results.items():\n",
    "    avg_degradation = np.mean([t['degradation'] for t in tests])\n",
    "    robust_count = len([t for t in tests if 'ROBUST' in t['status']])\n",
    "    \n",
    "    print(f\"\\n{SIGNAL_DEFINITIONS[signal_name]['name']}:\")\n",
    "    print(f\"   Avg degradation: {avg_degradation:.1f}%\")\n",
    "    print(f\"   Robust in {robust_count}/{len(tests)} tests\")\n",
    "    \n",
    "    if avg_degradation < 10 and robust_count >= 2:\n",
    "        print(f\"   ‚úÖ HIGHLY ROBUST - Works even with corrupted data\")\n",
    "    elif avg_degradation < 20:\n",
    "        print(f\"   ‚ö†Ô∏è MODERATELY ROBUST - Some sensitivity to noise\")\n",
    "    else:\n",
    "        print(f\"   ‚ùå FRAGILE - Breaks down with noisy data\")\n",
    "\n",
    "print(\"\\nüí° INSIGHT:\")\n",
    "print(\"   - Robust signals work in real-world noisy conditions\")\n",
    "print(\"   - Fragile signals may be overfitting to clean historical data\")\n",
    "print(\"   - Consider adding noise tolerance to fragile signals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6e76a4",
   "metadata": {},
   "source": [
    "## üéØ FINAL RECOMMENDATIONS\n",
    "\n",
    "Based on all testing phases, generate concrete code recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83ebd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === PHASE 6: SIGNAL COMBINATION DISCOVERY ===\n",
    "\n",
    "def test_signal_combination(signals, features_dict, data_dict):\n",
    "    \"\"\"Test multiple signals working together\"\"\"\n",
    "    trades = []\n",
    "    balance = 100000\n",
    "    positions = {}\n",
    "    \n",
    "    for ticker in features_dict.keys():\n",
    "        df_feat = features_dict[ticker]\n",
    "        df_price = data_dict[ticker]\n",
    "        \n",
    "        for i in range(60, len(df_feat) - 1):\n",
    "            price = df_price['Close'].iloc[i]\n",
    "            \n",
    "            # Exit logic (same as before)\n",
    "            if ticker in positions:\n",
    "                entry_price = positions[ticker]['entry']\n",
    "                days_held = positions[ticker]['days']\n",
    "                positions[ticker]['days'] += 1\n",
    "                pnl_pct = (price / entry_price - 1) * 100\n",
    "                \n",
    "                exit = False\n",
    "                if pnl_pct >= 20: exit = True\n",
    "                elif pnl_pct <= -10: exit = True\n",
    "                elif days_held > 30: exit = True\n",
    "                \n",
    "                if exit:\n",
    "                    balance += positions[ticker]['shares'] * price\n",
    "                    trades.append({'ticker': ticker, 'pnl_pct': pnl_pct, 'days': days_held})\n",
    "                    del positions[ticker]\n",
    "                continue\n",
    "            \n",
    "            # Entry: ANY of the signals can trigger\n",
    "            if balance < 1000 or ticker in positions:\n",
    "                continue\n",
    "            \n",
    "            entry_signal = False\n",
    "            triggered_by = None\n",
    "            \n",
    "            for signal_name in signals:\n",
    "                # Simplified: reuse logic from test_single_signal\n",
    "                if signal_name == 'trend':\n",
    "                    if df_feat['trend_align'].iloc[i] > 0.5 and df_feat['ribbon_bullish'].iloc[i] > 0:\n",
    "                        entry_signal = True\n",
    "                        triggered_by = signal_name\n",
    "                        break\n",
    "                elif signal_name == 'momentum':\n",
    "                    if df_feat['mom_5d'].iloc[i] > 5 and df_feat['macd_rising'].iloc[i] > 0:\n",
    "                        entry_signal = True\n",
    "                        triggered_by = signal_name\n",
    "                        break\n",
    "                elif signal_name == 'nuclear_dip':\n",
    "                    if df_feat['ret_21d'].iloc[i] < -10 and df_feat['macd_rising'].iloc[i] > 0:\n",
    "                        entry_signal = True\n",
    "                        triggered_by = signal_name\n",
    "                        break\n",
    "            \n",
    "            if entry_signal:\n",
    "                shares = int(balance * 0.20 / price)\n",
    "                if shares > 0:\n",
    "                    balance -= shares * price\n",
    "                    positions[ticker] = {'entry': price, 'shares': shares, 'days': 0}\n",
    "    \n",
    "    if len(trades) == 0:\n",
    "        return {'trades': 0, 'win_rate': 0, 'avg_pnl': 0}\n",
    "    \n",
    "    wins = len([t for t in trades if t['pnl_pct'] > 0])\n",
    "    return {\n",
    "        'trades': len(trades),\n",
    "        'win_rate': wins / len(trades) * 100,\n",
    "        'avg_pnl': np.mean([t['pnl_pct'] for t in trades]),\n",
    "        'total_pnl': np.sum([t['pnl_pct'] for t in trades])\n",
    "    }\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üîó PHASE 6: SIGNAL COMBINATION DISCOVERY\")\n",
    "print(\"=\"*70)\n",
    "print(\"Testing which signal pairs work best together...\\n\")\n",
    "\n",
    "# Test top 3 signals in combinations\n",
    "top_3 = [name for name, _ in sorted_signals[:3]]\n",
    "\n",
    "print(f\"Top 3 signals to test: {', '.join([SIGNAL_DEFINITIONS[s]['name'] for s in top_3])}\\n\")\n",
    "\n",
    "combo_results = {}\n",
    "\n",
    "# Test individual signals first (baseline)\n",
    "for signal in top_3:\n",
    "    result = test_signal_combination([signal], val_features, val_data)\n",
    "    combo_results[signal] = result\n",
    "    print(f\"Solo - {SIGNAL_DEFINITIONS[signal]['name']:<25} | Trades: {result['trades']:3d} | WR: {result['win_rate']:5.1f}% | Avg PnL: {result['avg_pnl']:+6.2f}%\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "\n",
    "# Test pairs\n",
    "from itertools import combinations\n",
    "for pair in combinations(top_3, 2):\n",
    "    combo_name = f\"{pair[0]}+{pair[1]}\"\n",
    "    result = test_signal_combination(list(pair), val_features, val_data)\n",
    "    combo_results[combo_name] = result\n",
    "    pair_names = ' + '.join([SIGNAL_DEFINITIONS[s]['name'] for s in pair])\n",
    "    print(f\"Pair - {pair_names:<43} | Trades: {result['trades']:3d} | WR: {result['win_rate']:5.1f}% | Avg PnL: {result['avg_pnl']:+6.2f}%\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "\n",
    "# Test all 3 together\n",
    "result_all = test_signal_combination(top_3, val_features, val_data)\n",
    "combo_results['all_3'] = result_all\n",
    "all_names = ' + '.join([SIGNAL_DEFINITIONS[s]['name'] for s in top_3])\n",
    "print(f\"All 3 - {all_names:<41} | Trades: {result_all['trades']:3d} | WR: {result_all['win_rate']:5.1f}% | Avg PnL: {result_all['avg_pnl']:+6.2f}%\")\n",
    "\n",
    "print(\"\\nüí° RECOMMENDATION:\")\n",
    "best_combo = max(combo_results.items(), key=lambda x: x[1]['avg_pnl'])\n",
    "print(f\"   Best combination: {best_combo[0]} with {best_combo[1]['avg_pnl']:+.2f}% avg PnL\")\n",
    "print(f\"   Use this in your backtest for optimal performance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcca5d9f",
   "metadata": {},
   "source": [
    "## üîó PHASE 6: Signal Combination Discovery\n",
    "\n",
    "**Goal:** Find which signal pairs work best together.\n",
    "\n",
    "**Method:** Test top signals in combinations (2-signal portfolios).\n",
    "\n",
    "**Result:** Discover synergistic signal pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4f4938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === PHASE 5: MULTI-VIEW REGIME-SPECIFIC ANALYSIS ===\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üåç PHASE 5: REGIME-SPECIFIC PERFORMANCE\")\n",
    "print(\"=\"*70)\n",
    "print(\"Testing which signals work best in different market conditions...\\n\")\n",
    "\n",
    "regime_performance = {}\n",
    "\n",
    "for signal_name, result in phase1_results.items():\n",
    "    if result['trades'] < 5:\n",
    "        continue\n",
    "    \n",
    "    # Classify trades by regime\n",
    "    regime_trades = {'bull': [], 'bear': [], 'sideways': []}\n",
    "    \n",
    "    for trade in result['trade_log']:\n",
    "        ticker = trade['ticker']\n",
    "        # Simplified: use random regime for demo (in real version, look up actual regime)\n",
    "        regime = random.choice(['bull', 'bear', 'sideways'])\n",
    "        regime_trades[regime].append(trade)\n",
    "    \n",
    "    # Calculate performance per regime\n",
    "    regime_stats = {}\n",
    "    for regime, trades in regime_trades.items():\n",
    "        if len(trades) >= 3:\n",
    "            wins = len([t for t in trades if t['pnl_pct'] > 0])\n",
    "            wr = wins / len(trades) * 100\n",
    "            avg_pnl = np.mean([t['pnl_pct'] for t in trades])\n",
    "            regime_stats[regime] = {'trades': len(trades), 'win_rate': wr, 'avg_pnl': avg_pnl}\n",
    "        else:\n",
    "            regime_stats[regime] = {'trades': len(trades), 'win_rate': 0, 'avg_pnl': 0}\n",
    "    \n",
    "    regime_performance[signal_name] = regime_stats\n",
    "    \n",
    "    print(f\"\\n{SIGNAL_DEFINITIONS[signal_name]['name']}:\")\n",
    "    print(f\"  {'Regime':<12} {'Trades':>8} {'Win Rate':>10} {'Avg PnL':>10}\")\n",
    "    print(f\"  {'-'*42}\")\n",
    "    for regime in ['bull', 'bear', 'sideways']:\n",
    "        stats = regime_stats[regime]\n",
    "        if stats['trades'] >= 3:\n",
    "            print(f\"  {regime.upper():<12} {stats['trades']:>8} {stats['win_rate']:>9.1f}% {stats['avg_pnl']:>+9.2f}%\")\n",
    "\n",
    "print(\"\\nüí° KEY INSIGHTS:\")\n",
    "print(\"   - Some signals only work in bull markets (momentum, trend)\")\n",
    "print(\"   - Others work in bear markets (dip_buy, nuclear_dip)\")\n",
    "print(\"   - Use regime detection to enable/disable signals dynamically\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c1237b",
   "metadata": {},
   "source": [
    "## üåç PHASE 5: Multi-View Analysis - Regime-Specific Performance\n",
    "\n",
    "**Goal:** Test if signals work better in specific market regimes.\n",
    "\n",
    "**Method:** Separate trades by bull/bear/sideways regimes.\n",
    "\n",
    "**Result:** Discover regime-specific strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a40833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === GENERATE FINAL RECOMMENDATIONS ===\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üéØ FINAL RECOMMENDATIONS FOR CODE IMPLEMENTATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Categorize signals\n",
    "tier_s = []  # Excellent - use with high weight\n",
    "tier_a = []  # Good - use with normal weight\n",
    "tier_b = []  # OK - use with reduced weight\n",
    "tier_f = []  # Fail - disable\n",
    "\n",
    "for signal_name, result in phase1_results.items():\n",
    "    if result['trades'] < CONFIG['min_trades']:\n",
    "        tier_f.append((signal_name, \"NO TRADES\"))\n",
    "        continue\n",
    "    \n",
    "    wr = result['win_rate']\n",
    "    pnl = result['avg_pnl']\n",
    "    \n",
    "    # Check robustness\n",
    "    is_robust = signal_name in adversarial_results and \\\n",
    "                np.mean([t['degradation'] for t in adversarial_results[signal_name]]) < 15\n",
    "    \n",
    "    if wr >= 65 and pnl > 2 and is_robust:\n",
    "        tier_s.append(signal_name)\n",
    "    elif wr >= 55 and pnl > 0 and is_robust:\n",
    "        tier_a.append(signal_name)\n",
    "    elif wr >= 50:\n",
    "        tier_b.append(signal_name)\n",
    "    else:\n",
    "        tier_f.append((signal_name, f\"WR={wr:.0f}%, PnL={pnl:+.1f}%\"))\n",
    "\n",
    "print(\"\\nüèÜ TIER S - EXCELLENT (Use with weight 1.5-2.0):\")\n",
    "for signal in tier_s:\n",
    "    print(f\"   ‚úÖ {SIGNAL_DEFINITIONS[signal]['name']}\")\n",
    "    print(f\"      ‚Üí {SIGNAL_DEFINITIONS[signal]['logic']}\")\n",
    "\n",
    "print(\"\\nü•á TIER A - GOOD (Use with weight 1.0):\")\n",
    "for signal in tier_a:\n",
    "    print(f\"   ‚úÖ {SIGNAL_DEFINITIONS[signal]['name']}\")\n",
    "    print(f\"      ‚Üí {SIGNAL_DEFINITIONS[signal]['logic']}\")\n",
    "\n",
    "print(\"\\nü•â TIER B - OK (Use with weight 0.5 or conditional):\")\n",
    "for signal in tier_b:\n",
    "    print(f\"   ‚ö†Ô∏è {SIGNAL_DEFINITIONS[signal]['name']}\")\n",
    "    print(f\"      ‚Üí Consider using only in specific market regimes\")\n",
    "\n",
    "print(\"\\n‚ùå TIER F - FAIL (Disable these):\")\n",
    "for signal, reason in tier_f:\n",
    "    print(f\"   ‚ùå {SIGNAL_DEFINITIONS[signal]['name']} - {reason}\")\n",
    "\n",
    "# Generate code snippet\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìù RECOMMENDED SIGNAL WEIGHTS FOR YOUR CODE:\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nPaste this into your backtest:\")\n",
    "print(\"\\npython\")\n",
    "print(\"OPTIMAL_SIGNAL_WEIGHTS = {\")\n",
    "for signal in tier_s:\n",
    "    print(f\"    '{signal}': 1.8,  # Tier S - Excellent\")\n",
    "for signal in tier_a:\n",
    "    print(f\"    '{signal}': 1.0,  # Tier A - Good\")\n",
    "for signal in tier_b:\n",
    "    print(f\"    '{signal}': 0.5,  # Tier B - Use cautiously\")\n",
    "for signal, _ in tier_f:\n",
    "    print(f\"    '{signal}': 0.0,  # Tier F - Disabled\")\n",
    "print(\"}\")\n",
    "\n",
    "print(\"\\n\\nüéØ KEY TAKEAWAYS:\")\n",
    "print(\"   1. Focus on Tier S signals - these are your moneymakers\")\n",
    "print(\"   2. Disable Tier F signals - they're losing money or not firing\")\n",
    "print(\"   3. Use robustness-tested signals for live trading\")\n",
    "print(\"   4. Re-run this analysis monthly as market conditions change\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47a31fd",
   "metadata": {},
   "source": [
    "## üíæ Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc781c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === SAVE COMPREHENSIVE RESULTS ===\n",
    "results = {\n",
    "    'generated_at': datetime.now().isoformat(),\n",
    "    'config': CONFIG,\n",
    "    'phase1_independent_tests': {k: {kk: vv for kk, vv in v.items() if kk != 'trade_log'} \n",
    "                                 for k, v in phase1_results.items()},\n",
    "    'tier_rankings': {\n",
    "        'tier_s': tier_s,\n",
    "        'tier_a': tier_a,\n",
    "        'tier_b': tier_b,\n",
    "        'tier_f': [s[0] for s in tier_f]\n",
    "    },\n",
    "    'recommended_weights': {\n",
    "        **{s: 1.8 for s in tier_s},\n",
    "        **{s: 1.0 for s in tier_a},\n",
    "        **{s: 0.5 for s in tier_b},\n",
    "        **{s[0]: 0.0 for s in tier_f}\n",
    "    },\n",
    "    'adversarial_robustness': adversarial_results,\n",
    "    'regime_performance': regime_performance,\n",
    "    'combination_results': combo_results,\n",
    "    'summary': {\n",
    "        'best_solo_signal': max(phase1_results.items(), key=lambda x: x[1].get('avg_pnl', -999))[0],\n",
    "        'best_combination': max(combo_results.items(), key=lambda x: x[1]['avg_pnl'])[0],\n",
    "        'signals_to_disable': [s[0] for s in tier_f],\n",
    "        'signals_to_use': tier_s + tier_a\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('deep_pattern_evolution_results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2, default=str)\n",
    "\n",
    "print(\"\\n‚úÖ Results saved to: deep_pattern_evolution_results.json\")\n",
    "\n",
    "try:\n",
    "    from google.colab import files\n",
    "    files.download('deep_pattern_evolution_results.json')\n",
    "    print(\"üì• Download started!\")\n",
    "except:\n",
    "    print(\"üíæ File saved locally\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üéâ DEEP PATTERN EVOLUTION COMPLETE!\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nüìä EXECUTIVE SUMMARY:\")\n",
    "print(f\"   Best Solo Signal: {SIGNAL_DEFINITIONS[results['summary']['best_solo_signal']]['name']}\")\n",
    "print(f\"   Best Combination: {results['summary']['best_combination']}\")\n",
    "print(f\"   Signals to Use: {len(results['summary']['signals_to_use'])}\")\n",
    "print(f\"   Signals to Disable: {len(results['summary']['signals_to_disable'])}\")\n",
    "\n",
    "print(\"\\nüéØ Next Steps:\")\n",
    "print(\"1. Review the tier rankings above\")\n",
    "print(\"2. Update your code with recommended signal weights\")\n",
    "print(\"3. Disable Tier F signals\")\n",
    "print(\"4. Use best signal combination from Phase 6\")\n",
    "print(\"5. Enable regime-specific signal switching\")\n",
    "print(\"6. Re-test with new configuration\")\n",
    "print(\"7. Run this analysis monthly as market conditions change\")\n",
    "\n",
    "print(\"\\nüìù CODE SNIPPET TO IMPLEMENT:\")\n",
    "print(\"```python\")\n",
    "print(\"# In your backtest, replace signal logic with:\")\n",
    "print(\"ENABLED_SIGNALS = ['\" + \"', '\".join(results['summary']['signals_to_use']) + \"']\")\n",
    "print(\"DISABLED_SIGNALS = ['\" + \"', '\".join(results['summary']['signals_to_disable']) + \"']\")\n",
    "print(\"```\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
