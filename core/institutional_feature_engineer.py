"""
INSTITUTIONAL-GRADE FEATURE ENGINEERING
Enhanced feature set with 150+ features including percentile ranks, second-order,
cross-asset, regime indicators, interaction terms, EMA ribbons, and Fibonacci levels.

Features include:
- Percentile-ranked indicators (RSI, ATR, volume over 90-day window)
- Second-order features (RSI momentum, volume acceleration)
- Cross-asset features (SPY correlation, VIX, sector rotation)
- Regime indicators (trend, volatility, momentum regimes)
- Interaction terms (RSI √ó volume, trend √ó volatility)
- Statistical features (z-scores, percentile ranks)
- EMA Ribbons (8/13/21/34/55/89/144/233) with slope, spread, crossovers
- Fibonacci Retracements & Extensions from swing pivots

Based on hedge fund research for swing trading (1-3 days to weeks).

Usage:
    fe = InstitutionalFeatureEngineer()
    features_df = fe.engineer(ohlcv_df, spy_df=spy_data, vix_series=vix_data)
"""

import numpy as np
import pandas as pd
import talib
from typing import Optional
import logging

logger = logging.getLogger(__name__)


class InstitutionalFeatureEngineer:
    """
    Institutional-grade feature engineering with 150+ features.
    
    Designed for swing trading (1-3 day to multi-week horizons).
    Includes EMA ribbons and Fibonacci retracement/extension levels.
    """
    
    # EMA ribbon periods for golden/death cross detection
    EMA_RIBBON_PERIODS = [8, 13, 21, 34, 55, 89, 144, 233]
    
    # Fibonacci retracement levels
    FIB_RETRACEMENT_LEVELS = [0.236, 0.382, 0.5, 0.618, 0.786]
    
    # Fibonacci extension levels  
    FIB_EXTENSION_LEVELS = [1.272, 1.618, 2.0, 2.618]
    
    def __init__(self):
        """Initialize feature engineer"""
        logger.info("‚úÖ InstitutionalFeatureEngineer initialized (with EMA ribbons + Fibonacci)")
    
    @staticmethod
    def get_array(df, col):
        """Extract numpy array from DataFrame column (handles multi-index)"""
        if isinstance(df[col], pd.DataFrame):
            return df[col].iloc[:, 0].values
        return df[col].values
    
    def _add_ema_ribbon_features(self, features: pd.DataFrame, close: np.ndarray) -> pd.DataFrame:
        """
        Add EMA Ribbon features for golden/death cross detection.
        
        EMA Ribbon uses 8 EMAs (8/13/21/34/55/89/144/233) to detect:
        - Strong trends (all EMAs aligned)
        - Trend transitions (crossovers)
        - Ribbon compression/expansion (volatility indicator)
        """
        # Calculate all EMA ribbon EMAs
        for period in self.EMA_RIBBON_PERIODS:
            features[f'ema_{period}'] = talib.EMA(close, timeperiod=period)
            # Price distance from each EMA
            features[f'price_vs_ema_{period}'] = (close - features[f'ema_{period}'].values) / (features[f'ema_{period}'].values + 1e-10)
            # EMA slope (3-bar rate of change)
            features[f'ema_{period}_slope'] = features[f'ema_{period}'].diff(3) / (features[f'ema_{period}'].shift(3) + 1e-10)
        
        # EMA Ribbon Width (spread between fastest and slowest EMA)
        features['ema_ribbon_width'] = (features['ema_8'] - features['ema_233']) / (close + 1e-10)
        
        # Ribbon compression (low std of width = consolidation)
        features['ema_ribbon_compression'] = features['ema_ribbon_width'].rolling(20).std()
        
        # Golden Cross / Death Cross signals
        features['ema_8_21_cross'] = np.where(features['ema_8'] > features['ema_21'], 1, -1)
        features['ema_21_55_cross'] = np.where(features['ema_21'] > features['ema_55'], 1, -1)
        features['ema_55_144_cross'] = np.where(features['ema_55'] > features['ema_144'], 1, -1)
        
        # Cross just happened (signal bars)
        features['ema_8_21_cross_signal'] = features['ema_8_21_cross'].diff().abs()
        features['ema_21_55_cross_signal'] = features['ema_21_55_cross'].diff().abs()
        
        # Ribbon alignment score (all EMAs aligned = strong trend)
        # Bullish: EMA_8 > EMA_13 > EMA_21 > ... > EMA_233
        features['ema_ribbon_bullish'] = (
            (features['ema_8'] > features['ema_13']).astype(int) +
            (features['ema_13'] > features['ema_21']).astype(int) +
            (features['ema_21'] > features['ema_34']).astype(int) +
            (features['ema_34'] > features['ema_55']).astype(int) +
            (features['ema_55'] > features['ema_89']).astype(int) +
            (features['ema_89'] > features['ema_144']).astype(int) +
            (features['ema_144'] > features['ema_233']).astype(int)
        ) / 7.0  # Normalized 0-1
        
        features['ema_ribbon_bearish'] = 1.0 - features['ema_ribbon_bullish']
        
        # Ribbon center (average of all EMAs)
        ribbon_cols = [f'ema_{p}' for p in self.EMA_RIBBON_PERIODS]
        features['ema_ribbon_center'] = features[ribbon_cols].mean(axis=1)
        features['price_vs_ribbon_center'] = (close - features['ema_ribbon_center'].values) / (features['ema_ribbon_center'].values + 1e-10)
        
        return features
    
    def _add_fibonacci_features(self, features: pd.DataFrame, high: np.ndarray, low: np.ndarray, close: np.ndarray) -> pd.DataFrame:
        """
        Add Fibonacci retracement and extension features.
        
        Uses swing high/low detection to calculate key Fibonacci levels:
        - Retracements: 0.236, 0.382, 0.5, 0.618, 0.786
        - Extensions: 1.272, 1.618, 2.0, 2.618
        """
        high_series = pd.Series(high)
        low_series = pd.Series(low)
        
        # Find swing highs and lows (20-bar lookback)
        swing_high = high_series.rolling(20, center=True).max()
        swing_low = low_series.rolling(20, center=True).min()
        fib_range = swing_high - swing_low
        
        # Fibonacci retracement levels (from swing high)
        for level in self.FIB_RETRACEMENT_LEVELS:
            level_name = str(level).replace('.', '_')
            features[f'fib_retrace_{level_name}'] = swing_high - (fib_range * level)
            # Distance from each fib level (normalized)
            features[f'dist_to_fib_{level_name}'] = (close - features[f'fib_retrace_{level_name}'].values) / (close + 1e-10)
        
        # Fibonacci extension levels (from swing low)
        for ext in self.FIB_EXTENSION_LEVELS:
            ext_name = str(ext).replace('.', '_')
            features[f'fib_ext_{ext_name}'] = swing_low + (fib_range * ext)
            features[f'dist_to_fib_ext_{ext_name}'] = (close - features[f'fib_ext_{ext_name}'].values) / (close + 1e-10)
        
        # Near key Fibonacci level signals (within 1% of level)
        features['near_fib_0_618'] = (np.abs(features['dist_to_fib_0_618']) < 0.01).astype(int)
        features['near_fib_0_382'] = (np.abs(features['dist_to_fib_0_382']) < 0.01).astype(int)
        features['near_fib_0_5'] = (np.abs(features['dist_to_fib_0_5']) < 0.01).astype(int)
        
        # Golden ratio zone signals (0.618 level with trend confirmation)
        if 'ema_ribbon_bullish' in features.columns:
            features['golden_zone_bullish'] = ((features['near_fib_0_618'] == 1) & (features['ema_ribbon_bullish'] > 0.5)).astype(int)
            features['golden_zone_bearish'] = ((features['near_fib_0_618'] == 1) & (features['ema_ribbon_bearish'] > 0.5)).astype(int)
        
        # Fib cluster zones (multiple levels within 2%)
        fib_cols = [f'fib_retrace_{str(l).replace(".", "_")}' for l in self.FIB_RETRACEMENT_LEVELS]
        features['fib_cluster_count'] = sum(
            (np.abs(close - features[col].values) / (close + 1e-10) < 0.02).astype(int)
            for col in fib_cols if col in features.columns
        )
        
        return features
    
    def engineer(
        self,
        df: pd.DataFrame,
        spy_df: Optional[pd.DataFrame] = None,
        vix_series: Optional[pd.Series] = None,
        sector_etf_df: Optional[pd.DataFrame] = None
    ) -> pd.DataFrame:
        """
        Generate institutional-grade features.
        
        Args:
            df: Stock OHLCV data
            spy_df: SPY (market) OHLCV data (optional but recommended)
            vix_series: VIX level data (optional)
            sector_etf_df: Sector ETF data for rotation (optional)
        
        Returns:
            DataFrame with 150+ features including EMA ribbons and Fibonacci levels
        """
        close = np.asarray(self.get_array(df, 'Close'), dtype='float64')
        high = np.asarray(self.get_array(df, 'High'), dtype='float64')
        low = np.asarray(self.get_array(df, 'Low'), dtype='float64')
        volume = np.asarray(self.get_array(df, 'Volume'), dtype='float64')
        
        features = pd.DataFrame(index=df.index)
        
        # === EMA RIBBON FEATURES (Golden/Death Cross Detection) ===
        features = self._add_ema_ribbon_features(features, close)
        
        # === FIBONACCI RETRACEMENT & EXTENSION FEATURES ===
        features = self._add_fibonacci_features(features, high, low, close)
        
        # === BASIC TECHNICAL INDICATORS ===
        features['rsi_9'] = talib.RSI(close, timeperiod=9)
        features['rsi_14'] = talib.RSI(close, timeperiod=14)
        features['rsi_21'] = talib.RSI(close, timeperiod=21)
        
        macd, macd_signal, macd_hist = talib.MACD(close, fastperiod=12, slowperiod=26, signalperiod=9)
        features['macd'] = macd
        features['macd_signal'] = macd_signal
        features['macd_histogram'] = macd_hist
        
        features['atr_14'] = talib.ATR(high, low, close, timeperiod=14)
        features['adx_14'] = talib.ADX(high, low, close, timeperiod=14)
        
        features['cci_14'] = talib.CCI(high, low, close, timeperiod=14)
        features['mfi_14'] = talib.MFI(high, low, close, volume, timeperiod=14)
        
        features['bb_upper'], features['bb_middle'], features['bb_lower'] = talib.BBANDS(close, timeperiod=20)
        features['bb_width'] = (features['bb_upper'] - features['bb_lower']) / features['bb_middle']
        features['bb_position'] = (close - features['bb_lower']) / (features['bb_upper'] - features['bb_lower'] + 1e-10)
        
        # Note: EMA_5, EMA_50, EMA_200 calculated here for backward compatibility
        # Full EMA ribbon (8/13/21/34/55/89/144/233) already calculated in _add_ema_ribbon_features
        features['ema_5'] = talib.EMA(close, timeperiod=5)
        features['ema_50'] = talib.EMA(close, timeperiod=50)
        features['ema_200'] = talib.EMA(close, timeperiod=200)
        
        features['obv'] = talib.OBV(close, volume)
        features['obv_ema_20'] = talib.EMA(features['obv'].values, timeperiod=20)
        
        # === PERCENTILE FEATURES (Research Requirement) ===
        # Percentile ranks over 90-day window
        features['rsi_14_percentile'] = features['rsi_14'].rolling(90).rank(pct=True)
        features['atr_14_percentile'] = features['atr_14'].rolling(90).rank(pct=True)
        features['volume_percentile'] = pd.Series(volume).rolling(90).rank(pct=True)
        features['adx_percentile'] = features['adx_14'].rolling(90).rank(pct=True)
        features['mfi_percentile'] = features['mfi_14'].rolling(90).rank(pct=True)
        features['bb_width_percentile'] = features['bb_width'].rolling(90).rank(pct=True)
        
        # === SECOND-ORDER FEATURES (Rate of Change) ===
        features['rsi_momentum'] = features['rsi_14'].diff()  # Change in RSI
        features['rsi_acceleration'] = features['rsi_momentum'].diff()  # 2nd derivative
        
        features['volume_acceleration'] = pd.Series(volume).pct_change().diff()
        features['macd_histogram_velocity'] = features['macd_histogram'].diff()
        
        features['price_momentum'] = pd.Series(close).pct_change(5)
        features['price_acceleration'] = features['price_momentum'].diff()
        
        features['atr_trend'] = features['atr_14'].diff(5)  # ATR increasing = vol rising
        features['adx_trend'] = features['adx_14'].diff(5)  # ADX rising = trend strengthening
        
        # === RETURNS AT MULTIPLE HORIZONS ===
        features['return_1d'] = pd.Series(close).pct_change(1)
        features['return_3d'] = pd.Series(close).pct_change(3)
        features['return_5d'] = pd.Series(close).pct_change(5)
        features['return_10d'] = pd.Series(close).pct_change(10)
        features['return_21d'] = pd.Series(close).pct_change(21)
        
        # === VOLUME ANALYSIS ===
        features['volume_sma_20'] = talib.SMA(volume, timeperiod=20)
        features['volume_ratio'] = volume / (features['volume_sma_20'] + 1e-9)
        features['volume_surge'] = (features['volume_ratio'] > 2.0).astype(float)
        
        # === REGIME INDICATORS ===
        # Trend regime
        features['price_above_ema50'] = (close > features['ema_50'].values).astype(float)
        features['price_above_ema200'] = (close > features['ema_200'].values).astype(float)
        features['ema_50_above_ema200'] = (features['ema_50'] > features['ema_200']).astype(float)
        
        features['trend_regime_bull'] = (
            (features['adx_14'] > 25) & 
            (close > features['ema_200'].values)
        ).astype(float)
        
        features['trend_regime_bear'] = (
            (features['adx_14'] > 25) & 
            (close < features['ema_200'].values)
        ).astype(float)
        
        features['trend_regime_range'] = (features['adx_14'] < 20).astype(float)
        
        # Volatility regime
        features['vol_regime_high'] = (features['atr_14_percentile'] > 0.67).astype(float)
        features['vol_regime_low'] = (features['atr_14_percentile'] < 0.33).astype(float)
        features['vol_regime_normal'] = (
            (features['atr_14_percentile'] >= 0.33) & 
            (features['atr_14_percentile'] <= 0.67)
        ).astype(float)
        
        # Momentum regime
        features['momentum_strong'] = (features['rsi_14'] > 60).astype(float)
        features['momentum_weak'] = (features['rsi_14'] < 40).astype(float)
        
        # === Z-SCORES (Statistical Normalization) ===
        features['rsi_zscore'] = (features['rsi_14'] - features['rsi_14'].rolling(90).mean()) / (features['rsi_14'].rolling(90).std() + 1e-10)
        features['volume_zscore'] = (pd.Series(volume) - pd.Series(volume).rolling(90).mean()) / (pd.Series(volume).rolling(90).std() + 1e-10)
        features['price_zscore'] = (pd.Series(close) - pd.Series(close).rolling(90).mean()) / (pd.Series(close).rolling(90).std() + 1e-10)
        
        # === INTERACTION FEATURES ===
        # Research shows interaction terms capture non-linear relationships
        features['rsi_x_volume'] = features['rsi_14'] * features['volume_ratio']
        features['trend_x_volatility'] = features['adx_14'] * features['atr_14_percentile']
        features['momentum_x_volume'] = features['rsi_momentum'] * features['volume_ratio']
        
        # EMA Ribbon interaction features
        features['ema_ribbon_x_adx'] = features['ema_ribbon_bullish'] * features['adx_14'] / 100
        features['ema_ribbon_x_rsi'] = features['ema_ribbon_bullish'] * features['rsi_14'] / 100
        features['golden_cross_strength'] = features['ema_8_21_cross'] * features['adx_14'] / 100
        
        # Fibonacci interaction features  
        features['fib_x_ribbon'] = features['near_fib_0_618'] * features['ema_ribbon_bullish']
        features['fib_x_volume'] = features['near_fib_0_618'] * features['volume_ratio']
        features['fib_cluster_x_adx'] = features['fib_cluster_count'] * features['adx_14'] / 100
        
        # Strong trend confirmation (ribbon + fib + volume)
        features['strong_trend_confirm'] = (
            (features['ema_ribbon_bullish'] > 0.7).astype(float) * 
            features['adx_14'] / 100 * 
            (features['volume_ratio'] > 1.2).astype(float)
        )
        
        # Reversal confluence (fib level + RSI extreme + volume spike)
        features['reversal_confluence'] = (
            features['near_fib_0_618'] * 
            ((features['rsi_14'] < 30) | (features['rsi_14'] > 70)).astype(float) *
            (features['volume_ratio'] > 1.5).astype(float)
        )
        
        # === CROSS-ASSET FEATURES (Market Context) ===
        if spy_df is not None:
            try:
                spy_close = self.get_array(spy_df, 'Close')
                spy_returns = pd.Series(spy_close).pct_change()
                
                features['spy_return_1d'] = spy_returns
                features['spy_return_5d'] = pd.Series(spy_close).pct_change(5)
                
                # Relative strength vs SPY
                stock_returns = pd.Series(close).pct_change()
                features['relative_strength_spy'] = stock_returns - spy_returns
                
                # Rolling correlation with SPY (20-day window)
                features['correlation_spy'] = stock_returns.rolling(20).corr(spy_returns)
                
                # Beta vs SPY
                cov = stock_returns.rolling(60).cov(spy_returns)
                spy_var = spy_returns.rolling(60).var()
                features['beta_spy'] = cov / (spy_var + 1e-10)
                
            except Exception as e:
                logger.warning(f"Could not add SPY features: {e}")
        
        if vix_series is not None:
            try:
                features['vix_level'] = vix_series
                features['vix_percentile'] = vix_series.rolling(90).rank(pct=True)
                features['vix_change'] = vix_series.diff()
                features['vix_high'] = (features['vix_percentile'] > 0.75).astype(float)
                features['vix_low'] = (features['vix_percentile'] < 0.25).astype(float)
            except Exception as e:
                logger.warning(f"Could not add VIX features: {e}")
        
        # === CLEANUP ===
        # Replace infinities with NaN
        features = features.replace([np.inf, -np.inf], np.nan)
        
        # Forward fill then backward fill
        features = features.ffill().bfill()
        
        # Fill remaining NaNs with median
        for col in features.columns:
            if features[col].isna().any():
                median_val = features[col].median()
                if pd.isna(median_val):
                    median_val = 0.0
                features[col] = features[col].fillna(median_val)
        
        logger.info(f"‚úÖ Generated {len(features.columns)} institutional features")
        
        return features
    
    def get_feature_importance_categories(self) -> dict:
        """Return feature categories for interpretability"""
        return {
            'basic_technical': ['rsi_9', 'rsi_14', 'rsi_21', 'macd', 'macd_signal', 'atr_14', 'adx_14'],
            'percentile_ranks': ['rsi_14_percentile', 'atr_14_percentile', 'volume_percentile', 'adx_percentile'],
            'second_order': ['rsi_momentum', 'rsi_acceleration', 'volume_acceleration', 'macd_histogram_velocity'],
            'regime_indicators': ['trend_regime_bull', 'trend_regime_bear', 'vol_regime_high', 'vol_regime_low'],
            'cross_asset': ['spy_return_1d', 'relative_strength_spy', 'correlation_spy', 'vix_level'],
            'interactions': ['rsi_x_volume', 'trend_x_volatility', 'momentum_x_volume', 'fib_x_ribbon', 'ema_ribbon_x_adx'],
            'ema_ribbon': ['ema_8', 'ema_13', 'ema_21', 'ema_34', 'ema_55', 'ema_89', 'ema_144', 'ema_233',
                          'ema_ribbon_bullish', 'ema_ribbon_bearish', 'ema_ribbon_width', 'ema_ribbon_compression',
                          'ema_8_21_cross', 'golden_cross_strength'],
            'fibonacci': ['fib_retrace_0_236', 'fib_retrace_0_382', 'fib_retrace_0_5', 'fib_retrace_0_618', 'fib_retrace_0_786',
                         'fib_ext_1_272', 'fib_ext_1_618', 'near_fib_0_618', 'golden_zone_bullish', 'fib_cluster_count'],
            'confluence': ['strong_trend_confirm', 'reversal_confluence']
        }


if __name__ == '__main__':
    # Example usage
    print("üîß Testing Institutional Feature Engineering...")
    
    import yfinance as yf
    from datetime import datetime, timedelta
    
    # Download stock data
    ticker = 'AAPL'
    df = yf.download(ticker, period='1y', progress=False)
    
    # Download SPY and VIX for cross-asset features
    spy_df = yf.download('SPY', period='1y', progress=False)
    vix_df = yf.download('^VIX', period='1y', progress=False)
    
    if len(df) > 0:
        print(f"‚úÖ Downloaded {len(df)} bars for {ticker}")
        
        # Initialize feature engineer
        fe = InstitutionalFeatureEngineer()
        
        # Generate features
        features = fe.engineer(
            df,
            spy_df=spy_df,
            vix_series=vix_df['Close'] if len(vix_df) > 0 else None
        )
        
        print(f"\nüìä Feature Engineering Results:")
        print(f"   Total Features: {len(features.columns)}")
        print(f"   Feature List: {list(features.columns[:10])}... (+{len(features.columns)-10} more)")
        print(f"   NaN Count: {features.isna().sum().sum()}")
        print(f"   Inf Count: {np.isinf(features.values).sum()}")
        
        # Show feature categories
        categories = fe.get_feature_importance_categories()
        print(f"\nüìÅ Feature Categories:")
        for category, feature_list in categories.items():
            print(f"   {category}: {len(feature_list)} features")
        
        # Show sample statistics
        print(f"\nüìà Sample Feature Statistics (last row):")
        sample = features.iloc[-1][['rsi_14', 'rsi_14_percentile', 'volume_ratio', 
                                     'trend_regime_bull', 'correlation_spy']].to_dict()
        for feat, val in sample.items():
            print(f"   {feat}: {val:.3f}" if not pd.isna(val) else f"   {feat}: NaN")
    
    print("\n‚úÖ Institutional Feature Engineering Ready for Production!")
