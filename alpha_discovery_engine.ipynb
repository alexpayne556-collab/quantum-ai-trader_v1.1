{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68d808c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Install Dependencies (Colab-Compatible)\n",
    "# TA-Lib requires system-level installation on Colab\n",
    "!wget -q http://prdownloads.sourceforge.net/ta-lib/ta-lib-0.4.0-src.tar.gz\n",
    "!tar -xzf ta-lib-0.4.0-src.tar.gz\n",
    "%cd ta-lib/\n",
    "!./configure --prefix=/usr > /dev/null 2>&1\n",
    "!make > /dev/null 2>&1\n",
    "!make install > /dev/null 2>&1\n",
    "%cd ..\n",
    "!rm -rf ta-lib ta-lib-0.4.0-src.tar.gz\n",
    "\n",
    "# Now install Python packages\n",
    "!pip install -q yfinance pyts deap gymnasium TA-Lib\n",
    "\n",
    "print(\"‚úì All dependencies installed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1db4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.decomposition import PCA\n",
    "import torch\n",
    "import yfinance as yf\n",
    "import talib\n",
    "from pyts.image import GramianAngularField\n",
    "from deap import base, creator, tools, gp, algorithms\n",
    "import operator\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('fivethirtyeight')\n",
    "print(\"‚úì All libraries imported!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9a7459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Stage 1: HARDCORE Data Preparation (20+ Years, 100+ Features, Human Rules)\n",
    "import itertools\n",
    "\n",
    "# =============================================\n",
    "# === GET MAXIMUM HISTORICAL DATA ===\n",
    "# =============================================\n",
    "print(\"üî• HARDCORE MODE: Loading 20+ years of data...\")\n",
    "ticker = \"SPY\"\n",
    "df = yf.download(ticker, start=\"2000-01-01\", end=\"2024-12-31\", progress=False)\n",
    "\n",
    "if isinstance(df.columns, pd.MultiIndex):\n",
    "    df.columns = df.columns.get_level_values(0)\n",
    "\n",
    "print(f\"‚úì Loaded {len(df)} days ({len(df)/252:.1f} years) of data\")\n",
    "\n",
    "# =============================================\n",
    "# === 100+ TECHNICAL INDICATORS ===\n",
    "# =============================================\n",
    "if len(df) > 250:\n",
    "    close = df['Close'].values.astype(float)\n",
    "    high = df['High'].values.astype(float)\n",
    "    low = df['Low'].values.astype(float)\n",
    "    open_price = df['Open'].values.astype(float)\n",
    "    volume = df['Volume'].values.astype(float)\n",
    "    \n",
    "    # === EMA RIBBON (Full Fibonacci Sequence) ===\n",
    "    for period in [5, 8, 13, 21, 34, 55, 89, 144, 200, 233]:\n",
    "        df[f'EMA{period}'] = talib.EMA(close, timeperiod=period)\n",
    "    \n",
    "    # === SMA at key levels ===\n",
    "    for period in [5, 10, 20, 50, 100, 150, 200]:\n",
    "        df[f'SMA{period}'] = talib.SMA(close, timeperiod=period)\n",
    "    \n",
    "    # === PROVEN HUMAN PATTERNS (Golden Cross, Death Cross, etc) ===\n",
    "    df['Golden_Cross'] = ((df['SMA50'] > df['SMA200']) & (df['SMA50'].shift(1) <= df['SMA200'].shift(1))).astype(int)\n",
    "    df['Death_Cross'] = ((df['SMA50'] < df['SMA200']) & (df['SMA50'].shift(1) >= df['SMA200'].shift(1))).astype(int)\n",
    "    df['Golden_Cross_Active'] = (df['SMA50'] > df['SMA200']).astype(int)\n",
    "    \n",
    "    # EMA Alignment Score (how many EMAs are in bullish order)\n",
    "    ema_cols = ['EMA5', 'EMA8', 'EMA13', 'EMA21', 'EMA34', 'EMA55', 'EMA89', 'EMA144', 'EMA200']\n",
    "    df['EMA_Bullish_Count'] = sum((df[ema_cols[i]] > df[ema_cols[i+1]]).astype(int) for i in range(len(ema_cols)-1))\n",
    "    df['EMA_Perfect_Bullish'] = (df['EMA_Bullish_Count'] == 8).astype(int)\n",
    "    df['EMA_Perfect_Bearish'] = (df['EMA_Bullish_Count'] == 0).astype(int)\n",
    "    \n",
    "    # Price vs ALL EMAs\n",
    "    for period in [8, 21, 55, 200]:\n",
    "        df[f'Price_vs_EMA{period}'] = (df['Close'] - df[f'EMA{period}']) / df[f'EMA{period}'] * 100\n",
    "        df[f'Above_EMA{period}'] = (df['Close'] > df[f'EMA{period}']).astype(int)\n",
    "    \n",
    "    # === RSI at multiple timeframes ===\n",
    "    for period in [2, 5, 7, 14, 21]:\n",
    "        df[f'RSI{period}'] = talib.RSI(close, timeperiod=period)\n",
    "    \n",
    "    # RSI Divergence Detection\n",
    "    df['RSI14'] = talib.RSI(close, timeperiod=14)\n",
    "    df['Price_Higher_High'] = ((df['High'] > df['High'].rolling(5).max().shift(1))).astype(int)\n",
    "    df['RSI_Lower_High'] = ((df['RSI14'] < df['RSI14'].rolling(5).max().shift(1))).astype(int)\n",
    "    df['Bearish_Divergence'] = (df['Price_Higher_High'] & df['RSI_Lower_High']).astype(int)\n",
    "    \n",
    "    df['Price_Lower_Low'] = ((df['Low'] < df['Low'].rolling(5).min().shift(1))).astype(int)\n",
    "    df['RSI_Higher_Low'] = ((df['RSI14'] > df['RSI14'].rolling(5).min().shift(1))).astype(int)\n",
    "    df['Bullish_Divergence'] = (df['Price_Lower_Low'] & df['RSI_Higher_Low']).astype(int)\n",
    "    \n",
    "    # RSI Overbought/Oversold Zones\n",
    "    df['RSI_Oversold'] = (df['RSI14'] < 30).astype(int)\n",
    "    df['RSI_Overbought'] = (df['RSI14'] > 70).astype(int)\n",
    "    df['RSI_Extreme_Oversold'] = (df['RSI14'] < 20).astype(int)\n",
    "    df['RSI_Extreme_Overbought'] = (df['RSI14'] > 80).astype(int)\n",
    "    \n",
    "    # === MACD Multiple Timeframes ===\n",
    "    for fast, slow, sig in [(8, 17, 9), (12, 26, 9), (5, 35, 5)]:\n",
    "        prefix = f'MACD_{fast}_{slow}'\n",
    "        macd, signal, hist = talib.MACD(close, fastperiod=fast, slowperiod=slow, signalperiod=sig)\n",
    "        df[f'{prefix}'] = macd\n",
    "        df[f'{prefix}_Hist'] = hist\n",
    "        df[f'{prefix}_Cross_Up'] = ((hist > 0) & (np.roll(hist, 1) <= 0)).astype(int)\n",
    "        df[f'{prefix}_Cross_Down'] = ((hist < 0) & (np.roll(hist, 1) >= 0)).astype(int)\n",
    "    \n",
    "    # === STOCHASTIC Multiple Settings ===\n",
    "    for k_period in [5, 14, 21]:\n",
    "        k, d = talib.STOCH(high, low, close, fastk_period=k_period, slowk_period=3, slowd_period=3)\n",
    "        df[f'STOCH_K{k_period}'] = k\n",
    "        df[f'STOCH_D{k_period}'] = d\n",
    "        df[f'STOCH{k_period}_Oversold'] = (k < 20).astype(int)\n",
    "        df[f'STOCH{k_period}_Overbought'] = (k > 80).astype(int)\n",
    "    \n",
    "    # === BOLLINGER BANDS Multiple Settings ===\n",
    "    for period in [10, 20, 50]:\n",
    "        upper, middle, lower = talib.BBANDS(close, timeperiod=period, nbdevup=2, nbdevdn=2)\n",
    "        df[f'BB{period}_Upper'] = upper\n",
    "        df[f'BB{period}_Lower'] = lower\n",
    "        df[f'BB{period}_Width'] = (upper - lower) / middle * 100\n",
    "        df[f'BB{period}_Position'] = (df['Close'] - lower) / (upper - lower + 1e-8)\n",
    "        df[f'BB{period}_Squeeze'] = (df[f'BB{period}_Width'] < df[f'BB{period}_Width'].rolling(50).quantile(0.2)).astype(int)\n",
    "    \n",
    "    # === ATR & Volatility ===\n",
    "    for period in [7, 14, 21]:\n",
    "        df[f'ATR{period}'] = talib.ATR(high, low, close, timeperiod=period)\n",
    "        df[f'ATR{period}_Pct'] = df[f'ATR{period}'] / df['Close'] * 100\n",
    "    \n",
    "    # Volatility Expansion/Contraction\n",
    "    df['Vol_Expanding'] = (df['ATR14'] > df['ATR14'].rolling(20).mean()).astype(int)\n",
    "    df['Vol_Contracting'] = (df['ATR14'] < df['ATR14'].rolling(20).mean() * 0.8).astype(int)\n",
    "    \n",
    "    # === ADX & Trend Strength ===\n",
    "    df['ADX'] = talib.ADX(high, low, close, timeperiod=14)\n",
    "    df['PLUS_DI'] = talib.PLUS_DI(high, low, close, timeperiod=14)\n",
    "    df['MINUS_DI'] = talib.MINUS_DI(high, low, close, timeperiod=14)\n",
    "    df['DI_Cross_Bullish'] = ((df['PLUS_DI'] > df['MINUS_DI']) & (df['PLUS_DI'].shift(1) <= df['MINUS_DI'].shift(1))).astype(int)\n",
    "    df['DI_Cross_Bearish'] = ((df['PLUS_DI'] < df['MINUS_DI']) & (df['PLUS_DI'].shift(1) >= df['MINUS_DI'].shift(1))).astype(int)\n",
    "    df['Strong_Trend'] = (df['ADX'] > 25).astype(int)\n",
    "    df['Very_Strong_Trend'] = (df['ADX'] > 40).astype(int)\n",
    "    \n",
    "    # === VOLUME Analysis ===\n",
    "    df['Volume_SMA20'] = df['Volume'].rolling(20).mean()\n",
    "    df['Volume_Ratio'] = df['Volume'] / df['Volume_SMA20']\n",
    "    df['Volume_Spike'] = (df['Volume_Ratio'] > 2).astype(int)\n",
    "    df['Volume_Surge'] = (df['Volume_Ratio'] > 3).astype(int)\n",
    "    df['OBV'] = talib.OBV(close, volume)\n",
    "    df['OBV_Trend'] = df['OBV'] - talib.EMA(df['OBV'].values, timeperiod=20)\n",
    "    df['MFI'] = talib.MFI(high, low, close, volume, timeperiod=14)\n",
    "    df['AD'] = talib.AD(high, low, close, volume)\n",
    "    \n",
    "    # === CANDLESTICK PATTERNS (All major ones) ===\n",
    "    df['CDL_DOJI'] = talib.CDLDOJI(open_price, high, low, close) / 100\n",
    "    df['CDL_HAMMER'] = talib.CDLHAMMER(open_price, high, low, close) / 100\n",
    "    df['CDL_ENGULFING'] = talib.CDLENGULFING(open_price, high, low, close) / 100\n",
    "    df['CDL_MORNINGSTAR'] = talib.CDLMORNINGSTAR(open_price, high, low, close) / 100\n",
    "    df['CDL_EVENINGSTAR'] = talib.CDLEVENINGSTAR(open_price, high, low, close) / 100\n",
    "    df['CDL_PIERCING'] = talib.CDLPIERCING(open_price, high, low, close) / 100\n",
    "    df['CDL_HARAMI'] = talib.CDLHARAMI(open_price, high, low, close) / 100\n",
    "    df['CDL_3WHITESOLDIERS'] = talib.CDL3WHITESOLDIERS(open_price, high, low, close) / 100\n",
    "    df['CDL_3BLACKCROWS'] = talib.CDL3BLACKCROWS(open_price, high, low, close) / 100\n",
    "    df['CDL_SHOOTINGSTAR'] = talib.CDLSHOOTINGSTAR(open_price, high, low, close) / 100\n",
    "    df['CDL_INVERTEDHAMMER'] = talib.CDLINVERTEDHAMMER(open_price, high, low, close) / 100\n",
    "    \n",
    "    # === SUPPORT/RESISTANCE ===\n",
    "    for period in [5, 10, 20, 50]:\n",
    "        df[f'High_{period}d'] = df['High'].rolling(period).max()\n",
    "        df[f'Low_{period}d'] = df['Low'].rolling(period).min()\n",
    "        df[f'Range_Position_{period}d'] = (df['Close'] - df[f'Low_{period}d']) / (df[f'High_{period}d'] - df[f'Low_{period}d'] + 1e-8)\n",
    "        df[f'Near_High_{period}d'] = (df['Close'] > df[f'High_{period}d'] * 0.98).astype(int)\n",
    "        df[f'Near_Low_{period}d'] = (df['Close'] < df[f'Low_{period}d'] * 1.02).astype(int)\n",
    "        df[f'Breakout_{period}d'] = (df['Close'] > df[f'High_{period}d'].shift(1)).astype(int)\n",
    "        df[f'Breakdown_{period}d'] = (df['Close'] < df[f'Low_{period}d'].shift(1)).astype(int)\n",
    "    \n",
    "    # === RETURNS at different horizons ===\n",
    "    for period in [1, 2, 3, 5, 10, 20, 60]:\n",
    "        df[f'Return_{period}d'] = df['Close'].pct_change(period)\n",
    "        df[f'Return_{period}d_Positive'] = (df[f'Return_{period}d'] > 0).astype(int)\n",
    "    \n",
    "    # Consecutive Up/Down Days\n",
    "    df['Up_Day'] = (df['Close'] > df['Open']).astype(int)\n",
    "    df['Consec_Up'] = df['Up_Day'].rolling(5).sum()\n",
    "    df['Consec_Down'] = 5 - df['Consec_Up']\n",
    "    \n",
    "    # === MOMENTUM INDICATORS ===\n",
    "    df['ROC5'] = talib.ROC(close, timeperiod=5)\n",
    "    df['ROC10'] = talib.ROC(close, timeperiod=10)\n",
    "    df['ROC20'] = talib.ROC(close, timeperiod=20)\n",
    "    df['MOM10'] = talib.MOM(close, timeperiod=10)\n",
    "    df['WILLR'] = talib.WILLR(high, low, close, timeperiod=14)\n",
    "    df['CCI'] = talib.CCI(high, low, close, timeperiod=20)\n",
    "    df['ULTOSC'] = talib.ULTOSC(high, low, close, timeperiod1=7, timeperiod2=14, timeperiod3=28)\n",
    "    \n",
    "    # === AROON ===\n",
    "    df['AROON_Up'], df['AROON_Down'] = talib.AROON(high, low, timeperiod=14)\n",
    "    df['AROON_Osc'] = df['AROON_Up'] - df['AROON_Down']\n",
    "    \n",
    "    # === PARABOLIC SAR ===\n",
    "    df['SAR'] = talib.SAR(high, low, acceleration=0.02, maximum=0.2)\n",
    "    df['SAR_Bullish'] = (df['Close'] > df['SAR']).astype(int)\n",
    "    df['SAR_Flip_Bull'] = ((df['SAR_Bullish'] == 1) & (df['SAR_Bullish'].shift(1) == 0)).astype(int)\n",
    "    df['SAR_Flip_Bear'] = ((df['SAR_Bullish'] == 0) & (df['SAR_Bullish'].shift(1) == 1)).astype(int)\n",
    "    \n",
    "    # === GAP Analysis ===\n",
    "    df['Gap'] = (df['Open'] - df['Close'].shift(1)) / df['Close'].shift(1) * 100\n",
    "    df['Gap_Up'] = (df['Gap'] > 0.5).astype(int)\n",
    "    df['Gap_Down'] = (df['Gap'] < -0.5).astype(int)\n",
    "    df['Large_Gap_Up'] = (df['Gap'] > 1.0).astype(int)\n",
    "    df['Large_Gap_Down'] = (df['Gap'] < -1.0).astype(int)\n",
    "    \n",
    "    # === PRICE ACTION ===\n",
    "    df['Body'] = df['Close'] - df['Open']\n",
    "    df['Body_Pct'] = abs(df['Body']) / df['Open'] * 100\n",
    "    df['Upper_Shadow'] = df['High'] - df[['Open', 'Close']].max(axis=1)\n",
    "    df['Lower_Shadow'] = df[['Open', 'Close']].min(axis=1) - df['Low']\n",
    "    df['Range'] = df['High'] - df['Low']\n",
    "    df['Range_Pct'] = df['Range'] / df['Low'] * 100\n",
    "    \n",
    "    # === COMPOUND SIGNALS (Human + Machine) ===\n",
    "    # Triple Screen (Elder)\n",
    "    df['Triple_Screen_Bull'] = ((df['EMA_Bullish_Count'] >= 6) & (df['RSI14'] < 45) & (df['STOCH_K14'] < 30)).astype(int)\n",
    "    df['Triple_Screen_Bear'] = ((df['EMA_Bullish_Count'] <= 2) & (df['RSI14'] > 55) & (df['STOCH_K14'] > 70)).astype(int)\n",
    "    \n",
    "    # Squeeze + Breakout\n",
    "    df['Squeeze_Breakout_Up'] = (df['BB20_Squeeze'].shift(1) & df['Breakout_20d']).astype(int)\n",
    "    df['Squeeze_Breakout_Down'] = (df['BB20_Squeeze'].shift(1) & df['Breakdown_20d']).astype(int)\n",
    "    \n",
    "    # Volume Confirmed Breakout\n",
    "    df['Vol_Confirmed_Breakout'] = (df['Breakout_20d'] & df['Volume_Spike']).astype(int)\n",
    "    df['Vol_Confirmed_Breakdown'] = (df['Breakdown_20d'] & df['Volume_Spike']).astype(int)\n",
    "    \n",
    "    # Mean Reversion Setup\n",
    "    df['Mean_Reversion_Long'] = ((df['BB20_Position'] < 0.1) & (df['RSI14'] < 30) & (df['STOCH_K14'] < 20)).astype(int)\n",
    "    df['Mean_Reversion_Short'] = ((df['BB20_Position'] > 0.9) & (df['RSI14'] > 70) & (df['STOCH_K14'] > 80)).astype(int)\n",
    "    \n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "# Count features\n",
    "feature_count = len([c for c in df.columns if c not in ['Open', 'High', 'Low', 'Close', 'Volume']])\n",
    "print(f\"‚úì HARDCORE Features computed: {feature_count} indicators\")\n",
    "print(f\"  Remaining rows: {len(df)} ({len(df)/252:.1f} years)\")\n",
    "\n",
    "# === CREATE 1-DAY PREDICTION TARGET (for bigger gains) ===\n",
    "df = df.reset_index(drop=True)\n",
    "df['Returns'] = df['Close'].pct_change()\n",
    "df['Future_1d_Return'] = df['Returns'].shift(-1)  # Next day return\n",
    "df['Future_3d_Return'] = df['Returns'].rolling(3).sum().shift(-3)\n",
    "df['Future_5d_Return'] = df['Returns'].rolling(5).sum().shift(-5)\n",
    "\n",
    "# High conviction targets (big moves only)\n",
    "df['Big_Move_Up'] = (df['Future_1d_Return'] > 0.01).astype(int)  # > 1% up\n",
    "df['Big_Move_Down'] = (df['Future_1d_Return'] < -0.01).astype(int)  # > 1% down\n",
    "\n",
    "print(f\"\\nüìä Target Distribution:\")\n",
    "print(f\"  Days with >1% up move: {df['Big_Move_Up'].sum()} ({df['Big_Move_Up'].mean()*100:.1f}%)\")\n",
    "print(f\"  Days with >1% down move: {df['Big_Move_Down'].sum()} ({df['Big_Move_Down'].mean()*100:.1f}%)\")\n",
    "\n",
    "# GASF Images (keep for visual patterns)\n",
    "print(\"\\nCreating GASF images...\")\n",
    "close_series = df['Close'].values.astype(float)\n",
    "returns = np.log(close_series[1:] / close_series[:-1])\n",
    "\n",
    "window_size = 20\n",
    "image_size = 20\n",
    "gasf_images = []\n",
    "gasf_indices = []\n",
    "\n",
    "gasf = GramianAngularField(image_size=image_size, method='summation', sample_range=(-1, 1))\n",
    "\n",
    "for i in range(len(returns) - window_size):\n",
    "    window = returns[i:i+window_size]\n",
    "    window_min, window_max = window.min(), window.max()\n",
    "    if window_max - window_min > 1e-8:\n",
    "        window_norm = 2 * (window - window_min) / (window_max - window_min) - 1\n",
    "    else:\n",
    "        window_norm = np.zeros_like(window)\n",
    "    try:\n",
    "        gasf_img = gasf.fit_transform(window_norm.reshape(1, -1))\n",
    "        gasf_images.append(gasf_img[0])\n",
    "        gasf_indices.append(i + window_size)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "gasf_images = np.array(gasf_images)\n",
    "print(f\"‚úì Created {len(gasf_images)} GASF images\")\n",
    "\n",
    "# Align data\n",
    "valid_indices = [idx for idx in gasf_indices if idx < len(df)]\n",
    "aligned_future_returns = df['Future_1d_Return'].iloc[valid_indices].values\n",
    "aligned_gasf_images = gasf_images[:len(valid_indices)]\n",
    "mask = ~np.isnan(aligned_future_returns)\n",
    "aligned_gasf_images = aligned_gasf_images[mask]\n",
    "aligned_future_returns = aligned_future_returns[mask]\n",
    "aligned_indices = np.array(valid_indices)[mask]\n",
    "\n",
    "print(f\"‚úì Data ready. {len(df)} days, {feature_count} features, 1-day prediction target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941c4e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Stage 2: Unsupervised Visual Discovery\n",
    "# Check if data is ready\n",
    "if 'aligned_gasf_images' not in dir() or len(aligned_gasf_images) == 0:\n",
    "    raise RuntimeError(\"‚ö†Ô∏è Run Cell 3 (Data Preparation) first!\")\n",
    "\n",
    "class VisualPatternFinder:\n",
    "    \"\"\"Cluster GASF images - find recurring visual structures.\"\"\"\n",
    "    \n",
    "    def __init__(self, n_patterns=10):\n",
    "        self.n_patterns = n_patterns\n",
    "        self.kmeans = None\n",
    "        self.patterns = {}\n",
    "    \n",
    "    def discover_visual_patterns(self, gasf_images, future_returns):\n",
    "        \"\"\"\n",
    "        Cluster images ‚Üí find which clusters are profitable.\n",
    "        \"\"\"\n",
    "        # Reshape for clustering (flatten images)\n",
    "        n_samples, h, w = gasf_images.shape\n",
    "        X = gasf_images.reshape(n_samples, h*w)\n",
    "        \n",
    "        # Cluster\n",
    "        self.kmeans = KMeans(n_clusters=self.n_patterns, random_state=42, n_init=10)\n",
    "        clusters = self.kmeans.fit_predict(X)\n",
    "        \n",
    "        # Analyze each cluster\n",
    "        print(\"\\nVISUAL PATTERN ANALYSIS\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        for cluster_id in range(self.n_patterns):\n",
    "            mask = clusters == cluster_id\n",
    "            cluster_returns = future_returns[mask]\n",
    "            \n",
    "            if len(cluster_returns) == 0:\n",
    "                continue\n",
    "\n",
    "            # Statistics\n",
    "            avg_return = np.mean(cluster_returns)\n",
    "            win_rate = (cluster_returns > 0).mean()\n",
    "            frequency = mask.sum() / len(clusters)\n",
    "            std_dev = np.std(cluster_returns) + 1e-8\n",
    "            sharpe = avg_return / std_dev * np.sqrt(252/5)  # Annualized roughly\n",
    "            \n",
    "            print(f\"\\nPattern {cluster_id}:\")\n",
    "            print(f\"  Frequency: {frequency*100:.1f}% of days\")\n",
    "            print(f\"  Next-5d return: {avg_return*100:.2f}%\")\n",
    "            print(f\"  Win rate: {win_rate*100:.1f}%\")\n",
    "            print(f\"  Sharpe: {sharpe:.2f}\")\n",
    "            \n",
    "            if avg_return > 0.005:  # Threshold for \"profitable\"\n",
    "                print(f\"  ‚úì PROFITABLE PATTERN FOUND\")\n",
    "            \n",
    "            self.patterns[cluster_id] = {\n",
    "                'avg_return': avg_return,\n",
    "                'win_rate': win_rate,\n",
    "                'frequency': frequency,\n",
    "                'sharpe': sharpe,\n",
    "                'centroid': self.kmeans.cluster_centers_[cluster_id].reshape(h, w)\n",
    "            }\n",
    "            \n",
    "    def plot_patterns(self):\n",
    "        \"\"\"Visualize the centroids of discovered patterns.\"\"\"\n",
    "        if not self.patterns:\n",
    "            print(\"No patterns discovered yet.\")\n",
    "            return\n",
    "            \n",
    "        fig, axes = plt.subplots(2, (self.n_patterns + 1) // 2, figsize=(15, 6))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        for i, (cluster_id, stats) in enumerate(self.patterns.items()):\n",
    "            if i < len(axes):\n",
    "                axes[i].imshow(stats['centroid'], cmap='rainbow', origin='lower')\n",
    "                axes[i].set_title(f\"P{cluster_id}: WR {stats['win_rate']:.2f}\")\n",
    "                axes[i].axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Discover patterns\n",
    "finder = VisualPatternFinder(n_patterns=8)\n",
    "finder.discover_visual_patterns(aligned_gasf_images, aligned_future_returns)\n",
    "finder.plot_patterns()\n",
    "\n",
    "print(\"\\n‚úì DISCOVERED: Which price shapes predict returns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4304bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Stage 3: BASELINE - Test Proven Human Trading Strategies\n",
    "\n",
    "class HumanStrategyTester:\n",
    "    \"\"\"Test known trading strategies to establish baseline.\"\"\"\n",
    "    \n",
    "    def __init__(self, df):\n",
    "        self.df = df.copy()\n",
    "        self.results = {}\n",
    "    \n",
    "    def backtest_strategy(self, name, signal_col, target_col='Future_1d_Return'):\n",
    "        \"\"\"Backtest a single strategy.\"\"\"\n",
    "        data = self.df[[signal_col, target_col]].dropna()\n",
    "        signals = data[signal_col].values\n",
    "        returns = data[target_col].values\n",
    "        \n",
    "        # Strategy returns\n",
    "        strat_returns = signals * returns\n",
    "        \n",
    "        # Metrics\n",
    "        total_return = (1 + strat_returns).prod() - 1\n",
    "        trades = (signals != 0).sum()\n",
    "        wins = (strat_returns > 0).sum()\n",
    "        win_rate = wins / trades if trades > 0 else 0\n",
    "        \n",
    "        avg_win = strat_returns[strat_returns > 0].mean() if (strat_returns > 0).sum() > 0 else 0\n",
    "        avg_loss = abs(strat_returns[strat_returns < 0].mean()) if (strat_returns < 0).sum() > 0 else 1e-8\n",
    "        profit_factor = avg_win / avg_loss if avg_loss > 0 else 999\n",
    "        \n",
    "        sharpe = np.mean(strat_returns) / (np.std(strat_returns) + 1e-8) * np.sqrt(252)\n",
    "        \n",
    "        # Drawdown\n",
    "        cumulative = np.cumsum(strat_returns)\n",
    "        running_max = np.maximum.accumulate(cumulative)\n",
    "        drawdown = running_max - cumulative\n",
    "        max_dd = drawdown.max()\n",
    "        \n",
    "        self.results[name] = {\n",
    "            'total_return': total_return,\n",
    "            'win_rate': win_rate,\n",
    "            'profit_factor': profit_factor,\n",
    "            'sharpe': sharpe,\n",
    "            'max_drawdown': max_dd,\n",
    "            'trades': trades\n",
    "        }\n",
    "        \n",
    "        return self.results[name]\n",
    "    \n",
    "    def test_all_strategies(self):\n",
    "        \"\"\"Test all known strategies.\"\"\"\n",
    "        \n",
    "        print(\"\\nüìä HUMAN STRATEGY BASELINE TEST\")\n",
    "        print(\"=\" * 70)\n",
    "        print(\"Testing proven trading strategies on 20+ years of data...\")\n",
    "        print()\n",
    "        \n",
    "        # Create strategy signals\n",
    "        df = self.df\n",
    "        \n",
    "        # 1. Buy & Hold\n",
    "        df['BuyHold_Signal'] = 1\n",
    "        self.backtest_strategy('Buy & Hold', 'BuyHold_Signal')\n",
    "        \n",
    "        # 2. Golden Cross (SMA 50/200)\n",
    "        if 'Golden_Cross_Active' in df.columns:\n",
    "            df['GoldenCross_Signal'] = df['Golden_Cross_Active'].apply(lambda x: 1 if x else -1)\n",
    "            self.backtest_strategy('Golden Cross (50/200)', 'GoldenCross_Signal')\n",
    "        \n",
    "        # 3. RSI Mean Reversion\n",
    "        if 'RSI14' in df.columns:\n",
    "            df['RSI_MeanRev_Signal'] = 0\n",
    "            df.loc[df['RSI14'] < 30, 'RSI_MeanRev_Signal'] = 1\n",
    "            df.loc[df['RSI14'] > 70, 'RSI_MeanRev_Signal'] = -1\n",
    "            self.backtest_strategy('RSI Mean Reversion', 'RSI_MeanRev_Signal')\n",
    "        \n",
    "        # 4. MACD Crossover\n",
    "        if 'MACD_12_26_Hist' in df.columns:\n",
    "            df['MACD_Signal'] = np.sign(df['MACD_12_26_Hist'])\n",
    "            self.backtest_strategy('MACD Crossover', 'MACD_Signal')\n",
    "        \n",
    "        # 5. Bollinger Band Mean Reversion\n",
    "        if 'BB20_Position' in df.columns:\n",
    "            df['BB_MeanRev_Signal'] = 0\n",
    "            df.loc[df['BB20_Position'] < 0.1, 'BB_MeanRev_Signal'] = 1\n",
    "            df.loc[df['BB20_Position'] > 0.9, 'BB_MeanRev_Signal'] = -1\n",
    "            self.backtest_strategy('Bollinger Band MR', 'BB_MeanRev_Signal')\n",
    "        \n",
    "        # 6. Triple Screen (Elder)\n",
    "        if 'Triple_Screen_Bull' in df.columns:\n",
    "            df['TripleScreen_Signal'] = 0\n",
    "            df.loc[df['Triple_Screen_Bull'] == 1, 'TripleScreen_Signal'] = 1\n",
    "            df.loc[df['Triple_Screen_Bear'] == 1, 'TripleScreen_Signal'] = -1\n",
    "            self.backtest_strategy('Triple Screen (Elder)', 'TripleScreen_Signal')\n",
    "        \n",
    "        # 7. Breakout Strategy\n",
    "        if 'Breakout_20d' in df.columns:\n",
    "            df['Breakout_Signal'] = 0\n",
    "            df.loc[df['Breakout_20d'] == 1, 'Breakout_Signal'] = 1\n",
    "            df.loc[df['Breakdown_20d'] == 1, 'Breakout_Signal'] = -1\n",
    "            self.backtest_strategy('20-Day Breakout', 'Breakout_Signal')\n",
    "        \n",
    "        # 8. Volume Confirmed Breakout\n",
    "        if 'Vol_Confirmed_Breakout' in df.columns:\n",
    "            df['VolBreakout_Signal'] = 0\n",
    "            df.loc[df['Vol_Confirmed_Breakout'] == 1, 'VolBreakout_Signal'] = 1\n",
    "            df.loc[df['Vol_Confirmed_Breakdown'] == 1, 'VolBreakout_Signal'] = -1\n",
    "            self.backtest_strategy('Volume Breakout', 'VolBreakout_Signal')\n",
    "        \n",
    "        # 9. ADX Trend Following\n",
    "        if 'ADX' in df.columns and 'PLUS_DI' in df.columns:\n",
    "            df['ADX_Signal'] = 0\n",
    "            df.loc[(df['ADX'] > 25) & (df['PLUS_DI'] > df['MINUS_DI']), 'ADX_Signal'] = 1\n",
    "            df.loc[(df['ADX'] > 25) & (df['PLUS_DI'] < df['MINUS_DI']), 'ADX_Signal'] = -1\n",
    "            self.backtest_strategy('ADX Trend Follow', 'ADX_Signal')\n",
    "        \n",
    "        # 10. Squeeze Breakout\n",
    "        if 'Squeeze_Breakout_Up' in df.columns:\n",
    "            df['Squeeze_Signal'] = 0\n",
    "            df.loc[df['Squeeze_Breakout_Up'] == 1, 'Squeeze_Signal'] = 1\n",
    "            df.loc[df['Squeeze_Breakout_Down'] == 1, 'Squeeze_Signal'] = -1\n",
    "            self.backtest_strategy('Squeeze Breakout', 'Squeeze_Signal')\n",
    "        \n",
    "        # 11. EMA Ribbon Alignment\n",
    "        if 'EMA_Perfect_Bullish' in df.columns:\n",
    "            df['EMA_Ribbon_Signal'] = 0\n",
    "            df.loc[df['EMA_Bullish_Count'] >= 7, 'EMA_Ribbon_Signal'] = 1\n",
    "            df.loc[df['EMA_Bullish_Count'] <= 1, 'EMA_Ribbon_Signal'] = -1\n",
    "            self.backtest_strategy('EMA Ribbon', 'EMA_Ribbon_Signal')\n",
    "        \n",
    "        # 12. RSI Divergence\n",
    "        if 'Bullish_Divergence' in df.columns:\n",
    "            df['Divergence_Signal'] = 0\n",
    "            df.loc[df['Bullish_Divergence'] == 1, 'Divergence_Signal'] = 1\n",
    "            df.loc[df['Bearish_Divergence'] == 1, 'Divergence_Signal'] = -1\n",
    "            self.backtest_strategy('RSI Divergence', 'Divergence_Signal')\n",
    "        \n",
    "        # 13. Stochastic Overbought/Oversold\n",
    "        if 'STOCH_K14' in df.columns:\n",
    "            df['Stoch_Signal'] = 0\n",
    "            df.loc[df['STOCH_K14'] < 20, 'Stoch_Signal'] = 1\n",
    "            df.loc[df['STOCH_K14'] > 80, 'Stoch_Signal'] = -1\n",
    "            self.backtest_strategy('Stochastic OS/OB', 'Stoch_Signal')\n",
    "        \n",
    "        # 14. Combined Mean Reversion\n",
    "        if 'Mean_Reversion_Long' in df.columns:\n",
    "            df['CombinedMR_Signal'] = 0\n",
    "            df.loc[df['Mean_Reversion_Long'] == 1, 'CombinedMR_Signal'] = 1\n",
    "            df.loc[df['Mean_Reversion_Short'] == 1, 'CombinedMR_Signal'] = -1\n",
    "            self.backtest_strategy('Combined Mean Rev', 'CombinedMR_Signal')\n",
    "        \n",
    "        # Print results\n",
    "        print(f\"{'Strategy':<25} {'Return':>10} {'Win Rate':>10} {'Sharpe':>8} {'PF':>8} {'MaxDD':>8}\")\n",
    "        print(\"-\" * 70)\n",
    "        \n",
    "        sorted_results = sorted(self.results.items(), key=lambda x: x[1]['sharpe'], reverse=True)\n",
    "        \n",
    "        for name, r in sorted_results:\n",
    "            print(f\"{name:<25} {r['total_return']*100:>9.1f}% {r['win_rate']*100:>9.1f}% \"\n",
    "                  f\"{r['sharpe']:>8.2f} {r['profit_factor']:>7.2f} {r['max_drawdown']*100:>7.1f}%\")\n",
    "        \n",
    "        # Best strategy\n",
    "        best = sorted_results[0]\n",
    "        print(f\"\\nüèÜ Best Human Strategy: {best[0]}\")\n",
    "        print(f\"   Sharpe: {best[1]['sharpe']:.2f}, Return: {best[1]['total_return']*100:.1f}%\")\n",
    "        \n",
    "        return self.results\n",
    "\n",
    "# Test human strategies\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "tester = HumanStrategyTester(df)\n",
    "human_results = tester.test_all_strategies()\n",
    "\n",
    "# Store best human strategy for comparison\n",
    "best_human = max(human_results.items(), key=lambda x: x[1]['sharpe'])\n",
    "print(f\"\\n‚ö° AI MUST BEAT: {best_human[0]} with Sharpe {best_human[1]['sharpe']:.2f}\")\n",
    "\n",
    "# Also run rare state detection\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "detector = UltimateRareStateDetector()\n",
    "rare_profiles = detector.find_rare_states(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e8f272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Stage 4: HARDCORE Formula Evolution (50 Features, 500 Pop, 100 Gens)\n",
    "\n",
    "class HardcoreFormulaEvolver:\n",
    "    \"\"\"Massive genetic programming with 50 key features.\"\"\"\n",
    "    \n",
    "    def __init__(self, feature_names):\n",
    "        # Reset creators\n",
    "        if hasattr(creator, \"FitnessMax\"):\n",
    "            del creator.FitnessMax\n",
    "        if hasattr(creator, \"Individual\"):\n",
    "            del creator.Individual\n",
    "            \n",
    "        creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "        creator.create(\"Individual\", gp.PrimitiveTree, fitness=creator.FitnessMax)\n",
    "        \n",
    "        self.feature_names = feature_names\n",
    "        self.n_features = len(feature_names)\n",
    "        self.toolbox = base.Toolbox()\n",
    "        self.pset = gp.PrimitiveSet(\"MAIN\", self.n_features)\n",
    "        \n",
    "        # Rename arguments\n",
    "        for i, name in enumerate(self.feature_names):\n",
    "            self.pset.renameArguments(**{f'ARG{i}': name})\n",
    "        \n",
    "        # === EXTENSIVE OPERATIONS ===\n",
    "        self.pset.addPrimitive(operator.add, 2, name='add')\n",
    "        self.pset.addPrimitive(operator.sub, 2, name='sub')\n",
    "        self.pset.addPrimitive(operator.mul, 2, name='mul')\n",
    "        \n",
    "        def pdiv(x, y): return x / (y + 1e-8)\n",
    "        def psqrt(x): return np.sqrt(np.abs(x))\n",
    "        def plog(x): return np.log(np.abs(x) + 1e-8)\n",
    "        def pexp(x): return np.clip(np.exp(np.clip(x, -10, 10)), -1e10, 1e10)\n",
    "        def pmax(x, y): return np.maximum(x, y)\n",
    "        def pmin(x, y): return np.minimum(x, y)\n",
    "        def pif(c, t, f): return np.where(c > 0, t, f)\n",
    "        def pand(x, y): return np.where((x > 0) & (y > 0), 1.0, 0.0)\n",
    "        def por(x, y): return np.where((x > 0) | (y > 0), 1.0, 0.0)\n",
    "        def pgt(x, y): return np.where(x > y, 1.0, -1.0)\n",
    "        def plt(x, y): return np.where(x < y, 1.0, -1.0)\n",
    "        \n",
    "        self.pset.addPrimitive(pdiv, 2, name='div')\n",
    "        self.pset.addPrimitive(psqrt, 1, name='sqrt')\n",
    "        self.pset.addPrimitive(plog, 1, name='log')\n",
    "        self.pset.addPrimitive(pexp, 1, name='exp')\n",
    "        self.pset.addPrimitive(np.sin, 1, name='sin')\n",
    "        self.pset.addPrimitive(np.cos, 1, name='cos')\n",
    "        self.pset.addPrimitive(np.tanh, 1, name='tanh')\n",
    "        self.pset.addPrimitive(np.abs, 1, name='abs')\n",
    "        self.pset.addPrimitive(operator.neg, 1, name='neg')\n",
    "        self.pset.addPrimitive(pmax, 2, name='max')\n",
    "        self.pset.addPrimitive(pmin, 2, name='min')\n",
    "        self.pset.addPrimitive(pif, 3, name='ifgt0')\n",
    "        self.pset.addPrimitive(pand, 2, name='AND')\n",
    "        self.pset.addPrimitive(por, 2, name='OR')\n",
    "        self.pset.addPrimitive(pgt, 2, name='GT')\n",
    "        self.pset.addPrimitive(plt, 2, name='LT')\n",
    "        \n",
    "        # Constants (trading thresholds)\n",
    "        for val in [0.0, 0.5, 1.0, 2.0, -1.0, 20.0, 30.0, 50.0, 70.0, 80.0]:\n",
    "            name = f'c{str(val).replace(\".\", \"_\").replace(\"-\", \"neg\")}'\n",
    "            self.pset.addTerminal(val, name=name)\n",
    "        \n",
    "        self.toolbox.register(\"expr\", gp.genHalfAndHalf, pset=self.pset, min_=2, max_=6)\n",
    "        self.toolbox.register(\"individual\", tools.initIterate, creator.Individual, self.toolbox.expr)\n",
    "        self.toolbox.register(\"population\", tools.initRepeat, list, self.toolbox.individual)\n",
    "        self.toolbox.register(\"mate\", gp.cxOnePoint)\n",
    "        self.toolbox.register(\"mutate\", gp.mutUniform, expr=self.toolbox.expr, pset=self.pset)\n",
    "        self.toolbox.register(\"select\", tools.selTournament, tournsize=7)\n",
    "        \n",
    "        self.toolbox.decorate(\"mate\", gp.staticLimit(key=operator.attrgetter(\"height\"), max_value=15))\n",
    "        self.toolbox.decorate(\"mutate\", gp.staticLimit(key=operator.attrgetter(\"height\"), max_value=15))\n",
    "    \n",
    "    def eval_formula(self, individual, X, y):\n",
    "        \"\"\"Multi-metric fitness: correlation + sharpe + win rate.\"\"\"\n",
    "        try:\n",
    "            func = gp.compile(individual, self.pset)\n",
    "            pred = func(*[X[:,i] for i in range(self.n_features)])\n",
    "            \n",
    "            if np.isnan(pred).any() or np.isinf(pred).any():\n",
    "                return (-100.0,)\n",
    "            \n",
    "            pred = np.array(pred).flatten()\n",
    "            \n",
    "            # Correlation\n",
    "            corr = np.corrcoef(pred, y)[0, 1]\n",
    "            if np.isnan(corr):\n",
    "                return (-100.0,)\n",
    "            \n",
    "            # Strategy performance\n",
    "            signals = np.sign(pred)\n",
    "            strat_ret = signals * y\n",
    "            \n",
    "            # Win rate\n",
    "            wins = (strat_ret > 0).sum()\n",
    "            trades = (signals != 0).sum()\n",
    "            win_rate = wins / trades if trades > 0 else 0.5\n",
    "            \n",
    "            # Sharpe\n",
    "            sharpe = np.mean(strat_ret) / (np.std(strat_ret) + 1e-8) * np.sqrt(252)\n",
    "            \n",
    "            # Profit factor\n",
    "            gross_profit = strat_ret[strat_ret > 0].sum()\n",
    "            gross_loss = abs(strat_ret[strat_ret < 0].sum())\n",
    "            pf = gross_profit / (gross_loss + 1e-8)\n",
    "            \n",
    "            # Combined fitness (weighted)\n",
    "            fitness = (\n",
    "                corr * 0.3 +                    # Correlation\n",
    "                np.tanh(sharpe) * 0.3 +         # Risk-adjusted return\n",
    "                (win_rate - 0.5) * 2 * 0.2 +    # Win rate above 50%\n",
    "                np.tanh(pf - 1) * 0.2           # Profit factor above 1\n",
    "            )\n",
    "            \n",
    "            return (fitness,)\n",
    "            \n",
    "        except Exception as e:\n",
    "            return (-100.0,)\n",
    "    \n",
    "    def evolve(self, X, y, pop_size=500, generations=100, checkpoint_every=25):\n",
    "        \"\"\"Evolve with progress checkpoints.\"\"\"\n",
    "        \n",
    "        self.toolbox.register(\"evaluate\", self.eval_formula, X=X, y=y)\n",
    "        \n",
    "        pop = self.toolbox.population(n=pop_size)\n",
    "        hof = tools.HallOfFame(20)  # Keep top 20\n",
    "        \n",
    "        stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "        stats.register(\"avg\", lambda x: np.mean([v[0] for v in x if v[0] > -50]))\n",
    "        stats.register(\"max\", np.max)\n",
    "        \n",
    "        print(f\"üß¨ Starting HARDCORE Evolution...\")\n",
    "        print(f\"   Population: {pop_size}\")\n",
    "        print(f\"   Generations: {generations}\")\n",
    "        print(f\"   Features: {self.n_features}\")\n",
    "        print()\n",
    "        \n",
    "        # Evolve with checkpoints\n",
    "        for gen in range(generations):\n",
    "            # Select and clone\n",
    "            offspring = self.toolbox.select(pop, len(pop))\n",
    "            offspring = list(map(self.toolbox.clone, offspring))\n",
    "            \n",
    "            # Crossover\n",
    "            for child1, child2 in zip(offspring[::2], offspring[1::2]):\n",
    "                if np.random.random() < 0.7:\n",
    "                    self.toolbox.mate(child1, child2)\n",
    "                    del child1.fitness.values\n",
    "                    del child2.fitness.values\n",
    "            \n",
    "            # Mutation\n",
    "            for mutant in offspring:\n",
    "                if np.random.random() < 0.3:\n",
    "                    self.toolbox.mutate(mutant)\n",
    "                    del mutant.fitness.values\n",
    "            \n",
    "            # Evaluate\n",
    "            invalid = [ind for ind in offspring if not ind.fitness.valid]\n",
    "            fitnesses = map(self.toolbox.evaluate, invalid)\n",
    "            for ind, fit in zip(invalid, fitnesses):\n",
    "                ind.fitness.values = fit\n",
    "            \n",
    "            pop[:] = offspring\n",
    "            hof.update(pop)\n",
    "            \n",
    "            # Progress\n",
    "            fits = [ind.fitness.values[0] for ind in pop if ind.fitness.values[0] > -50]\n",
    "            if fits:\n",
    "                avg_fit = np.mean(fits)\n",
    "                max_fit = np.max(fits)\n",
    "                \n",
    "                if (gen + 1) % 10 == 0 or gen == 0:\n",
    "                    print(f\"   Gen {gen+1:3d}: avg={avg_fit:.4f}, max={max_fit:.4f}\")\n",
    "                \n",
    "                if (gen + 1) % checkpoint_every == 0:\n",
    "                    print(f\"\\n   üìç Checkpoint at Gen {gen+1}:\")\n",
    "                    best = hof[0]\n",
    "                    self._show_formula_stats(best, X, y)\n",
    "                    print()\n",
    "        \n",
    "        return hof\n",
    "    \n",
    "    def _show_formula_stats(self, formula, X, y):\n",
    "        \"\"\"Show formula performance stats.\"\"\"\n",
    "        func = gp.compile(formula, self.pset)\n",
    "        pred = func(*[X[:,i] for i in range(self.n_features)])\n",
    "        signals = np.sign(pred)\n",
    "        strat_ret = signals * y\n",
    "        \n",
    "        total_ret = (1 + strat_ret).prod() - 1\n",
    "        win_rate = (strat_ret > 0).sum() / (signals != 0).sum() if (signals != 0).sum() > 0 else 0\n",
    "        sharpe = np.mean(strat_ret) / (np.std(strat_ret) + 1e-8) * np.sqrt(252)\n",
    "        \n",
    "        print(f\"      Formula: {str(formula)[:80]}...\")\n",
    "        print(f\"      Total Return: {total_ret*100:.1f}%\")\n",
    "        print(f\"      Win Rate: {win_rate*100:.1f}%\")\n",
    "        print(f\"      Sharpe: {sharpe:.2f}\")\n",
    "\n",
    "# === SELECT 50 MOST IMPORTANT FEATURES ===\n",
    "print(\"\\nüî• HARDCORE FORMULA EVOLUTION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Key features for formula evolution (50 most important)\n",
    "hardcore_features = [\n",
    "    # Core Momentum (10)\n",
    "    'RSI14', 'RSI2', 'RSI7', 'STOCH_K14', 'STOCH_D14', 'MFI', 'CCI', 'WILLR', 'ULTOSC', 'MOM10',\n",
    "    # Trend (10)\n",
    "    'ADX', 'PLUS_DI', 'MINUS_DI', 'AROON_Osc', 'EMA_Bullish_Count', 'SAR_Bullish', \n",
    "    'Golden_Cross_Active', 'Strong_Trend', 'Above_EMA21', 'Above_EMA200',\n",
    "    # Volatility (8)\n",
    "    'ATR14_Pct', 'BB20_Position', 'BB20_Width', 'BB20_Squeeze', 'Vol_Expanding', 'Vol_Contracting',\n",
    "    'Range_Pct', 'Gap',\n",
    "    # Volume (5)\n",
    "    'Volume_Ratio', 'Volume_Spike', 'OBV_Trend', 'AD',\n",
    "    # Price Position (7)\n",
    "    'Price_vs_EMA21', 'Price_vs_EMA200', 'Range_Position_20d', 'Near_High_20d', 'Near_Low_20d',\n",
    "    'Breakout_20d', 'Breakdown_20d',\n",
    "    # Returns (5)\n",
    "    'Return_1d', 'Return_3d', 'Return_5d', 'Consec_Up', 'Consec_Down',\n",
    "    # Human Patterns (5)\n",
    "    'Bullish_Divergence', 'Bearish_Divergence', 'Mean_Reversion_Long', 'Mean_Reversion_Short',\n",
    "    'Triple_Screen_Bull'\n",
    "]\n",
    "\n",
    "# Filter to available features\n",
    "available_features = [f for f in hardcore_features if f in df.columns]\n",
    "print(f\"Using {len(available_features)} features for evolution\")\n",
    "\n",
    "# Prepare data\n",
    "data_subset = df[available_features + ['Future_1d_Return']].dropna()\n",
    "X_features = data_subset[available_features].values\n",
    "y_returns = data_subset['Future_1d_Return'].values\n",
    "\n",
    "# Normalize\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "scaler = RobustScaler()  # More robust to outliers\n",
    "X_features = scaler.fit_transform(X_features)\n",
    "\n",
    "print(f\"Training data: {len(X_features)} samples\")\n",
    "print(f\"Target: 1-day forward return\")\n",
    "\n",
    "# === RUN HARDCORE EVOLUTION ===\n",
    "evolver = HardcoreFormulaEvolver(available_features)\n",
    "best_formulas = evolver.evolve(X_features, y_returns, pop_size=500, generations=100)\n",
    "\n",
    "# === SHOW TOP RESULTS ===\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üèÜ TOP 10 DISCOVERED FORMULAS:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for i, formula in enumerate(best_formulas[:10]):\n",
    "    print(f\"\\n{i+1}. Fitness: {formula.fitness.values[0]:.4f}\")\n",
    "    evolver._show_formula_stats(formula, X_features, y_returns)\n",
    "\n",
    "best_formula = best_formulas[0] if best_formulas else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385c823b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Stage 5: HARDCORE RL Training (2000 Episodes, Deep Q-Table)\n",
    "\n",
    "class DeepQAgent:\n",
    "    \"\"\"More sophisticated Q-learning with deeper state discretization.\"\"\"\n",
    "    \n",
    "    def __init__(self, n_features, n_actions=3, n_bins=10):\n",
    "        self.n_features = min(n_features, 6)  # Use top 6 features\n",
    "        self.n_actions = n_actions\n",
    "        self.n_bins = n_bins\n",
    "        \n",
    "        # Q-table: n_bins^n_features x n_actions\n",
    "        self.n_states = n_bins ** self.n_features\n",
    "        self.q_table = np.zeros((self.n_states, n_actions))\n",
    "        \n",
    "        # Learning parameters\n",
    "        self.lr = 0.1\n",
    "        self.gamma = 0.95\n",
    "        self.epsilon = 0.3\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.9995\n",
    "        \n",
    "        self.bins = None\n",
    "        \n",
    "    def setup_bins(self, data):\n",
    "        \"\"\"Create discretization bins from percentiles.\"\"\"\n",
    "        self.bins = []\n",
    "        for i in range(self.n_features):\n",
    "            percentiles = np.percentile(data[:, i], np.linspace(0, 100, self.n_bins + 1)[1:-1])\n",
    "            self.bins.append(percentiles)\n",
    "    \n",
    "    def discretize(self, state):\n",
    "        \"\"\"Convert continuous state to discrete index.\"\"\"\n",
    "        if self.bins is None:\n",
    "            return 0\n",
    "        \n",
    "        indices = []\n",
    "        for i in range(self.n_features):\n",
    "            idx = np.digitize(state[i], self.bins[i])\n",
    "            idx = np.clip(idx, 0, self.n_bins - 1)\n",
    "            indices.append(idx)\n",
    "        \n",
    "        # Convert to single index\n",
    "        state_idx = 0\n",
    "        for i, idx in enumerate(indices):\n",
    "            state_idx += idx * (self.n_bins ** i)\n",
    "        \n",
    "        return min(state_idx, self.n_states - 1)\n",
    "    \n",
    "    def act(self, state, training=True):\n",
    "        if training and np.random.random() < self.epsilon:\n",
    "            return np.random.randint(self.n_actions)\n",
    "        \n",
    "        state_idx = self.discretize(state)\n",
    "        return np.argmax(self.q_table[state_idx])\n",
    "    \n",
    "    def update(self, state, action, reward, next_state, done):\n",
    "        state_idx = self.discretize(state)\n",
    "        next_state_idx = self.discretize(next_state)\n",
    "        \n",
    "        if done:\n",
    "            target = reward\n",
    "        else:\n",
    "            target = reward + self.gamma * np.max(self.q_table[next_state_idx])\n",
    "        \n",
    "        self.q_table[state_idx, action] += self.lr * (target - self.q_table[state_idx, action])\n",
    "        \n",
    "        # Decay epsilon\n",
    "        self.epsilon = max(self.epsilon_min, self.epsilon * self.epsilon_decay)\n",
    "\n",
    "\n",
    "class HardcoreTradingEnv(gym.Env):\n",
    "    \"\"\"Trading environment optimized for 1-day returns.\"\"\"\n",
    "    \n",
    "    def __init__(self, df, feature_cols):\n",
    "        super().__init__()\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.feature_cols = [f for f in feature_cols if f in df.columns][:6]  # Top 6 features\n",
    "        \n",
    "        self.current_idx = 250\n",
    "        self.max_idx = len(df) - 2\n",
    "        \n",
    "        self.action_space = spaces.Discrete(3)  # SHORT, HOLD, LONG\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=-np.inf, high=np.inf,\n",
    "            shape=(len(self.feature_cols),),\n",
    "            dtype=np.float32\n",
    "        )\n",
    "        \n",
    "        # Normalize\n",
    "        self.scaler = StandardScaler()\n",
    "        valid_data = df[self.feature_cols].dropna()\n",
    "        self.scaler.fit(valid_data)\n",
    "        \n",
    "        self.position = 0\n",
    "        self.total_pnl = 0\n",
    "    \n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        self.current_idx = np.random.randint(250, self.max_idx - 100)\n",
    "        self.position = 0\n",
    "        self.total_pnl = 0\n",
    "        return self._get_state(), {}\n",
    "    \n",
    "    def step(self, action):\n",
    "        new_position = action - 1  # -1, 0, 1\n",
    "        \n",
    "        # Get next day return\n",
    "        next_return = self.df['Future_1d_Return'].iloc[self.current_idx]\n",
    "        if np.isnan(next_return):\n",
    "            next_return = 0\n",
    "        \n",
    "        # Calculate reward\n",
    "        reward = float(new_position * next_return * 100)\n",
    "        \n",
    "        # Transaction cost\n",
    "        if new_position != self.position:\n",
    "            reward -= 0.02  # 2 bps\n",
    "        \n",
    "        self.position = new_position\n",
    "        self.total_pnl += reward\n",
    "        self.current_idx += 1\n",
    "        \n",
    "        done = self.current_idx >= self.max_idx\n",
    "        \n",
    "        return self._get_state(), reward, done, False, {'pnl': self.total_pnl}\n",
    "    \n",
    "    def _get_state(self):\n",
    "        idx = min(self.current_idx, len(self.df) - 1)\n",
    "        state = self.df[self.feature_cols].iloc[idx].values.astype(float)\n",
    "        state = np.nan_to_num(state, 0)\n",
    "        state = self.scaler.transform(state.reshape(1, -1)).flatten()\n",
    "        return state.astype(np.float32)\n",
    "\n",
    "\n",
    "# === TRAIN RL AGENT ===\n",
    "print(\"\\nü§ñ HARDCORE RL TRAINING\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Key features for RL state\n",
    "rl_features = ['RSI14', 'ADX', 'BB20_Position', 'Volume_Ratio', 'EMA_Bullish_Count', 'Return_1d']\n",
    "rl_features = [f for f in rl_features if f in df.columns]\n",
    "\n",
    "print(f\"State features: {rl_features}\")\n",
    "\n",
    "env = HardcoreTradingEnv(df, rl_features)\n",
    "agent = DeepQAgent(n_features=len(rl_features), n_bins=8)\n",
    "\n",
    "# Collect states for bin setup\n",
    "sample_states = []\n",
    "for _ in range(500):\n",
    "    state, _ = env.reset()\n",
    "    sample_states.append(state)\n",
    "sample_states = np.array(sample_states)\n",
    "agent.setup_bins(sample_states)\n",
    "\n",
    "print(f\"Q-table size: {agent.n_states} states x {agent.n_actions} actions\")\n",
    "print(f\"\\nTraining for 2000 episodes...\")\n",
    "\n",
    "episode_rewards = []\n",
    "best_avg = -np.inf\n",
    "\n",
    "for episode in range(2000):\n",
    "    state, _ = env.reset()\n",
    "    total_reward = 0\n",
    "    \n",
    "    for step in range(200):  # ~200 trading days per episode\n",
    "        action = agent.act(state)\n",
    "        next_state, reward, done, _, _ = env.step(action)\n",
    "        agent.update(state, action, reward, next_state, done)\n",
    "        \n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "        \n",
    "        if done:\n",
    "            break\n",
    "    \n",
    "    episode_rewards.append(total_reward)\n",
    "    \n",
    "    if (episode + 1) % 200 == 0:\n",
    "        avg = np.mean(episode_rewards[-200:])\n",
    "        if avg > best_avg:\n",
    "            best_avg = avg\n",
    "            print(f\"   Episode {episode+1}: Avg Reward = {avg:.2f} (NEW BEST!) Œµ={agent.epsilon:.3f}\")\n",
    "        else:\n",
    "            print(f\"   Episode {episode+1}: Avg Reward = {avg:.2f}, Œµ={agent.epsilon:.3f}\")\n",
    "\n",
    "print(f\"\\n‚úì Training complete. Best avg reward: {best_avg:.2f}\")\n",
    "\n",
    "# === EVALUATE RL AGENT ===\n",
    "print(\"\\nüìä RL Agent Evaluation (Walk-Forward):\")\n",
    "\n",
    "# Test on last 2 years\n",
    "test_start = len(df) - 504  # ~2 years\n",
    "test_signals = []\n",
    "test_returns = []\n",
    "\n",
    "env.current_idx = test_start\n",
    "agent.epsilon = 0  # No exploration\n",
    "\n",
    "while env.current_idx < len(df) - 2:\n",
    "    state = env._get_state()\n",
    "    action = agent.act(state, training=False)\n",
    "    signal = action - 1\n",
    "    \n",
    "    actual_return = df['Future_1d_Return'].iloc[env.current_idx]\n",
    "    if not np.isnan(actual_return):\n",
    "        test_signals.append(signal)\n",
    "        test_returns.append(actual_return)\n",
    "    \n",
    "    env.current_idx += 1\n",
    "\n",
    "test_signals = np.array(test_signals)\n",
    "test_returns = np.array(test_returns)\n",
    "strat_returns = test_signals * test_returns\n",
    "\n",
    "rl_total_return = (1 + strat_returns).prod() - 1\n",
    "rl_win_rate = (strat_returns > 0).sum() / (test_signals != 0).sum() if (test_signals != 0).sum() > 0 else 0\n",
    "rl_sharpe = np.mean(strat_returns) / (np.std(strat_returns) + 1e-8) * np.sqrt(252)\n",
    "\n",
    "print(f\"Test Period: Last 2 years ({len(test_signals)} days)\")\n",
    "print(f\"Total Return: {rl_total_return*100:.1f}%\")\n",
    "print(f\"Win Rate: {rl_win_rate*100:.1f}%\")\n",
    "print(f\"Sharpe Ratio: {rl_sharpe:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759fd60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Stage 6: ULTIMATE Multimodal Fusion\n",
    "class UltimateEnsemble:\n",
    "    \"\"\"Combine all discovery methods with confidence weighting.\"\"\"\n",
    "    \n",
    "    def __init__(self, visual_finder, rare_detector, best_formula, evolver, rl_agent, env):\n",
    "        self.visual = visual_finder\n",
    "        self.rare = rare_detector\n",
    "        self.formula = best_formula\n",
    "        self.evolver = evolver\n",
    "        self.agent = rl_agent\n",
    "        self.env = env\n",
    "        \n",
    "        if self.formula is not None:\n",
    "            self.compiled_formula = gp.compile(self.formula, self.evolver.pset)\n",
    "        else:\n",
    "            self.compiled_formula = None\n",
    "        \n",
    "        # Track performance for confidence weighting\n",
    "        self.method_accuracy = {\n",
    "            'visual': 0.5,\n",
    "            'genetic': 0.5,\n",
    "            'rare': 0.5,\n",
    "            'rl': 0.5\n",
    "        }\n",
    "    \n",
    "    def get_ensemble_signal(self, row_dict, gasf_img=None):\n",
    "        \"\"\"Query all modalities and combine signals.\"\"\"\n",
    "        \n",
    "        votes = {}\n",
    "        confidences = {}\n",
    "        \n",
    "        # 1. Visual Pattern Vote\n",
    "        if gasf_img is not None and self.visual.kmeans is not None:\n",
    "            try:\n",
    "                cluster = self.visual.kmeans.predict(gasf_img.reshape(1, -1))[0]\n",
    "                pattern_stats = self.visual.patterns.get(cluster, {})\n",
    "                avg_ret = pattern_stats.get('avg_return', 0)\n",
    "                votes['visual'] = np.sign(avg_ret)\n",
    "                confidences['visual'] = min(abs(avg_ret) * 100, 1.0)  # Scale confidence\n",
    "            except:\n",
    "                votes['visual'] = 0\n",
    "                confidences['visual'] = 0\n",
    "        else:\n",
    "            votes['visual'] = 0\n",
    "            confidences['visual'] = 0\n",
    "            \n",
    "        # 2. Genetic Formula Vote\n",
    "        if self.compiled_formula is not None:\n",
    "            try:\n",
    "                # Build feature array from row_dict\n",
    "                features = []\n",
    "                for feat in self.evolver.feature_names:\n",
    "                    val = row_dict.get(feat, 0)\n",
    "                    if np.isnan(val):\n",
    "                        val = 0\n",
    "                    features.append(val)\n",
    "                \n",
    "                f_val = self.compiled_formula(*features)\n",
    "                votes['genetic'] = float(np.sign(f_val))\n",
    "                confidences['genetic'] = min(abs(f_val), 1.0)\n",
    "            except:\n",
    "                votes['genetic'] = 0\n",
    "                confidences['genetic'] = 0\n",
    "        else:\n",
    "            votes['genetic'] = 0\n",
    "            confidences['genetic'] = 0\n",
    "            \n",
    "        # 3. Rare State Vote\n",
    "        # Check if current state is rare (use ADX + BB_Width + Volume_Ratio)\n",
    "        try:\n",
    "            adx = row_dict.get('ADX', 25)\n",
    "            bb_width = row_dict.get('BB_Width', 10)\n",
    "            vol_ratio = row_dict.get('Volume_Ratio', 1)\n",
    "            \n",
    "            # Rare = low ADX + narrow bands + high volume (squeeze breakout)\n",
    "            is_squeeze = bb_width < 5 and vol_ratio > 1.5\n",
    "            if is_squeeze:\n",
    "                votes['rare'] = 1  # Squeeze = bullish bias\n",
    "                confidences['rare'] = 0.7\n",
    "            else:\n",
    "                votes['rare'] = 0\n",
    "                confidences['rare'] = 0.3\n",
    "        except:\n",
    "            votes['rare'] = 0\n",
    "            confidences['rare'] = 0\n",
    "            \n",
    "        # 4. RL Agent Vote\n",
    "        if self.agent is not None:\n",
    "            try:\n",
    "                state = []\n",
    "                for feat in self.env.state_features:\n",
    "                    val = row_dict.get(feat, 0)\n",
    "                    if np.isnan(val):\n",
    "                        val = 0\n",
    "                    state.append(val)\n",
    "                state = np.array(state, dtype=np.float32)\n",
    "                \n",
    "                action = self.agent.act(state)\n",
    "                votes['rl'] = action - 1  # Convert to -1, 0, 1\n",
    "                \n",
    "                # Confidence from Q-value spread\n",
    "                state_idx = self.agent.discretize_state(state)\n",
    "                q_vals = self.agent.q_table[state_idx]\n",
    "                q_spread = np.max(q_vals) - np.mean(q_vals)\n",
    "                confidences['rl'] = min(q_spread / 10, 1.0)\n",
    "            except:\n",
    "                votes['rl'] = 0\n",
    "                confidences['rl'] = 0\n",
    "        else:\n",
    "            votes['rl'] = 0\n",
    "            confidences['rl'] = 0\n",
    "        \n",
    "        # Weighted consensus\n",
    "        total_weight = sum(confidences.values())\n",
    "        if total_weight > 0:\n",
    "            weighted_signal = sum(v * confidences[k] for k, v in votes.items()) / total_weight\n",
    "        else:\n",
    "            weighted_signal = 0\n",
    "        \n",
    "        return {\n",
    "            'signal': weighted_signal,\n",
    "            'direction': 'LONG' if weighted_signal > 0.2 else 'SHORT' if weighted_signal < -0.2 else 'NEUTRAL',\n",
    "            'votes': votes,\n",
    "            'confidences': confidences,\n",
    "            'consensus_strength': abs(weighted_signal)\n",
    "        }\n",
    "    \n",
    "    def backtest_ensemble(self, df, gasf_images=None, aligned_indices=None):\n",
    "        \"\"\"Backtest the full ensemble on historical data.\"\"\"\n",
    "        \n",
    "        print(\"\\nüìà ENSEMBLE BACKTEST\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        signals = []\n",
    "        returns = []\n",
    "        \n",
    "        # Sample positions to avoid overfitting\n",
    "        test_indices = range(200, min(len(df)-5, len(df)), 5)  # Every 5th day\n",
    "        \n",
    "        for idx in test_indices:\n",
    "            if idx >= len(df) - 5:\n",
    "                continue\n",
    "                \n",
    "            row = df.iloc[idx].to_dict()\n",
    "            \n",
    "            # Get GASF if available\n",
    "            gasf_img = None\n",
    "            if gasf_images is not None and aligned_indices is not None:\n",
    "                matching = np.where(aligned_indices == idx)[0]\n",
    "                if len(matching) > 0:\n",
    "                    gasf_img = gasf_images[matching[0]]\n",
    "            \n",
    "            result = self.get_ensemble_signal(row, gasf_img)\n",
    "            signal = result['signal']\n",
    "            \n",
    "            # Get actual future return\n",
    "            future_ret = df['Future_5d_Return'].iloc[idx]\n",
    "            if np.isnan(future_ret):\n",
    "                continue\n",
    "            \n",
    "            signals.append(signal)\n",
    "            returns.append(future_ret)\n",
    "        \n",
    "        signals = np.array(signals)\n",
    "        returns = np.array(returns)\n",
    "        \n",
    "        # Calculate strategy returns\n",
    "        positions = np.sign(signals)\n",
    "        strategy_returns = positions * returns\n",
    "        \n",
    "        # Metrics\n",
    "        total_return = (1 + strategy_returns).prod() - 1\n",
    "        buy_hold_return = (1 + returns).prod() - 1\n",
    "        win_rate = (strategy_returns > 0).sum() / (strategy_returns != 0).sum() if (strategy_returns != 0).sum() > 0 else 0\n",
    "        \n",
    "        avg_win = strategy_returns[strategy_returns > 0].mean() if (strategy_returns > 0).sum() > 0 else 0\n",
    "        avg_loss = abs(strategy_returns[strategy_returns < 0].mean()) if (strategy_returns < 0).sum() > 0 else 0\n",
    "        profit_factor = avg_win / avg_loss if avg_loss > 0 else 999\n",
    "        \n",
    "        sharpe = np.mean(strategy_returns) / (np.std(strategy_returns) + 1e-8) * np.sqrt(252/5)\n",
    "        \n",
    "        print(f\"Strategy Return: {total_return*100:.2f}%\")\n",
    "        print(f\"Buy & Hold Return: {buy_hold_return*100:.2f}%\")\n",
    "        print(f\"Alpha Generated: {(total_return - buy_hold_return)*100:.2f}%\")\n",
    "        print(f\"Win Rate: {win_rate*100:.1f}%\")\n",
    "        print(f\"Profit Factor: {profit_factor:.2f}\")\n",
    "        print(f\"Sharpe Ratio: {sharpe:.2f}\")\n",
    "        print(f\"Trades: {(positions != 0).sum()}\")\n",
    "        \n",
    "        return {\n",
    "            'total_return': total_return,\n",
    "            'buy_hold': buy_hold_return,\n",
    "            'alpha': total_return - buy_hold_return,\n",
    "            'win_rate': win_rate,\n",
    "            'sharpe': sharpe\n",
    "        }\n",
    "\n",
    "# Create ensemble with all components\n",
    "print(\"\\nüéØ BUILDING ULTIMATE ENSEMBLE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "ensemble = UltimateEnsemble(\n",
    "    visual_finder=finder,\n",
    "    rare_detector=detector,\n",
    "    best_formula=best_formula,\n",
    "    evolver=evolver,\n",
    "    rl_agent=agent,\n",
    "    env=env\n",
    ")\n",
    "\n",
    "print(\"‚úì Ensemble integrates:\")\n",
    "print(\"  1. Visual Pattern Recognition (GASF + KMeans)\")\n",
    "print(\"  2. Genetic Formula Discovery (25 features)\")\n",
    "print(\"  3. Rare State Detection (Multi-feature anomaly)\")\n",
    "print(\"  4. RL Agent (Q-Learning policy)\")\n",
    "\n",
    "# Run backtest\n",
    "backtest_results = ensemble.backtest_ensemble(df, aligned_gasf_images, aligned_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9207a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Stage 7: FINAL COMPARISON - AI vs Human Strategies\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üéØ FINAL SHOWDOWN: AI vs HUMAN STRATEGIES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# === Compile All Results ===\n",
    "final_comparison = {}\n",
    "\n",
    "# 1. Best Human Strategy\n",
    "best_human_name, best_human_stats = best_human\n",
    "final_comparison['Best Human Strategy'] = {\n",
    "    'name': best_human_name,\n",
    "    'sharpe': best_human_stats['sharpe'],\n",
    "    'return': best_human_stats['total_return'],\n",
    "    'win_rate': best_human_stats['win_rate']\n",
    "}\n",
    "\n",
    "# 2. Best Genetic Formula\n",
    "if best_formula is not None:\n",
    "    func = gp.compile(best_formula, evolver.pset)\n",
    "    pred = func(*[X_features[:,i] for i in range(len(available_features))])\n",
    "    signals = np.sign(pred)\n",
    "    strat_returns = signals * y_returns\n",
    "    \n",
    "    gp_return = (1 + strat_returns).prod() - 1\n",
    "    gp_win_rate = (strat_returns > 0).sum() / (signals != 0).sum()\n",
    "    gp_sharpe = np.mean(strat_returns) / (np.std(strat_returns) + 1e-8) * np.sqrt(252)\n",
    "    \n",
    "    final_comparison['Best Genetic Formula'] = {\n",
    "        'formula': str(best_formula)[:60] + '...',\n",
    "        'sharpe': gp_sharpe,\n",
    "        'return': gp_return,\n",
    "        'win_rate': gp_win_rate\n",
    "    }\n",
    "\n",
    "# 3. RL Agent\n",
    "final_comparison['RL Agent'] = {\n",
    "    'sharpe': rl_sharpe,\n",
    "    'return': rl_total_return,\n",
    "    'win_rate': rl_win_rate\n",
    "}\n",
    "\n",
    "# 4. Buy & Hold Baseline\n",
    "bh_return = (1 + df['Future_1d_Return'].dropna()).prod() - 1\n",
    "bh_sharpe = df['Future_1d_Return'].mean() / df['Future_1d_Return'].std() * np.sqrt(252)\n",
    "final_comparison['Buy & Hold'] = {\n",
    "    'sharpe': bh_sharpe,\n",
    "    'return': bh_return,\n",
    "    'win_rate': (df['Future_1d_Return'] > 0).mean()\n",
    "}\n",
    "\n",
    "# === Print Comparison ===\n",
    "print(f\"\\n{'Strategy':<30} {'Sharpe':>10} {'Return':>12} {'Win Rate':>10}\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "sorted_comparison = sorted(final_comparison.items(), key=lambda x: x[1]['sharpe'], reverse=True)\n",
    "\n",
    "for name, stats in sorted_comparison:\n",
    "    sharpe = stats['sharpe']\n",
    "    ret = stats['return'] * 100\n",
    "    wr = stats['win_rate'] * 100\n",
    "    marker = \"üèÜ\" if name == sorted_comparison[0][0] else \"  \"\n",
    "    print(f\"{marker} {name:<28} {sharpe:>10.2f} {ret:>11.1f}% {wr:>9.1f}%\")\n",
    "\n",
    "# === Winner Declaration ===\n",
    "winner = sorted_comparison[0]\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(f\"üèÜ WINNER: {winner[0]}\")\n",
    "print(f\"   Sharpe: {winner[1]['sharpe']:.2f}\")\n",
    "print(f\"   Return: {winner[1]['return']*100:.1f}%\")\n",
    "print(f\"   Win Rate: {winner[1]['win_rate']*100:.1f}%\")\n",
    "\n",
    "if 'Genetic' in winner[0] or 'RL' in winner[0]:\n",
    "    print(\"\\nüéâ AI BEATS HUMAN STRATEGIES!\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Human strategies still win. Need more training or features.\")\n",
    "\n",
    "# === SAVE EVERYTHING ===\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üíæ SAVING ALL DISCOVERIES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "discoveries = {\n",
    "    'ticker': ticker,\n",
    "    'data_years': len(df) / 252,\n",
    "    'features_count': feature_count,\n",
    "    'comparison': {\n",
    "        k: {key: float(val) if isinstance(val, (np.floating, float)) else val \n",
    "            for key, val in v.items()}\n",
    "        for k, v in final_comparison.items()\n",
    "    },\n",
    "    'best_formula': str(best_formula) if best_formula else None,\n",
    "    'human_strategies': {\n",
    "        k: {key: float(val) if isinstance(val, (np.floating, float)) else val \n",
    "            for key, val in v.items()}\n",
    "        for k, v in human_results.items()\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('hardcore_discoveries.json', 'w') as f:\n",
    "    json.dump(discoveries, f, indent=2)\n",
    "print(\"‚úì Saved: hardcore_discoveries.json\")\n",
    "\n",
    "# Save models\n",
    "models = {\n",
    "    'q_table': agent.q_table,\n",
    "    'bins': agent.bins,\n",
    "    'scaler': env.scaler,\n",
    "    'features': rl_features\n",
    "}\n",
    "with open('hardcore_models.pkl', 'wb') as f:\n",
    "    pickle.dump(models, f)\n",
    "print(\"‚úì Saved: hardcore_models.pkl\")\n",
    "\n",
    "# === RECOMMENDATIONS ===\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üöÄ TO GET BIGGER GAINS (like your 4.73%):\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\"\"\n",
    "1. INCREASE EVOLUTION PARAMETERS:\n",
    "   - Change pop_size=1000, generations=500\n",
    "   - This will take longer but find better formulas\n",
    "   \n",
    "2. FOCUS ON BIG MOVES ONLY:\n",
    "   - Filter to only trade when Big_Move_Up or Big_Move_Down predicted\n",
    "   - These are >1% moves (like your 4.73% day)\n",
    "\n",
    "3. ADD INTRADAY DATA:\n",
    "   - 1-hour or 15-minute bars give more patterns\n",
    "   - Use yfinance with interval='1h'\n",
    "\n",
    "4. MULTI-ASSET:\n",
    "   - Train on QQQ, IWM, individual stocks\n",
    "   - Some assets have more predictable patterns\n",
    "\n",
    "5. COMBINE SIGNALS:\n",
    "   - Only trade when 3+ methods agree\n",
    "   - (Genetic + RL + Human strategy)\n",
    "\n",
    "6. REAL-TIME FEATURES:\n",
    "   - VIX level and change\n",
    "   - Sector rotation\n",
    "   - Market breadth (A/D ratio)\n",
    "   - Pre-market gaps\n",
    "\n",
    "7. REGIME DETECTION:\n",
    "   - Bull market vs Bear market\n",
    "   - High vol vs Low vol\n",
    "   - Train different models for each\n",
    "\n",
    "8. WALK-FORWARD VALIDATION:\n",
    "   - Train on 2000-2020, test on 2021-2024\n",
    "   - Prevents overfitting\n",
    "\"\"\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
