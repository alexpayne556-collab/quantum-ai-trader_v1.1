{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68d808c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Install Dependencies\n",
    "# Install necessary libraries for Colab environment\n",
    "!pip install yfinance pyts deap gym talib-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1db4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.decomposition import PCA\n",
    "import torch\n",
    "import yfinance as yf\n",
    "import talib\n",
    "from pyts.image import GramianAngularField\n",
    "from deap import base, creator, tools, gp, algorithms\n",
    "import operator\n",
    "import gym\n",
    "from gym import spaces\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9a7459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Stage 1: Data Preparation\n",
    "# 1. Get data (10 years minimum for robust patterns)\n",
    "print(\"Loading data...\")\n",
    "ticker = \"SPY\"  # or your asset\n",
    "df = yf.download(ticker, start=\"2014-01-01\", end=\"2024-12-31\", progress=False)\n",
    "\n",
    "# Handle MultiIndex columns if present (yfinance update)\n",
    "if isinstance(df.columns, pd.MultiIndex):\n",
    "    df.columns = df.columns.get_level_values(0)\n",
    "\n",
    "print(f\"✓ Loaded {len(df)} days of data\")\n",
    "\n",
    "# 2. Compute technical indicators\n",
    "# Ensure we have enough data\n",
    "if len(df) > 50:\n",
    "    df['RSI'] = talib.RSI(df['Close'], timeperiod=14)\n",
    "    df['ATR'] = talib.ATR(df['High'], df['Low'], df['Close'], timeperiod=14)\n",
    "    df['SMA20'] = talib.SMA(df['Close'], timeperiod=20)\n",
    "    df['SMA50'] = talib.SMA(df['Close'], timeperiod=50)\n",
    "    df['Volume_MA'] = df['Volume'].rolling(20).mean()\n",
    "    \n",
    "    # Drop NaNs created by indicators\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "# 3. Create GASF images (visual representation)\n",
    "print(\"Creating GASF images...\")\n",
    "gasf = GramianAngularField(image_size=64, method='summation')\n",
    "\n",
    "# Convert prices to returns (stationary)\n",
    "returns = np.log(df['Close'] / df['Close'].shift(1)).dropna().values\n",
    "\n",
    "# Create rolling 20-day windows as GASF images\n",
    "window_size = 20\n",
    "gasf_images = []\n",
    "gasf_indices = []\n",
    "\n",
    "# We need to align indices with the dataframe\n",
    "# The returns array is 1 shorter than df (due to shift)\n",
    "# We start loop from 0, which corresponds to df index 1\n",
    "for i in range(len(returns) - window_size):\n",
    "    window = returns[i:i+window_size].reshape(1, -1)\n",
    "    try:\n",
    "        gasf_img = gasf.fit_transform(window)\n",
    "        gasf_images.append(gasf_img[0]) # fit_transform returns (n_samples, image_size, image_size)\n",
    "        # The index in df corresponding to the END of this window\n",
    "        # returns[0] is change from day 0 to 1.\n",
    "        # window returns[i:i+20] covers days i+1 to i+20.\n",
    "        # The prediction is for day i+21 onwards.\n",
    "        gasf_indices.append(i + window_size) \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "gasf_images = np.array(gasf_images)\n",
    "print(f\"✓ Created {len(gasf_images)} GASF images\")\n",
    "\n",
    "# 4. Create labels (future returns)\n",
    "# We want to predict returns AFTER the window\n",
    "df['Returns'] = np.log(df['Close'] / df['Close'].shift(1))\n",
    "df['Future_5d_Return'] = df['Returns'].rolling(5).sum().shift(-5)\n",
    "df['Label'] = (df['Future_5d_Return'] > 0).astype(int)\n",
    "\n",
    "# Align data for subsequent stages\n",
    "# gasf_indices points to the row in df that is the LAST day of the window.\n",
    "# We want to predict Future_5d_Return from that day.\n",
    "valid_indices = [idx for idx in gasf_indices if idx < len(df)]\n",
    "aligned_future_returns = df['Future_5d_Return'].iloc[valid_indices].values\n",
    "aligned_gasf_images = gasf_images[:len(valid_indices)]\n",
    "\n",
    "# Remove NaNs from alignment (end of dataset)\n",
    "mask = ~np.isnan(aligned_future_returns)\n",
    "aligned_gasf_images = aligned_gasf_images[mask]\n",
    "aligned_future_returns = aligned_future_returns[mask]\n",
    "aligned_indices = np.array(valid_indices)[mask]\n",
    "\n",
    "print(f\"✓ Data ready for discovery. Samples: {len(aligned_gasf_images)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941c4e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Stage 2: Unsupervised Visual Discovery\n",
    "class VisualPatternFinder:\n",
    "    \"\"\"Cluster GASF images - find recurring visual structures.\"\"\"\n",
    "    \n",
    "    def __init__(self, n_patterns=10):\n",
    "        self.n_patterns = n_patterns\n",
    "        self.kmeans = None\n",
    "        self.patterns = {}\n",
    "    \n",
    "    def discover_visual_patterns(self, gasf_images, future_returns):\n",
    "        \"\"\"\n",
    "        Cluster images → find which clusters are profitable.\n",
    "        \"\"\"\n",
    "        # Reshape for clustering (flatten images)\n",
    "        n_samples, h, w = gasf_images.shape\n",
    "        X = gasf_images.reshape(n_samples, h*w)\n",
    "        \n",
    "        # Cluster\n",
    "        self.kmeans = KMeans(n_clusters=self.n_patterns, random_state=42, n_init=10)\n",
    "        clusters = self.kmeans.fit_predict(X)\n",
    "        \n",
    "        # Analyze each cluster\n",
    "        print(\"\\nVISUAL PATTERN ANALYSIS\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        for cluster_id in range(self.n_patterns):\n",
    "            mask = clusters == cluster_id\n",
    "            cluster_returns = future_returns[mask]\n",
    "            \n",
    "            if len(cluster_returns) == 0:\n",
    "                continue\n",
    "\n",
    "            # Statistics\n",
    "            avg_return = np.mean(cluster_returns)\n",
    "            win_rate = (cluster_returns > 0).mean()\n",
    "            frequency = mask.sum() / len(clusters)\n",
    "            std_dev = np.std(cluster_returns) + 1e-8\n",
    "            sharpe = avg_return / std_dev * np.sqrt(252/5) # Annualized roughly\n",
    "            \n",
    "            print(f\"\\nPattern {cluster_id}:\")\n",
    "            print(f\"  Frequency: {frequency*100:.1f}% of days\")\n",
    "            print(f\"  Next-5d return: {avg_return*100:.2f}%\")\n",
    "            print(f\"  Win rate: {win_rate*100:.1f}%\")\n",
    "            print(f\"  Sharpe: {sharpe:.2f}\")\n",
    "            \n",
    "            if avg_return > 0.005: # Threshold for \"profitable\"\n",
    "                print(f\"  ✓ PROFITABLE PATTERN FOUND\")\n",
    "            \n",
    "            self.patterns[cluster_id] = {\n",
    "                'avg_return': avg_return,\n",
    "                'win_rate': win_rate,\n",
    "                'frequency': frequency,\n",
    "                'sharpe': sharpe,\n",
    "                'centroid': self.kmeans.cluster_centers_[cluster_id].reshape(h, w)\n",
    "            }\n",
    "            \n",
    "    def plot_patterns(self):\n",
    "        \"\"\"Visualize the centroids of discovered patterns.\"\"\"\n",
    "        if not self.patterns:\n",
    "            print(\"No patterns discovered yet.\")\n",
    "            return\n",
    "            \n",
    "        fig, axes = plt.subplots(2, (self.n_patterns + 1) // 2, figsize=(15, 6))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        for i, (cluster_id, stats) in enumerate(self.patterns.items()):\n",
    "            if i < len(axes):\n",
    "                axes[i].imshow(stats['centroid'], cmap='rainbow', origin='lower')\n",
    "                axes[i].set_title(f\"P{cluster_id}: WR {stats['win_rate']:.2f}\")\n",
    "                axes[i].axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Discover patterns\n",
    "finder = VisualPatternFinder(n_patterns=8)\n",
    "finder.discover_visual_patterns(aligned_gasf_images, aligned_future_returns)\n",
    "finder.plot_patterns()\n",
    "\n",
    "print(\"\\n✓ DISCOVERED: Which price shapes predict returns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4304bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Stage 3: Rare Structure Detection\n",
    "class RareStateDetector:\n",
    "    \"\"\"Find anomalous market structures.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.pca = PCA(n_components=0.95) # Keep 95% variance\n",
    "        self.iso_forest = IsolationForest(contamination=0.05, random_state=42)\n",
    "    \n",
    "    def find_rare_states(self, df):\n",
    "        \"\"\"Analyze: What rare states precede big moves?\"\"\"\n",
    "        \n",
    "        # Features\n",
    "        feature_cols = ['RSI', 'ATR', 'Volume_MA', 'SMA20', 'SMA50']\n",
    "        data_subset = df[feature_cols].copy()\n",
    "        data_subset.dropna(inplace=True)\n",
    "        \n",
    "        features = data_subset.values\n",
    "        \n",
    "        # Standardize\n",
    "        features = StandardScaler().fit_transform(features)\n",
    "        \n",
    "        # Reduce dimensions\n",
    "        features_reduced = self.pca.fit_transform(features)\n",
    "        \n",
    "        # Find anomalies\n",
    "        anomalies = self.iso_forest.fit_predict(features_reduced)\n",
    "        # -1 is anomaly, 1 is normal\n",
    "        anomaly_indices = np.where(anomalies == -1)[0]\n",
    "        \n",
    "        print(\"\\nRARE STATE ANALYSIS\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"Found {len(anomaly_indices)} rare states (top 5%)\")\n",
    "        \n",
    "        # For each rare state, check next returns\n",
    "        # We need to map these indices back to the dataframe to get future returns\n",
    "        # data_subset indices match df indices if we are careful\n",
    "        \n",
    "        rare_returns = []\n",
    "        \n",
    "        for idx in anomaly_indices:\n",
    "            # Get the actual index in the dataframe\n",
    "            df_idx = data_subset.index[idx]\n",
    "            \n",
    "            # Look up future return\n",
    "            if df_idx in df.index:\n",
    "                ret = df.loc[df_idx, 'Future_5d_Return']\n",
    "                if not np.isnan(ret):\n",
    "                    rare_returns.append(ret)\n",
    "        \n",
    "        rare_returns = np.array(rare_returns)\n",
    "            \n",
    "        if len(rare_returns) > 0:\n",
    "            print(f\"After rare states:\")\n",
    "            print(f\"  Average return: {np.mean(rare_returns)*100:.2f}%\")\n",
    "            print(f\"  Win rate: {(rare_returns > 0).mean()*100:.1f}%\")\n",
    "            print(f\"  Max drawdown: {np.min(rare_returns)*100:.2f}%\")\n",
    "            \n",
    "            if np.mean(rare_returns) < -0.01:\n",
    "                print(f\"  ⚠️ RARE STATES PRECEDE CRASHES!\")\n",
    "            elif np.mean(rare_returns) > 0.01:\n",
    "                print(f\"  ✓ RARE STATES PRECEDE RALLIES!\")\n",
    "            else:\n",
    "                print(f\"  ℹ️ Rare states are neutral/noisy.\")\n",
    "\n",
    "detector = RareStateDetector()\n",
    "detector.find_rare_states(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e8f272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Stage 4: Symbolic Regression (Genetic Programming)\n",
    "class FormulEvolver:\n",
    "    \"\"\"Genetic programming: evolve trading formulas.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Check if creator classes already exist to avoid errors on re-run\n",
    "        if not hasattr(creator, \"FitnessMax\"):\n",
    "            creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "        if not hasattr(creator, \"Individual\"):\n",
    "            creator.create(\"Individual\", gp.PrimitiveTree, fitness=creator.FitnessMax)\n",
    "        \n",
    "        self.toolbox = base.Toolbox()\n",
    "        self.pset = gp.PrimitiveSet(\"MAIN\", 5)  # 5 inputs: RSI, ATR, SMA20, SMA50, VolMA\n",
    "        \n",
    "        # Rename arguments for clarity in output\n",
    "        self.pset.renameArguments(ARG0='RSI', ARG1='ATR', ARG2='SMA20', ARG3='SMA50', ARG4='VolMA')\n",
    "        \n",
    "        # Operations\n",
    "        self.pset.addPrimitive(operator.add, 2, name='add')\n",
    "        self.pset.addPrimitive(operator.sub, 2, name='sub')\n",
    "        self.pset.addPrimitive(operator.mul, 2, name='mul')\n",
    "        def protected_div(x, y):\n",
    "            return x / (y + 1e-8)\n",
    "        self.pset.addPrimitive(protected_div, 2, name='div')\n",
    "        def protected_sqrt(x):\n",
    "            return np.sqrt(np.abs(x))\n",
    "        self.pset.addPrimitive(protected_sqrt, 1, name='sqrt')\n",
    "        self.pset.addPrimitive(np.sin, 1, name='sin')\n",
    "        self.pset.addPrimitive(np.tanh, 1, name='tanh')\n",
    "        \n",
    "        self.pset.addTerminal(1.0, name='const_1')\n",
    "        self.pset.addTerminal(0.5, name='const_0.5')\n",
    "        \n",
    "        self.toolbox.register(\"expr\", gp.genHalfAndHalf, pset=self.pset, min_=1, max_=3)\n",
    "        self.toolbox.register(\"individual\", tools.initIterate, creator.Individual, self.toolbox.expr)\n",
    "        self.toolbox.register(\"population\", tools.initRepeat, list, self.toolbox.individual)\n",
    "        \n",
    "        self.toolbox.register(\"evaluate\", self.eval_formula)\n",
    "        self.toolbox.register(\"mate\", gp.cxOnePoint)\n",
    "        self.toolbox.register(\"mutate\", gp.mutUniform, expr=self.toolbox.expr, pset=self.pset)\n",
    "        self.toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "        \n",
    "        # Limit tree height to prevent bloat\n",
    "        self.toolbox.decorate(\"mate\", gp.staticLimit(key=operator.attrgetter(\"height\"), max_value=17))\n",
    "        self.toolbox.decorate(\"mutate\", gp.staticLimit(key=operator.attrgetter(\"height\"), max_value=17))\n",
    "    \n",
    "    def eval_formula(self, individual, X, y):\n",
    "        \"\"\"Evaluate formula on data.\"\"\"\n",
    "        func = gp.compile(individual, self.pset)\n",
    "        \n",
    "        # X is (n_samples, 5)\n",
    "        # We need to pass columns as arguments\n",
    "        try:\n",
    "            # Apply function to all rows\n",
    "            # func expects 5 arguments. We can unpack columns.\n",
    "            # Note: This might be slow if not vectorized. \n",
    "            # DEAP functions usually work on scalars, but numpy functions work on arrays.\n",
    "            # If primitives are numpy-compatible, we can pass arrays directly.\n",
    "            pred = func(X[:,0], X[:,1], X[:,2], X[:,3], X[:,4])\n",
    "            \n",
    "            # Check for NaNs or Infs\n",
    "            if np.isnan(pred).any() or np.isinf(pred).any():\n",
    "                return (-100.0,)\n",
    "                \n",
    "            # Metric: Correlation with future returns\n",
    "            # We want high absolute correlation (can be negative, we just flip signal)\n",
    "            # But here we optimize for positive correlation\n",
    "            correlation = np.corrcoef(pred, y)[0, 1]\n",
    "            \n",
    "            if np.isnan(correlation):\n",
    "                return (-100.0,)\n",
    "            \n",
    "            return (correlation,)\n",
    "            \n",
    "        except Exception as e:\n",
    "            return (-100.0,)\n",
    "    \n",
    "    def evolve(self, X, y, pop_size=100, generations=10):\n",
    "        \"\"\"Evolve formulas.\"\"\"\n",
    "        pop = self.toolbox.population(n=pop_size)\n",
    "        hof = tools.HallOfFame(5)\n",
    "        \n",
    "        stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "        stats.register(\"avg\", np.mean)\n",
    "        stats.register(\"max\", np.max)\n",
    "        \n",
    "        # Pass X and y to evaluate\n",
    "        # We need to register evaluate with fixed arguments or use partial\n",
    "        # But DEAP expects evaluate(individual). \n",
    "        # We can't easily pass X, y in register.\n",
    "        # Hack: Bind X and y to the method before running\n",
    "        self.toolbox.register(\"evaluate\", self.eval_formula, X=X, y=y)\n",
    "        \n",
    "        pop, log = algorithms.eaSimple(\n",
    "            pop, self.toolbox,\n",
    "            cxpb=0.7, mutpb=0.2,\n",
    "            ngen=generations,\n",
    "            stats=stats,\n",
    "            halloffame=hof,\n",
    "            verbose=True\n",
    "        )\n",
    "        \n",
    "        return hof, log\n",
    "\n",
    "# Prepare data for Evolution\n",
    "feature_cols = ['RSI', 'ATR', 'SMA20', 'SMA50', 'Volume_MA']\n",
    "data_subset = df[feature_cols + ['Future_5d_Return']].dropna()\n",
    "\n",
    "X_features = data_subset[feature_cols].values\n",
    "y_returns = data_subset['Future_5d_Return'].values\n",
    "\n",
    "# Normalize features for better evolution stability\n",
    "X_features = StandardScaler().fit_transform(X_features)\n",
    "\n",
    "# Evolve\n",
    "print(\"\\nFORMULA EVOLUTION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "evolver = FormulEvolver()\n",
    "# Reduced generations for demo speed\n",
    "best_formulas, log = evolver.evolve(X_features, y_returns, pop_size=50, generations=10)\n",
    "\n",
    "print(\"\\nBest discovered formulas:\")\n",
    "for i, formula in enumerate(best_formulas[:3]):\n",
    "    correlation = formula.fitness.values[0]\n",
    "    print(f\"\\n{i+1}. Correlation: {correlation:.4f}\")\n",
    "    print(f\"   Formula: {gp.stringify(formula)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385c823b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Stage 5: RL with Curiosity\n",
    "class TradingEnvWithCuriosity(gym.Env):\n",
    "    \"\"\"RL environment where agent learns to find profitable sequences.\"\"\"\n",
    "    \n",
    "    def __init__(self, df, window=20):\n",
    "        super(TradingEnvWithCuriosity, self).__init__()\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.window = window\n",
    "        self.current_idx = window\n",
    "        self.max_idx = len(df) - 5 # Leave room for future return calc\n",
    "        \n",
    "        # Actions: 0=SELL, 1=HOLD, 2=BUY\n",
    "        self.action_space = spaces.Discrete(3)\n",
    "        \n",
    "        # Observation: RSI, ATR, Vol, SMA diffs\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=-np.inf,\n",
    "            high=np.inf,\n",
    "            shape=(5,), \n",
    "            dtype=np.float32\n",
    "        )\n",
    "    \n",
    "    def reset(self):\n",
    "        self.current_idx = np.random.randint(self.window, self.max_idx - 100)\n",
    "        return self._get_state()\n",
    "    \n",
    "    def step(self, action):\n",
    "        # Get returns for the NEXT day (or next 5 days)\n",
    "        # Here we simulate a 1-day step\n",
    "        current_return = self.df['Returns'].iloc[self.current_idx]\n",
    "        \n",
    "        # Reward logic\n",
    "        # 0=SELL (short), 1=HOLD (flat), 2=BUY (long)\n",
    "        # Map to -1, 0, 1\n",
    "        position = action - 1 \n",
    "        \n",
    "        # Simple PnL reward\n",
    "        reward = position * current_return * 100 \n",
    "        \n",
    "        # Curiosity/Entropy bonus could be added here (simplified for now)\n",
    "        \n",
    "        self.current_idx += 1\n",
    "        done = self.current_idx >= self.max_idx\n",
    "        \n",
    "        return self._get_state(), reward, done, {}\n",
    "    \n",
    "    def _get_state(self):\n",
    "        idx = self.current_idx\n",
    "        # Ensure we don't go out of bounds\n",
    "        if idx >= len(self.df):\n",
    "            idx = len(self.df) - 1\n",
    "            \n",
    "        # Simple normalization on the fly\n",
    "        rsi = self.df['RSI'].iloc[idx] / 100.0\n",
    "        atr = self.df['ATR'].iloc[idx] / (self.df['Close'].iloc[idx] + 1e-8)\n",
    "        vol = np.log(self.df['Volume'].iloc[idx] / (self.df['Volume_MA'].iloc[idx] + 1e-8) + 1e-8)\n",
    "        sma20 = (self.df['Close'].iloc[idx] - self.df['SMA20'].iloc[idx]) / (self.df['SMA20'].iloc[idx] + 1e-8)\n",
    "        sma50 = (self.df['Close'].iloc[idx] - self.df['SMA50'].iloc[idx]) / (self.df['SMA50'].iloc[idx] + 1e-8)\n",
    "        \n",
    "        return np.array([rsi, atr, vol, sma20, sma50], dtype=np.float32)\n",
    "\n",
    "print(\"\\nRL ENVIRONMENT SETUP\")\n",
    "print(\"=\" * 60)\n",
    "env = TradingEnvWithCuriosity(df)\n",
    "obs = env.reset()\n",
    "print(\"Observation space:\", env.observation_space)\n",
    "print(\"Action space:\", env.action_space)\n",
    "print(\"Initial observation:\", obs)\n",
    "print(\"Agent ready to explore.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759fd60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Stage 6: Multimodal Fusion\n",
    "class EnsembleAlphaDiscovery:\n",
    "    \"\"\"Combine all discovery methods.\"\"\"\n",
    "    \n",
    "    def __init__(self, visual_finder, rare_detector, best_formula):\n",
    "        self.visual = visual_finder\n",
    "        self.rare = rare_detector\n",
    "        self.formula = best_formula\n",
    "        self.pset = gp.PrimitiveSet(\"MAIN\", 5) # Re-define or pass from evolver\n",
    "        # Re-setup pset for compilation\n",
    "        self.pset.renameArguments(ARG0='RSI', ARG1='ATR', ARG2='SMA20', ARG3='SMA50', ARG4='VolMA')\n",
    "        self.pset.addPrimitive(operator.add, 2, name='add')\n",
    "        self.pset.addPrimitive(operator.sub, 2, name='sub')\n",
    "        self.pset.addPrimitive(operator.mul, 2, name='mul')\n",
    "        def protected_div(x, y): return x / (y + 1e-8)\n",
    "        self.pset.addPrimitive(protected_div, 2, name='div')\n",
    "        def protected_sqrt(x): return np.sqrt(np.abs(x))\n",
    "        self.pset.addPrimitive(protected_sqrt, 1, name='sqrt')\n",
    "        self.pset.addPrimitive(np.sin, 1, name='sin')\n",
    "        self.pset.addPrimitive(np.tanh, 1, name='tanh')\n",
    "        self.pset.addTerminal(1.0, name='const_1')\n",
    "        self.pset.addTerminal(0.5, name='const_0.5')\n",
    "        \n",
    "        self.compiled_formula = gp.compile(self.formula, self.pset)\n",
    "    \n",
    "    def get_ensemble_signal(self, current_state_dict, gasf_img):\n",
    "        \"\"\"Query all modalities.\"\"\"\n",
    "        \n",
    "        votes = {}\n",
    "        \n",
    "        # 1. Visual Vote\n",
    "        # Predict cluster\n",
    "        if self.visual.kmeans:\n",
    "            cluster = self.visual.kmeans.predict(gasf_img.reshape(1, -1))[0]\n",
    "            pattern_stats = self.visual.patterns.get(cluster, {})\n",
    "            # Vote is avg_return scaled\n",
    "            votes['visual'] = np.sign(pattern_stats.get('avg_return', 0))\n",
    "        else:\n",
    "            votes['visual'] = 0\n",
    "            \n",
    "        # 2. Genetic Vote\n",
    "        # Evaluate formula\n",
    "        try:\n",
    "            f_val = self.compiled_formula(\n",
    "                current_state_dict['RSI'], \n",
    "                current_state_dict['ATR'], \n",
    "                current_state_dict['SMA20'], \n",
    "                current_state_dict['SMA50'], \n",
    "                current_state_dict['Volume_MA']\n",
    "            )\n",
    "            votes['genetic'] = np.sign(f_val)\n",
    "        except:\n",
    "            votes['genetic'] = 0\n",
    "            \n",
    "        # 3. Rare Vote\n",
    "        # (Simplified: if rare, assume reversion or momentum based on history)\n",
    "        # For now, random placeholder or neutral\n",
    "        votes['rare'] = 0 \n",
    "        \n",
    "        consensus = np.mean(list(votes.values()))\n",
    "        \n",
    "        return {\n",
    "            'signal': consensus,\n",
    "            'votes': votes,\n",
    "        }\n",
    "\n",
    "print(\"✓ Ensemble ready: Uses all discovery methods\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9207a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Stage 7: Statistical Validation\n",
    "def is_discovery_real(predictions, returns, n_permutations=100):\n",
    "    \"\"\"Is accuracy better than random?\"\"\"\n",
    "    \n",
    "    # Align lengths\n",
    "    min_len = min(len(predictions), len(returns))\n",
    "    predictions = predictions[:min_len]\n",
    "    returns = returns[:min_len]\n",
    "    \n",
    "    # Calculate real accuracy (Directional)\n",
    "    # predictions are -1, 0, 1. returns are float.\n",
    "    # Match signs\n",
    "    correct = np.sign(predictions) == np.sign(returns)\n",
    "    real_accuracy = correct.mean()\n",
    "    \n",
    "    perm_accuracies = []\n",
    "    for _ in range(n_permutations):\n",
    "        shuffled = np.random.permutation(returns)\n",
    "        acc = (np.sign(predictions) == np.sign(shuffled)).mean()\n",
    "        perm_accuracies.append(acc)\n",
    "    \n",
    "    p_value = (np.array(perm_accuracies) >= real_accuracy).mean()\n",
    "    \n",
    "    print(f\"Real accuracy: {real_accuracy:.4f}\")\n",
    "    print(f\"Random accuracy: {np.mean(perm_accuracies):.4f}\")\n",
    "    print(f\"P-value: {p_value:.4f}\")\n",
    "    \n",
    "    return p_value < 0.05  # Significant?\n",
    "\n",
    "print(\"Validation function ready.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
