{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66eb0f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# CELL 1: ENVIRONMENT SETUP (COLAB NATIVE - V4)\n",
    "# ==========================================\n",
    "\n",
    "print(\"ðŸ”§ Setting up production environment...\")\n",
    "\n",
    "# STRATEGY: Use Colab's pre-installed packages (don't fight the system)\n",
    "# Colab already has: numpy 2.x, scipy 1.13, pandas 2.x, sklearn 1.x\n",
    "\n",
    "# Only install what's missing or needs upgrade\n",
    "!pip install -q yfinance xgboost==2.0.3 lightgbm==4.1.0 joblib python-dotenv\n",
    "\n",
    "# Optional: pandas-ta (fallback to manual TA if fails)\n",
    "!pip install -q pandas-ta 2>/dev/null || echo \"âš ï¸ pandas-ta skipped (will use manual TA)\"\n",
    "\n",
    "print(\"âœ… Packages installed - importing...\")\n",
    "\n",
    "# Core imports\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import scipy\n",
    "import sklearn\n",
    "import joblib\n",
    "import requests\n",
    "import warnings\n",
    "import json\n",
    "import logging\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from typing import List, Dict, Tuple\n",
    "import os\n",
    "\n",
    "# Try pandas-ta (fallback to manual TA if fails)\n",
    "try:\n",
    "    import pandas_ta as ta\n",
    "    HAS_PANDAS_TA = True\n",
    "except:\n",
    "    HAS_PANDAS_TA = False\n",
    "    print(\"âš ï¸ pandas-ta not available, using manual TA calculations\")\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger('Alpha76')\n",
    "\n",
    "# GPU Check\n",
    "try:\n",
    "    import torch\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"ðŸ”¥ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"ðŸ”¥ VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "    else:\n",
    "        print(\"âš ï¸ No GPU - training will use CPU (slower)\")\n",
    "except ImportError:\n",
    "    print(\"âš ï¸ PyTorch not found - XGBoost will try to use GPU directly\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ðŸ† HEDGEFUND KILLER - PRODUCTION TRAINER\")\n",
    "print(\"=\"*70)\n",
    "print(f\"âœ… NumPy: {np.__version__}\")\n",
    "print(f\"âœ… Scipy: {scipy.__version__}\")\n",
    "print(f\"âœ… Sklearn: {sklearn.__version__}\")\n",
    "print(f\"âœ… XGBoost: {xgb.__version__}\")\n",
    "print(f\"âœ… Pandas: {pd.__version__}\")\n",
    "print(f\"âœ… YFinance: {yf.__version__}\")\n",
    "print(f\"âœ… Pandas-TA: {'Available' if HAS_PANDAS_TA else 'Manual mode'}\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nðŸ’¡ Using Colab's native package versions (no conflicts)\")\n",
    "print(\"   This is the SMART way - don't fight the system!\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32034233",
   "metadata": {},
   "source": [
    "## ðŸšœ MODULE 1: DATA HARVESTER\n",
    "Production-grade data collection with quality checks and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d255f682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# MODULE 1: DATA HARVESTER\n",
    "# ==========================================\n",
    "\n",
    "class DataHarvester:\n",
    "    \"\"\"Download and validate market data\"\"\"\n",
    "    \n",
    "    def __init__(self, tickers: List[str], period: str = \"2y\", interval: str = \"1h\"):\n",
    "        self.tickers = tickers\n",
    "        self.period = period\n",
    "        self.interval = interval\n",
    "        \n",
    "    def harvest(self) -> pd.DataFrame:\n",
    "        \"\"\"Download with quality checks\"\"\"\n",
    "        logger.info(f\"ðŸšœ Harvesting {len(self.tickers)} tickers...\")\n",
    "        \n",
    "        data = yf.download(\n",
    "            self.tickers,\n",
    "            period=self.period,\n",
    "            interval=self.interval,\n",
    "            group_by='ticker',\n",
    "            auto_adjust=True,\n",
    "            progress=True,\n",
    "            threads=True\n",
    "        )\n",
    "        \n",
    "        dfs = []\n",
    "        warnings_list = []\n",
    "        \n",
    "        for ticker in self.tickers:\n",
    "            try:\n",
    "                df = data[ticker].copy() if len(self.tickers) > 1 else data.copy()\n",
    "                \n",
    "                if df.empty or df['Volume'].sum() == 0:\n",
    "                    warnings_list.append(f\"{ticker}: No data\")\n",
    "                    continue\n",
    "                \n",
    "                df['ticker'] = ticker\n",
    "                df.reset_index(inplace=True)\n",
    "                dfs.append(df)\n",
    "                \n",
    "                logger.info(f\"  âœ… {ticker}: {len(df)} bars\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                warnings_list.append(f\"{ticker}: {str(e)}\")\n",
    "        \n",
    "        if warnings_list:\n",
    "            logger.warning(f\"\\nâš ï¸ Warnings:\\n\" + \"\\n\".join([f\"  - {w}\" for w in warnings_list]))\n",
    "        \n",
    "        result = pd.concat(dfs, ignore_index=True)\n",
    "        logger.info(f\"\\nâœ… Total: {len(result):,} rows from {len(dfs)} tickers\")\n",
    "        \n",
    "        return result\n",
    "\n",
    "# ===================================================================\n",
    "# ðŸ† HEDGEFUND KILLER UNIVERSE - YOUR PERSONAL WATCHLIST (100+ TICKERS)\n",
    "# ===================================================================\n",
    "\n",
    "# ðŸ’¼ YOUR ROBINHOOD PORTFOLIO (Current Holdings - Track Daily)\n",
    "PORTFOLIO = [\n",
    "    'KDK', 'TLRY', 'SERV', 'RR', 'HOOD', 'LYFT', 'UBER',\n",
    "    'MVST', 'APLD', 'SGBX', 'LUNR', 'IONQ', 'XBIO', 'ASTS'\n",
    "]\n",
    "\n",
    "# ðŸ”¥ PERPLEXITY HOT PICKS (Trade Immediately - High Conviction)\n",
    "HOT_PICKS = [\n",
    "    'DGNX',  # +21% today, +293% revenue, $9.62 (Turnaround Momentum)\n",
    "    'ELWS',  # +145% revenue, 0.2s blockchain (Pre-explosive)\n",
    "    'PALI',  # $1.73â†’$12 target = 593% upside (Biotech Catapult)\n",
    "]\n",
    "\n",
    "# âš¡ IMMEDIATE ALPHA (Your Hot List - Super Volatile)\n",
    "IMMEDIATE_ALPHA = [\n",
    "    'SERV', 'SGBX', 'RR', 'IONQ', 'MVST', 'TLRY', 'MU', 'SMR', 'LEU'\n",
    "]\n",
    "\n",
    "# ðŸ§  QUANTUM & AI (The Future - High Beta)\n",
    "QUANTUM_AI = [\n",
    "    'RGTI', 'QUBT', 'PLTR', 'SOUN', 'BBAI', 'SYM', 'AI', 'IONQ'\n",
    "]\n",
    "\n",
    "# ðŸš€ SPACE & SATELLITE (Binary Outcomes - $0 or $100)\n",
    "SPACE = [\n",
    "    'RKLB', 'ASTS', 'LUNR', 'SPCE', 'PL', 'BKSY', 'SPIR', 'ACHR', 'JOBY'\n",
    "]\n",
    "\n",
    "# ðŸ’° CRYPTO & FINTECH (BTC Correlation - Liquidity Pump)\n",
    "CRYPTO_FINTECH = [\n",
    "    'MSTR', 'COIN', 'MARA', 'RIOT', 'CLSK', 'SOFI', 'UPST', 'AFRM', 'HOOD'\n",
    "]\n",
    "\n",
    "# âš¡ ENERGY & NUCLEAR (Power Grid Megatrend)\n",
    "ENERGY_NUCLEAR = [\n",
    "    'OKLO', 'NNE', 'FLNC', 'SHLS', 'SMR', 'LEU', 'PLUG', 'BE', 'QS'\n",
    "]\n",
    "\n",
    "# ðŸ§¬ BIOTECH (Catalyst-Driven - FDA Binary Events)\n",
    "BIOTECH = [\n",
    "    'CRSP', 'EDIT', 'NTLA', 'BEAM', 'VKTX', 'PALI', 'XBIO', 'RARE'\n",
    "]\n",
    "\n",
    "# ðŸ’» HIGH BETA TECH (EV, Semis, Consumer)\n",
    "TECH = [\n",
    "    'TSLA', 'LAZR', 'MBLY', 'INVZ', 'MVST', 'MU', 'DUOL', 'RBLX', 'DKNG'\n",
    "]\n",
    "\n",
    "# ðŸŽ¯ COMBINE INTO ULTIMATE UNIVERSE (Deduplicated)\n",
    "TICKERS = list(set(\n",
    "    PORTFOLIO + HOT_PICKS + IMMEDIATE_ALPHA + QUANTUM_AI + \n",
    "    SPACE + CRYPTO_FINTECH + ENERGY_NUCLEAR + BIOTECH + TECH\n",
    "))\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"ðŸ† HEDGEFUND KILLER - ULTIMATE ALPHA UNIVERSE\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Total Tickers: {len(TICKERS)}\")\n",
    "print(f\"\\n  ðŸ’¼ Your Portfolio: {len(PORTFOLIO)} (Current Holdings)\")\n",
    "print(f\"  ðŸ”¥ Hot Picks: {len(HOT_PICKS)} (Perplexity-Analyzed - IMMEDIATE ALPHA)\")\n",
    "print(f\"  âš¡ Immediate Alpha: {len(IMMEDIATE_ALPHA)} (Super Volatile)\")\n",
    "print(f\"  ðŸ§  Quantum/AI: {len(QUANTUM_AI)}\")\n",
    "print(f\"  ðŸš€ Space: {len(SPACE)}\")\n",
    "print(f\"  ðŸ’° Crypto/Fintech: {len(CRYPTO_FINTECH)}\")\n",
    "print(f\"  âš¡ Energy/Nuclear: {len(ENERGY_NUCLEAR)}\")\n",
    "print(f\"  ðŸ§¬ Biotech: {len(BIOTECH)}\")\n",
    "print(f\"  ðŸ’» High Beta Tech: {len(TECH)}\")\n",
    "print(f\"\\nðŸŽ¯ Hot Picks Details:\")\n",
    "print(f\"  â€¢ DGNX: +21% today, +293% revenue (Turnaround Momentum)\")\n",
    "print(f\"  â€¢ ELWS: +145% revenue, 0.2s blockchain (Pre-explosive)\")\n",
    "print(f\"  â€¢ PALI: $1.73â†’$12 target = 593% upside (Biotech Catalyst)\")\n",
    "print(f\"\\nðŸ† MISSION: Embarrass hedge fund billionaires in 6-12 months\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "harvester = DataHarvester(TICKERS)\n",
    "raw_data = harvester.harvest()\n",
    "\n",
    "print(f\"\\nðŸ“Š Data Range: {raw_data['Datetime'].min()} to {raw_data['Datetime'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c9cf41",
   "metadata": {},
   "source": [
    "## ðŸ§  MODULE 2: FEATURE ENGINE\n",
    "ATR-scaled triple barrier labels + volatility-adaptive indicators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17df8de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# MODULE 2: FEATURE ENGINE\n",
    "# ==========================================\n",
    "\n",
    "def calculate_atr(high, low, close, period=14):\n",
    "    \"\"\"Manual ATR calculation\"\"\"\n",
    "    tr1 = high - low\n",
    "    tr2 = abs(high - close.shift())\n",
    "    tr3 = abs(low - close.shift())\n",
    "    tr = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)\n",
    "    return tr.rolling(period).mean()\n",
    "\n",
    "def calculate_rsi(close, period=14):\n",
    "    \"\"\"Manual RSI calculation\"\"\"\n",
    "    delta = close.diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(period).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(period).mean()\n",
    "    rs = gain / (loss + 1e-9)\n",
    "    return 100 - (100 / (1 + rs))\n",
    "\n",
    "class FeatureEngine:\n",
    "    \"\"\"Production feature engineering\"\"\"\n",
    "    \n",
    "    def engineer(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        df = df.copy()\n",
    "        \n",
    "        if len(df) < 200:\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        # ATR foundation\n",
    "        if HAS_PANDAS_TA:\n",
    "            df['ATR_14'] = ta.atr(df['High'], df['Low'], df['Close'], length=14)\n",
    "        else:\n",
    "            df['ATR_14'] = calculate_atr(df['High'], df['Low'], df['Close'])\n",
    "        \n",
    "        df['ATR_pct'] = df['ATR_14'] / df['Close']\n",
    "        \n",
    "        # Microstructure\n",
    "        df['feat_spread'] = (df['High'] - df['Low']) / df['Close']\n",
    "        df['feat_vol_surge'] = df['Volume'] / (df['Volume'].rolling(20).mean() + 1e-9)\n",
    "        \n",
    "        # RSI (adaptive)\n",
    "        vol_20 = df['Close'].rolling(20).std() / df['Close']\n",
    "        is_volatile = vol_20 > vol_20.quantile(0.75)\n",
    "        \n",
    "        if HAS_PANDAS_TA:\n",
    "            rsi_fast = ta.rsi(df['Close'], length=7)\n",
    "            rsi_norm = ta.rsi(df['Close'], length=14)\n",
    "        else:\n",
    "            rsi_fast = calculate_rsi(df['Close'], 7)\n",
    "            rsi_norm = calculate_rsi(df['Close'], 14)\n",
    "        \n",
    "        df['feat_rsi'] = np.where(is_volatile, rsi_fast, rsi_norm)\n",
    "        \n",
    "        # Trend\n",
    "        df['feat_sma_20'] = df['Close'].rolling(20).mean()\n",
    "        df['feat_sma_50'] = df['Close'].rolling(50).mean()\n",
    "        df['feat_ema_12'] = df['Close'].ewm(span=12).mean()\n",
    "        df['feat_price_above_sma20'] = (df['Close'] > df['feat_sma_20']).astype(int)\n",
    "        \n",
    "        # Volume\n",
    "        df['feat_vol_mean'] = df['Volume'].rolling(20).mean()\n",
    "        df['feat_vol_trend'] = df['Volume'].rolling(5).mean() / (df['Volume'].rolling(20).mean() + 1)\n",
    "        \n",
    "        # Returns\n",
    "        df['feat_return_1h'] = df['Close'].pct_change(1)\n",
    "        df['feat_return_4h'] = df['Close'].pct_change(4)\n",
    "        df['feat_return_24h'] = df['Close'].pct_change(24)\n",
    "        \n",
    "        # ATR-SCALED TRIPLE BARRIER TARGET\n",
    "        df['upper_barrier'] = df['Close'] + (1.5 * df['ATR_14'])\n",
    "        df['lower_barrier'] = df['Close'] - (1.0 * df['ATR_14'])\n",
    "        \n",
    "        indexer = pd.api.indexers.FixedForwardWindowIndexer(window_size=5)\n",
    "        df['fwd_max'] = df['High'].rolling(window=indexer).max()\n",
    "        df['fwd_min'] = df['Low'].rolling(window=indexer).min()\n",
    "        \n",
    "        df['target'] = ((df['fwd_max'] >= df['upper_barrier']) & \n",
    "                        (df['fwd_min'] > df['lower_barrier'])).astype(int)\n",
    "        \n",
    "        # ðŸ”¥ PERPLEXITY HOT PICK FEATURES (Thesis-Specific Alpha)\n",
    "        ticker = df['ticker'].iloc[0] if 'ticker' in df.columns else None\n",
    "        \n",
    "        if ticker == 'DGNX':\n",
    "            # Turnaround Momentum: Track recovery from $0.45 lows\n",
    "            df['feat_recovery_pct'] = (df['Close'] - 0.45) / 0.45  # 2,037% at $9.62\n",
    "            df['feat_consolidation'] = (df['Close'].rolling(5).std() / df['Close']) < 0.02\n",
    "            \n",
    "        elif ticker == 'ELWS':\n",
    "            # Pre-explosive: Track coiling pattern\n",
    "            df['feat_vol_compression'] = df['Close'].rolling(20).std() / df['Close']\n",
    "            df['feat_vol_spike_ready'] = (df['Volume'].rolling(5).mean() / \n",
    "                                           df['Volume'].rolling(20).mean()) > 1.2\n",
    "            \n",
    "        elif ticker == 'PALI':\n",
    "            # Biotech Catalyst: Track dormant â†’ explosive\n",
    "            df['feat_rsi_neutral'] = ((df['feat_rsi'] > 40) & \n",
    "                                       (df['feat_rsi'] < 60)).astype(int)\n",
    "            df['feat_analyst_gap'] = 12.00 / df['Close']  # Distance to $12 target\n",
    "        \n",
    "        return df.dropna()\n",
    "\n",
    "logger.info(\"\\nðŸ§  Engineering features...\")\n",
    "\n",
    "feature_engine = FeatureEngine()\n",
    "all_features = []\n",
    "\n",
    "for ticker in raw_data['ticker'].unique():\n",
    "    ticker_df = raw_data[raw_data['ticker'] == ticker].copy()\n",
    "    features_df = feature_engine.engineer(ticker_df)\n",
    "    \n",
    "    if not features_df.empty:\n",
    "        all_features.append(features_df)\n",
    "        logger.info(f\"  âœ… {ticker}: {len(features_df)} rows, {features_df['target'].mean():.1%} BUY\")\n",
    "\n",
    "full_df = pd.concat(all_features, ignore_index=True)\n",
    "\n",
    "print(f\"\\nâœ… Features: {len(full_df):,} rows\")\n",
    "print(f\"   BUY signals: {full_df['target'].sum():,} ({full_df['target'].mean():.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ea28bb",
   "metadata": {},
   "source": [
    "## ðŸ¤– MODULE 3-4: REGIME + ENSEMBLE TRAINING\n",
    "IWM regime detection + XGBoost GPU training with walk-forward validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af788338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# MODULES 3-4: REGIME + ENSEMBLE\n",
    "# ==========================================\n",
    "\n",
    "class RegimeClassifier:\n",
    "    def classify_regime(self) -> str:\n",
    "        try:\n",
    "            iwm = yf.download('IWM', period='30d', interval='1d', progress=False)\n",
    "            vix_data = yf.download('^VIX', period='5d', interval='1d', progress=False)\n",
    "            \n",
    "            iwm_return = (iwm['Close'].iloc[-1] / iwm['Close'].iloc[-21] - 1) if len(iwm) >= 21 else 0\n",
    "            vix = vix_data['Close'].iloc[-1] if not vix_data.empty else 20\n",
    "            \n",
    "            logger.info(f\"ðŸ“Š IWM: {iwm_return:.2%} | VIX: {vix:.1f}\")\n",
    "            \n",
    "            if vix > 30:\n",
    "                return 'PANIC'\n",
    "            elif iwm_return > 0.05:\n",
    "                return 'BULL_LOW' if vix < 15 else 'BULL_MID'\n",
    "            elif iwm_return < -0.05:\n",
    "                return 'BEAR_LOW' if vix < 15 else 'BEAR_MID'\n",
    "            else:\n",
    "                return 'CHOPPY'\n",
    "        except:\n",
    "            return 'CHOPPY'\n",
    "\n",
    "regime_classifier = RegimeClassifier()\n",
    "current_regime = regime_classifier.classify_regime()\n",
    "print(f\"\\nðŸŒ Regime: {current_regime}\")\n",
    "\n",
    "# ENSEMBLE TRAINING\n",
    "class EnsembleClassifier:\n",
    "    def __init__(self):\n",
    "        self.results = []\n",
    "        \n",
    "    def train(self, X, y, n_splits=3):\n",
    "        features = [c for c in X.columns if 'feat_' in c]\n",
    "        X_features = X[features].copy()\n",
    "        \n",
    "        tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "        \n",
    "        for fold, (train_idx, test_idx) in enumerate(tscv.split(X_features), 1):\n",
    "            logger.info(f\"\\nðŸ”„ FOLD {fold}/{n_splits}\")\n",
    "            \n",
    "            X_train, X_test = X_features.iloc[train_idx], X_features.iloc[test_idx]\n",
    "            y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "            \n",
    "            # Scale\n",
    "            scaler = StandardScaler()\n",
    "            X_train_scaled = scaler.fit_transform(X_train)\n",
    "            X_test_scaled = scaler.transform(X_test)\n",
    "            \n",
    "            # Train\n",
    "            scale_pos_weight = (y_train == 0).sum() / max((y_train == 1).sum(), 1)\n",
    "            \n",
    "            model = xgb.XGBClassifier(\n",
    "                n_estimators=2000,\n",
    "                learning_rate=0.005,\n",
    "                max_depth=7,\n",
    "                subsample=0.7,\n",
    "                colsample_bytree=0.7,\n",
    "                scale_pos_weight=scale_pos_weight,\n",
    "                tree_method='hist',\n",
    "                device='cuda' if 'torch' in dir() and torch.cuda.is_available() else 'cpu',\n",
    "                early_stopping_rounds=100,\n",
    "                random_state=42\n",
    "            )\n",
    "            \n",
    "            model.fit(X_train_scaled, y_train, eval_set=[(X_test_scaled, y_test)], verbose=False)\n",
    "            \n",
    "            # Evaluate\n",
    "            preds = model.predict(X_test_scaled)\n",
    "            precision = precision_score(y_test, preds)\n",
    "            f1 = f1_score(y_test, preds)\n",
    "            auc = roc_auc_score(y_test, model.predict_proba(X_test_scaled)[:, 1])\n",
    "            \n",
    "            logger.info(f\"  Precision: {precision:.2%} | F1: {f1:.2%} | AUC: {auc:.2%}\")\n",
    "            \n",
    "            self.results.append({\n",
    "                'fold': fold,\n",
    "                'precision': precision,\n",
    "                'f1': f1,\n",
    "                'auc': auc,\n",
    "                'model': model,\n",
    "                'scaler': scaler,\n",
    "                'features': features\n",
    "            })\n",
    "        \n",
    "        avg_precision = np.mean([r['precision'] for r in self.results])\n",
    "        logger.info(f\"\\nðŸ† Avg Precision: {avg_precision:.2%}\")\n",
    "        \n",
    "        return self.results\n",
    "\n",
    "ensemble = EnsembleClassifier()\n",
    "features_for_training = [c for c in full_df.columns if 'feat_' in c]\n",
    "X_train = full_df[features_for_training]\n",
    "y_train = full_df['target']\n",
    "\n",
    "training_results = ensemble.train(X_train, y_train)\n",
    "\n",
    "best_result = max(training_results, key=lambda x: x['precision'])\n",
    "print(f\"\\nðŸ’¾ Best: Fold {best_result['fold']}, {best_result['precision']:.2%} precision\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8222121e",
   "metadata": {},
   "source": [
    "## ðŸ’¾ SAVE PRODUCTION ARTIFACTS\n",
    "Export trained models for deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fc1a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# SAVE MODELS\n",
    "# ==========================================\n",
    "\n",
    "logger.info(\"\\nðŸ’¾ Saving artifacts...\")\n",
    "\n",
    "joblib.dump(best_result['model'], 'alpha76_model.pkl')\n",
    "joblib.dump(best_result['scaler'], 'alpha76_scaler.pkl')\n",
    "\n",
    "metadata = {\n",
    "    'training_date': datetime.now().isoformat(),\n",
    "    'tickers': TICKERS,\n",
    "    'avg_precision': float(np.mean([r['precision'] for r in training_results])),\n",
    "    'avg_f1': float(np.mean([r['f1'] for r in training_results])),\n",
    "    'features': best_result['features'],\n",
    "    'current_regime': current_regime\n",
    "}\n",
    "\n",
    "with open('alpha76_metadata.json', 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ðŸ† TRAINING COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Precision: {metadata['avg_precision']:.2%}\")\n",
    "print(f\"F1 Score:  {metadata['avg_f1']:.2%}\")\n",
    "print(f\"Files: alpha76_model.pkl, alpha76_scaler.pkl, alpha76_metadata.json\")\n",
    "print(\"\\nðŸš‚ READY FOR DEPLOYMENT!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
