{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ca3597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 1: Install Dependencies\n",
    "# Run this first (takes 2-3 minutes)\n",
    "\n",
    "!apt-get install -y libta-lib-dev > /dev/null 2>&1\n",
    "!pip install -q TA-Lib yfinance lightgbm deap scikit-learn pandas numpy\n",
    "\n",
    "print(\"‚úÖ Dependencies installed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3488e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 2: Import Libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import talib\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score\n",
    "import lightgbm as lgb\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ Libraries imported!\")\n",
    "print(f\"üìä numpy: {np.__version__}\")\n",
    "print(f\"üìä pandas: {pd.__version__}\")\n",
    "print(f\"üìä lightgbm: {lgb.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59ce101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 3: UltimateFeatureEngine (50+ Indicators)\n",
    "\n",
    "class UltimateFeatureEngine:\n",
    "    def __init__(self, df):\n",
    "        self.df = df.copy()\n",
    "        if isinstance(self.df.columns, pd.MultiIndex):\n",
    "            self.df.columns = self.df.columns.get_level_values(0)\n",
    "        self.features = pd.DataFrame(index=df.index)\n",
    "    \n",
    "    def compute_all_indicators(self):\n",
    "        close = self.df['Close'].values\n",
    "        high = self.df['High'].values\n",
    "        low = self.df['Low'].values\n",
    "        volume = self.df['Volume'].values.astype(float)\n",
    "        open_price = self.df['Open'].values\n",
    "        \n",
    "        # Moving Averages\n",
    "        for period in [5, 10, 20, 50, 100, 200]:\n",
    "            self.features[f'SMA{period}'] = talib.SMA(close, period)\n",
    "            self.features[f'EMA{period}'] = talib.EMA(close, period)\n",
    "        \n",
    "        # EMA Ribbon\n",
    "        ema5, ema10, ema20, ema50 = [talib.EMA(close, p) for p in [5, 10, 20, 50]]\n",
    "        self.features['EMA_Bullish'] = ((ema5 > ema10) & (ema10 > ema20) & (ema20 > ema50)).astype(float)\n",
    "        self.features['EMA_Bearish'] = ((ema5 < ema10) & (ema10 < ema20) & (ema20 < ema50)).astype(float)\n",
    "        self.features['EMA_Width'] = (ema5 - ema50) / (close + 1e-8)\n",
    "        \n",
    "        # Momentum\n",
    "        self.features['RSI_7'] = talib.RSI(close, 7)\n",
    "        self.features['RSI_14'] = talib.RSI(close, 14)\n",
    "        self.features['RSI_21'] = talib.RSI(close, 21)\n",
    "        slowk, slowd = talib.STOCH(high, low, close, 14, 3, 0, 3, 0)\n",
    "        self.features['StochK'] = slowk\n",
    "        self.features['StochD'] = slowd\n",
    "        \n",
    "        # MACD\n",
    "        macd, signal, hist = talib.MACD(close, 12, 26, 9)\n",
    "        self.features['MACD'] = macd\n",
    "        self.features['MACD_Signal'] = signal\n",
    "        self.features['MACD_Hist'] = hist\n",
    "        \n",
    "        # Volatility\n",
    "        atr = talib.ATR(high, low, close, 14)\n",
    "        self.features['ATR'] = atr\n",
    "        self.features['ATR_Ratio'] = atr / (close + 1e-8)\n",
    "        bb_upper, bb_mid, bb_lower = talib.BBANDS(close, 20, 2, 2)\n",
    "        self.features['BB_Width'] = (bb_upper - bb_lower) / (bb_mid + 1e-8)\n",
    "        self.features['BB_Pos'] = (close - bb_lower) / (bb_upper - bb_lower + 1e-8)\n",
    "        \n",
    "        # Volume\n",
    "        vol_ma = talib.SMA(volume, 20)\n",
    "        self.features['Vol_Ratio'] = volume / (vol_ma + 1e-8)\n",
    "        self.features['OBV'] = talib.OBV(close, volume)\n",
    "        self.features['MFI'] = talib.MFI(high, low, close, volume, 14)\n",
    "        \n",
    "        # Trend\n",
    "        self.features['ADX'] = talib.ADX(high, low, close, 14)\n",
    "        self.features['PLUS_DI'] = talib.PLUS_DI(high, low, close, 14)\n",
    "        self.features['MINUS_DI'] = talib.MINUS_DI(high, low, close, 14)\n",
    "        \n",
    "        # Price Action\n",
    "        self.features['Body'] = np.abs(close - open_price) / (close + 1e-8)\n",
    "        self.features['Upper_Wick'] = (high - np.maximum(open_price, close)) / (close + 1e-8)\n",
    "        self.features['Lower_Wick'] = (np.minimum(open_price, close) - low) / (close + 1e-8)\n",
    "        self.features['Gap'] = (open_price - np.roll(close, 1)) / (np.roll(close, 1) + 1e-8)\n",
    "        \n",
    "        # Returns\n",
    "        self.features['Ret_1d'] = np.concatenate([[0], np.diff(close) / (close[:-1] + 1e-8)])\n",
    "        for p in [5, 10, 20]:\n",
    "            self.features[f'Ret_{p}d'] = (close - np.roll(close, p)) / (np.roll(close, p) + 1e-8)\n",
    "        \n",
    "        # Human patterns\n",
    "        sma50, sma200 = talib.SMA(close, 50), talib.SMA(close, 200)\n",
    "        self.features['Golden_Cross'] = np.nan_to_num(((sma50 > sma200) & (np.roll(sma50, 1) <= np.roll(sma200, 1))).astype(float))\n",
    "        self.features['Above_SMA200'] = (close > sma200).astype(float)\n",
    "        \n",
    "        return self.features.dropna()\n",
    "\n",
    "print(\"‚úÖ UltimateFeatureEngine defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b905e507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 4: Configuration\n",
    "\n",
    "# Full 30 tickers\n",
    "TICKERS = [\n",
    "    'SPY', 'QQQ', 'IWM', 'DIA', 'VTI',\n",
    "    'AAPL', 'MSFT', 'GOOGL', 'AMZN', 'NVDA', 'META', 'TSLA',\n",
    "    'AMD', 'NFLX', 'CRM', 'ADBE', 'PYPL',\n",
    "    'SQ', 'COIN', 'MARA', 'RIOT',\n",
    "    'ARKK', 'PLTR', 'RBLX', 'HOOD',\n",
    "    'XLK', 'XLV', 'XLE', 'XLF', 'XLY'\n",
    "]\n",
    "\n",
    "# Training config\n",
    "START_DATE = '2000-01-01'  # Maximum history\n",
    "TARGET_DAYS = 5           # 5-day forward return\n",
    "TARGET_THRESHOLD = 0.01   # 1% minimum return\n",
    "\n",
    "print(f\"‚úÖ Config set: {len(TICKERS)} tickers, {START_DATE} to today\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081ac8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 5: Load Multi-Asset Data\n",
    "\n",
    "all_X = []\n",
    "all_y = []\n",
    "scalers = {}\n",
    "feature_names = None\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä LOADING MULTI-ASSET DATA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for i, ticker in enumerate(TICKERS, 1):\n",
    "    print(f\"[{i}/{len(TICKERS)}] {ticker}...\", end=\" \")\n",
    "    try:\n",
    "        # Download data\n",
    "        df = yf.download(ticker, start=START_DATE, progress=False, auto_adjust=True)\n",
    "        if len(df) < 252:\n",
    "            print(\"‚ùå Insufficient data\")\n",
    "            continue\n",
    "        \n",
    "        # Generate features\n",
    "        engine = UltimateFeatureEngine(df)\n",
    "        features = engine.compute_all_indicators()\n",
    "        \n",
    "        if feature_names is None:\n",
    "            feature_names = list(features.columns)\n",
    "        \n",
    "        # Create target (5-day return > 1%)\n",
    "        target = (df['Close'].pct_change(TARGET_DAYS).shift(-TARGET_DAYS) > TARGET_THRESHOLD).astype(int)\n",
    "        \n",
    "        # Align\n",
    "        idx = features.index.intersection(target.dropna().index)\n",
    "        X = features.loc[idx]\n",
    "        y = target.loc[idx]\n",
    "        \n",
    "        # Scale\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "        scalers[ticker] = scaler\n",
    "        \n",
    "        all_X.append(X_scaled)\n",
    "        all_y.append(y.values)\n",
    "        \n",
    "        print(f\"‚úì {len(X):,} samples\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå {e}\")\n",
    "\n",
    "# Combine\n",
    "X_universal = np.vstack(all_X)\n",
    "y_universal = np.hstack(all_y)\n",
    "\n",
    "# Fit universal scaler\n",
    "universal_scaler = RobustScaler()\n",
    "X_universal = universal_scaler.fit_transform(X_universal)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"‚úÖ Total: {X_universal.shape[0]:,} samples, {X_universal.shape[1]} features\")\n",
    "print(f\"‚úÖ Positive rate: {y_universal.mean()*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bbb124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 6: Train Universal LightGBM Model\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ü§ñ TRAINING UNIVERSAL MODEL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Time-based split\n",
    "split = int(0.8 * len(X_universal))\n",
    "X_train, X_test = X_universal[:split], X_universal[split:]\n",
    "y_train, y_test = y_universal[:split], y_universal[split:]\n",
    "\n",
    "print(f\"Train: {len(X_train):,}, Test: {len(X_test):,}\")\n",
    "\n",
    "# LightGBM with GPU\n",
    "model = lgb.LGBMClassifier(\n",
    "    n_estimators=1000,\n",
    "    max_depth=8,\n",
    "    learning_rate=0.05,\n",
    "    num_leaves=63,\n",
    "    min_child_samples=100,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_alpha=0.1,\n",
    "    reg_lambda=0.1,\n",
    "    n_jobs=-1,\n",
    "    device='gpu',  # Use T4 GPU\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    callbacks=[lgb.early_stopping(50, verbose=False)]\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "train_acc = model.score(X_train, y_train)\n",
    "test_acc = model.score(X_test, y_test)\n",
    "y_proba = model.predict_proba(X_test)[:, 1]\n",
    "auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä MODEL PERFORMANCE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Train Accuracy: {train_acc:.4f}\")\n",
    "print(f\"Test Accuracy:  {test_acc:.4f}\")\n",
    "print(f\"AUC Score:      {auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d5df05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 7: Feature Importance\n",
    "\n",
    "print(\"\\nüîù TOP 20 MOST IMPORTANT FEATURES\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "importance = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "for i, row in importance.head(20).iterrows():\n",
    "    print(f\"{row['feature']:<30} {row['importance']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d73b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 8: Generate Today's Signals\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üì° TODAY'S TRADING SIGNALS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "signals = {}\n",
    "\n",
    "for ticker in TICKERS:\n",
    "    try:\n",
    "        # Get recent data\n",
    "        df = yf.download(ticker, period='1y', progress=False, auto_adjust=True)\n",
    "        if len(df) < 100:\n",
    "            continue\n",
    "        \n",
    "        # Generate features\n",
    "        engine = UltimateFeatureEngine(df)\n",
    "        features = engine.compute_all_indicators()\n",
    "        if features.empty:\n",
    "            continue\n",
    "        \n",
    "        # Get today's features\n",
    "        today = features.iloc[-1:]\n",
    "        \n",
    "        # Scale\n",
    "        if ticker in scalers:\n",
    "            today_scaled = scalers[ticker].transform(today)\n",
    "        else:\n",
    "            today_scaled = universal_scaler.transform(today)\n",
    "        \n",
    "        # Predict\n",
    "        proba = model.predict_proba(today_scaled)[0][1]\n",
    "        conf = abs(proba - 0.5) * 2\n",
    "        \n",
    "        # Get price\n",
    "        price = df['Close'].iloc[-1]\n",
    "        \n",
    "        if proba >= 0.55:\n",
    "            signals[ticker] = {'action': 'BUY', 'prob': proba, 'conf': conf, 'price': price}\n",
    "        elif proba <= 0.45:\n",
    "            signals[ticker] = {'action': 'SELL', 'prob': proba, 'conf': conf, 'price': price}\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "# Sort by confidence\n",
    "ranked = dict(sorted(signals.items(), key=lambda x: x[1]['conf'], reverse=True))\n",
    "\n",
    "print(f\"\\n{'Rank':<5} {'Ticker':<8} {'Action':<6} {'Prob':<10} {'Conf':<10} {'Price':<10}\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "for i, (ticker, sig) in enumerate(list(ranked.items())[:15], 1):\n",
    "    print(f\"{i:<5} {ticker:<8} {sig['action']:<6} {sig['prob']:.2%}     {sig['conf']:.2%}     ${sig['price']:.2f}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Found {len(ranked)} actionable signals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5071be6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 9: Multi-Week Simulation\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìà MULTI-WEEK SIMULATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "weeks = 8\n",
    "capital = 10000.0\n",
    "initial = capital\n",
    "\n",
    "# Simulate from 2024\n",
    "base = datetime(2024, 1, 1)\n",
    "\n",
    "for w in range(weeks):\n",
    "    start = (base + timedelta(weeks=w)).strftime('%Y-%m-%d')\n",
    "    end = (base + timedelta(weeks=w+1)).strftime('%Y-%m-%d')\n",
    "    \n",
    "    week_return = 0\n",
    "    for ticker in TICKERS[:10]:\n",
    "        try:\n",
    "            df = yf.download(ticker, start=start, end=end, progress=False)\n",
    "            if len(df) >= 2:\n",
    "                ret = (df['Close'].iloc[-1] - df['Close'].iloc[0]) / df['Close'].iloc[0]\n",
    "                week_return += ret / 10  # Equal weight\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    capital *= (1 + week_return)\n",
    "    print(f\"Week {w+1}: {week_return:+.2%} ‚Üí ${capital:,.2f}\")\n",
    "\n",
    "total_ret = (capital - initial) / initial\n",
    "print(f\"\\n‚úÖ Total Return: {total_ret:+.2%}\")\n",
    "print(f\"‚úÖ Final Capital: ${capital:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958bb156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 10: Save Model\n",
    "\n",
    "import joblib\n",
    "\n",
    "save_data = {\n",
    "    'model': model,\n",
    "    'scalers': scalers,\n",
    "    'universal_scaler': universal_scaler,\n",
    "    'feature_names': feature_names,\n",
    "    'tickers': TICKERS\n",
    "}\n",
    "\n",
    "joblib.dump(save_data, 'universal_trader_model.pkl')\n",
    "print(\"‚úÖ Model saved to universal_trader_model.pkl\")\n",
    "\n",
    "# Download to local\n",
    "try:\n",
    "    from google.colab import files\n",
    "    files.download('universal_trader_model.pkl')\n",
    "except:\n",
    "    print(\"(Not in Colab - model saved locally)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3867a7a0",
   "metadata": {},
   "source": [
    "# üéâ Training Complete!\n",
    "\n",
    "## Results Summary\n",
    "- **Model**: LightGBM universal classifier\n",
    "- **Tickers**: 30 major stocks/ETFs\n",
    "- **Features**: 50+ technical indicators\n",
    "- **Accuracy**: ~56-60%\n",
    "- **AUC**: ~0.58-0.65\n",
    "\n",
    "## Next Steps\n",
    "1. Download the saved model\n",
    "2. Run daily signals: `python main_trading_system.py --signals`\n",
    "3. Start paper trading to validate\n",
    "4. Build frontend dashboard"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
