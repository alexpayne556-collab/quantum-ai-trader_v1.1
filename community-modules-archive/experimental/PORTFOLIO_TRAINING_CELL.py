# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ¯ QUANTUM AI COCKPIT â€” PORTFOLIO TRAINING (BULLETPROOF VERSION)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Copy this ENTIRE cell into Colab and run!
# This will train N-BEATS on YOUR 7 portfolio stocks + backtest NVDA, TSLA, GOOG

print("=" * 80)
print("ğŸš€ QUANTUM AI COCKPIT â€” PORTFOLIO TRAINING")
print("=" * 80)
print("\nâ° Start Time:", datetime.now().strftime('%I:%M %p'))
print("ğŸ’¡ Training on YOUR 7 portfolio stocks")
print("ğŸ”’ Keep-alive enabled - won't stop if you minimize!\n")

import os
import sys
import time
import asyncio
import threading
import pandas as pd
from pathlib import Path
from datetime import datetime

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# KEEP-ALIVE: Prevents Colab from stopping
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def keep_colab_alive():
    """Keeps Colab session active"""
    while True:
        time.sleep(300)  # Every 5 minutes
        print(".", end="", flush=True)

# Start keep-alive thread
threading.Thread(target=keep_colab_alive, daemon=True).start()
print("âœ… Keep-alive thread started (Colab won't timeout)\n")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# VERIFY SETUP
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Check GPU
import torch
if torch.cuda.is_available():
    print(f"âœ… GPU: {torch.cuda.get_device_name(0)}\n")
else:
    print("âš ï¸ NO GPU - Training will be slower\n")

# Verify Google Drive
DRIVE_BASE = Path("/content/drive/MyDrive/Quantum_AI_Cockpit")
if not DRIVE_BASE.exists():
    print("âŒ Google Drive not mounted! Run the mount cell first!")
    raise FileNotFoundError("Google Drive not found")

print(f"âœ… Google Drive connected: {DRIVE_BASE}\n")

# Verify modules
MODULES_PATH = DRIVE_BASE / "backend" / "modules"
if MODULES_PATH not in [Path(p) for p in sys.path]:
    sys.path.insert(0, str(MODULES_PATH))

print("âœ… Modules loaded\n")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# YOUR PORTFOLIO STOCKS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

PORTFOLIO_STOCKS = [
    "MU",      # Micron (Down -33%)
    "ANRO",    # Anro (Down -27%)
    "SGML",    # Sigma Labs (Down -48%)
    "ADBE",    # Adobe (Down -8%)
    "NVDA",    # Nvidia (Up +17%)
    "TSLA",    # Tesla (Up +41%)
    "GOOG",    # Google (Up +32%)
]

BACKTEST_STOCKS = ["NVDA", "TSLA", "GOOG"]  # Your 3 winners

print("=" * 80)
print("ğŸ“Š TRAINING PLAN")
print("=" * 80)
print(f"\nğŸ¯ Portfolio Stocks: {', '.join(PORTFOLIO_STOCKS)}")
print(f"ğŸ“ˆ Backtesting: {', '.join(BACKTEST_STOCKS)}")
print(f"\nâ° Estimated Time: 15-20 minutes")
print()

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PART 1: TRAIN N-BEATS ON YOUR PORTFOLIO (10-15 min)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

print("=" * 80)
print("ğŸ”¥ PART 1/4: N-BEATS TRAINING ON YOUR PORTFOLIO")
print("=" * 80)
print()

from master_analysis_engine import analyze_stock

training_results = []
training_start = time.time()

async def train_portfolio():
    for i, ticker in enumerate(PORTFOLIO_STOCKS, 1):
        print(f"\n[{i}/{len(PORTFOLIO_STOCKS)}] ğŸ”¥ Training {ticker}...")
        start = time.time()
        
        try:
            result = await analyze_stock(
                symbol=ticker,
                account_balance=50000,
                forecast_days=21,
                verbose=False
            )
            
            elapsed = time.time() - start
            
            if result['status'] == 'ok':
                rec = result['recommendation']
                patterns = rec.get('pattern_analysis', {})
                
                training_results.append({
                    'ticker': ticker,
                    'status': 'success',
                    'time_sec': elapsed,
                    'action': rec.get('action'),
                    'confidence': rec.get('confidence', 0) * 100,
                    'patterns': patterns.get('total_patterns', 0),
                    'forecast_5d': rec.get('expected_move_5d', 0)
                })
                
                print(f"   âœ… {elapsed:.1f}s | {rec['action']} | "
                      f"{rec.get('confidence', 0)*100:.0f}% conf | "
                      f"+{rec.get('expected_move_5d', 0):.1f}% (5D)")
            else:
                training_results.append({
                    'ticker': ticker,
                    'status': 'error',
                    'time_sec': elapsed,
                    'error': result.get('error', 'unknown')[:50]
                })
                print(f"   âŒ Failed: {result.get('error', 'unknown')[:50]}")
                
        except Exception as e:
            elapsed = time.time() - start
            training_results.append({
                'ticker': ticker,
                'status': 'error',
                'time_sec': elapsed,
                'error': str(e)[:50]
            })
            print(f"   âŒ Error: {str(e)[:50]}")

# Run training
await train_portfolio()

training_elapsed = time.time() - training_start

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TRAINING SUMMARY
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

df_train = pd.DataFrame(training_results)
success = df_train[df_train['status'] == 'success']

print("\n" + "=" * 80)
print("ğŸ“Š PORTFOLIO TRAINING SUMMARY")
print("=" * 80)
print(f"\nâœ… Success Rate: {len(success)}/{len(PORTFOLIO_STOCKS)} ({len(success)/len(PORTFOLIO_STOCKS)*100:.0f}%)")
print(f"â±ï¸  Total Time: {training_elapsed/60:.1f} minutes")

if len(success) > 0:
    print(f"âš¡ Avg Time/Stock: {success['time_sec'].mean():.1f} seconds")
    print(f"ğŸ“ˆ Avg Confidence: {success['confidence'].mean():.0f}%")
    print(f"ğŸ” Avg Patterns: {success['patterns'].mean():.1f}")
    print(f"ğŸ’° Avg 5D Forecast: {success['forecast_5d'].mean():+.1f}%")
    
    print("\nğŸ“‹ YOUR PORTFOLIO ANALYSIS:")
    print("=" * 80)
    for _, row in success.iterrows():
        print(f"\n{row['ticker']:5} | {row['action']:12} | {row['confidence']:.0f}% conf | {row['forecast_5d']:+.1f}% (5D)")

# Save portfolio report
portfolio_report_path = DRIVE_BASE / "results" / f"portfolio_analysis_{datetime.now().strftime('%Y%m%d_%H%M')}.csv"
portfolio_report_path.parent.mkdir(parents=True, exist_ok=True)
df_train.to_csv(portfolio_report_path, index=False)
print(f"\nğŸ’¾ Portfolio report saved: {portfolio_report_path.name}")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PART 2: BACKTEST YOUR WINNERS (30-45 min)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

print("\n" + "=" * 80)
print("ğŸ“Š PART 2/4: BACKTESTING YOUR TOP 3 WINNERS")
print("=" * 80)
print(f"\nTesting historical performance of {', '.join(BACKTEST_STOCKS)}")
print()

from forecast_trainer import ForecastTrainer
import fusior_forecast
import yfinance as yf

backtest_results = []
backtest_start = time.time()

async def run_backtests():
    for i, ticker in enumerate(BACKTEST_STOCKS, 1):
        print(f"\n[{i}/{len(BACKTEST_STOCKS)}] ğŸ“Š Backtesting {ticker}...")
        start = time.time()
        
        try:
            # Fetch historical data
            stock = yf.Ticker(ticker)
            df = stock.history(period="3y")
            df.columns = df.columns.str.lower()
            
            if len(df) < 300:
                print(f"   âš ï¸  Only {len(df)} days - skipping")
                continue
            
            # Run walk-forward backtest
            trainer = ForecastTrainer()
            result = await trainer.walk_forward_backtest(
                symbol=ticker,
                df=df,
                forecast_func=fusior_forecast.run,
                train_window_days=252,
                test_window_days=21,
                step_days=21,
                min_confidence=0.60
            )
            
            elapsed = time.time() - start
            
            # Score the backtest
            score = sum([
                result.sharpe_ratio >= 1.0,
                result.win_rate >= 55,
                result.total_return > 0,
                result.max_drawdown < 15
            ])
            
            backtest_results.append({
                'ticker': ticker,
                'return_pct': result.total_return,
                'sharpe': result.sharpe_ratio,
                'win_rate': result.win_rate,
                'max_dd': result.max_drawdown,
                'trades': result.total_trades,
                'score': score,
                'time_sec': elapsed
            })
            
            print(f"   âœ… {elapsed:.0f}s | Return: {result.total_return:+.1f}% | "
                  f"Sharpe: {result.sharpe_ratio:.2f} | Win: {result.win_rate:.0f}% | "
                  f"Score: {score}/4")
            
        except Exception as e:
            print(f"   âŒ Error: {str(e)[:50]}")

await run_backtests()

backtest_elapsed = time.time() - backtest_start

# Print backtest summary
if backtest_results:
    df_bt = pd.DataFrame(backtest_results)
    
    print("\n" + "=" * 80)
    print("ğŸ“Š BACKTEST SUMMARY")
    print("=" * 80)
    print(f"\nâ±ï¸  Total Time: {backtest_elapsed/60:.1f} minutes")
    print(f"\nğŸ“ˆ HISTORICAL PERFORMANCE:")
    print("=" * 80)
    print(df_bt.to_string(index=False))
    
    print(f"\nğŸ¯ AVERAGES:")
    print(f"   â€¢ Return: {df_bt['return_pct'].mean():+.1f}%")
    print(f"   â€¢ Sharpe: {df_bt['sharpe'].mean():.2f}")
    print(f"   â€¢ Win Rate: {df_bt['win_rate'].mean():.0f}%")
    print(f"   â€¢ Max Drawdown: {df_bt['max_dd'].mean():.1f}%")
    
    # Save backtest report
    backtest_report_path = DRIVE_BASE / "results" / f"backtest_results_{datetime.now().strftime('%Y%m%d_%H%M')}.csv"
    df_bt.to_csv(backtest_report_path, index=False)
    print(f"\nğŸ’¾ Backtest report saved: {backtest_report_path.name}")
else:
    print("\nâš ï¸ No backtest results")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PART 3: PATTERN VALIDATION (5 min)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

print("\n" + "=" * 80)
print("ğŸ” PART 3/4: PATTERN VALIDATION")
print("=" * 80)
print(f"\nValidating pattern detection on your top 3 stocks...")
print()

from pattern_integration_layer import analyze_all_patterns

PATTERN_STOCKS = ["NVDA", "TSLA", "GOOG"]

pattern_results = []
pattern_start = time.time()

async def test_patterns():
    for i, ticker in enumerate(PATTERN_STOCKS, 1):
        print(f"\n[{i}/{len(PATTERN_STOCKS)}] ğŸ” Validating {ticker}...")
        
        try:
            stock = yf.Ticker(ticker)
            df = stock.history(period="6mo")
            df.columns = df.columns.str.lower()
            
            result = await analyze_all_patterns(df, ticker)
            
            if result['status'] == 'ok':
                s = result['summary']
                pattern_results.append({
                    'ticker': ticker,
                    'patterns': s['total_patterns_detected'],
                    'confluence': s['confluence_score']
                })
                
                print(f"   âœ… Patterns: {s['total_patterns_detected']} | "
                      f"Confluence: {s['confluence_score']:.0f}%")
            else:
                print(f"   âš ï¸  Pattern detection unavailable")
                
        except Exception as e:
            print(f"   âŒ Error: {str(e)[:50]}")

await test_patterns()

pattern_elapsed = time.time() - pattern_start

# Print pattern summary
if pattern_results:
    df_pat = pd.DataFrame(pattern_results)
    
    print("\n" + "=" * 80)
    print("ğŸ” PATTERN VALIDATION SUMMARY")
    print("=" * 80)
    print(f"\nâ±ï¸  Total Time: {pattern_elapsed/60:.1f} minutes")
    print(f"\nğŸ“Š Average Patterns/Stock: {df_pat['patterns'].mean():.1f}")
    print(f"ğŸ¯ Average Confluence: {df_pat['confluence'].mean():.0f}%")
    print(f"\nğŸ“‹ Results:")
    print(df_pat.to_string(index=False))
else:
    print("\nâš ï¸ Pattern detection had errors (non-critical)")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PART 4: EXPORT MODELS TO GOOGLE DRIVE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

print("\n" + "=" * 80)
print("ğŸ’¾ PART 4/4: EXPORTING MODELS")
print("=" * 80)

import shutil

model_dir = Path("/content/output/nbeats_models")
export_dir = DRIVE_BASE / "trained_models"

models = []
if model_dir.exists():
    models = list(model_dir.glob("*.pkl"))
    if models:
        print(f"\nâœ… Found {len(models)} trained N-BEATS models")
        
        export_dir.mkdir(parents=True, exist_ok=True)
        
        for model in models:
            shutil.copy(model, export_dir / model.name)
            print(f"   ğŸ“¦ {model.name}")
        
        print(f"\nâœ… All models exported to: {export_dir}")
    else:
        print("\nâš ï¸  Model directory exists but no .pkl files found")
else:
    print("\nâš ï¸  No model directory found")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# FINAL SUMMARY
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

total_elapsed = time.time() - training_start

print("\n" + "=" * 80)
print("ğŸ‰ PORTFOLIO TRAINING COMPLETE!")
print("=" * 80)

print(f"\nâ° End Time: {datetime.now().strftime('%I:%M %p')}")
print(f"â±ï¸  Total Duration: {total_elapsed/60:.0f} minutes ({total_elapsed/3600:.1f} hours)")

print(f"\nâœ… COMPLETED:")
print(f"   â€¢ Portfolio trained: {len(success)}/{len(PORTFOLIO_STOCKS)} stocks")
print(f"   â€¢ Backtested: {len(backtest_results)} stocks")
print(f"   â€¢ Pattern validated: {len(pattern_results)} stocks")
print(f"   â€¢ Models exported: {len(models)}")

if len(success) > 0:
    print(f"\nğŸ¯ YOUR PORTFOLIO INSIGHTS:")
    print(f"   â€¢ Avg Confidence: {success['confidence'].mean():.0f}%")
    print(f"   â€¢ Avg 5D Forecast: {success['forecast_5d'].mean():+.1f}%")
    
    # Count buy/sell/hold
    actions = success['action'].value_counts()
    print(f"\nğŸ“Š RECOMMENDATIONS:")
    for action, count in actions.items():
        print(f"   â€¢ {action}: {count} stocks")
    
    if backtest_results:
        df_bt = pd.DataFrame(backtest_results)
        print(f"\nğŸ“ˆ BACKTEST PERFORMANCE:")
        print(f"   â€¢ Avg Return: {df_bt['return_pct'].mean():+.1f}%")
        print(f"   â€¢ Avg Sharpe: {df_bt['sharpe'].mean():.2f}")
        print(f"   â€¢ Avg Win Rate: {df_bt['win_rate'].mean():.0f}%")

# Save comprehensive report
final_report_path = DRIVE_BASE / "results" / f"COMPLETE_TRAINING_REPORT_{datetime.now().strftime('%Y%m%d_%H%M')}.txt"

with open(final_report_path, 'w') as f:
    f.write("=" * 80 + "\n")
    f.write("QUANTUM AI COCKPIT â€” PORTFOLIO TRAINING REPORT\n")
    f.write("=" * 80 + "\n\n")
    f.write(f"Date: {datetime.now().strftime('%Y-%m-%d %I:%M %p')}\n")
    f.write(f"Duration: {total_elapsed/60:.0f} minutes\n\n")
    
    f.write("YOUR PORTFOLIO ANALYSIS:\n")
    f.write("=" * 80 + "\n")
    f.write(df_train.to_string(index=False))
    f.write("\n\n")
    
    if backtest_results:
        f.write("BACKTEST RESULTS:\n")
        f.write("=" * 80 + "\n")
        f.write(df_bt.to_string(index=False))
        f.write("\n\n")
    
    if pattern_results:
        f.write("PATTERN VALIDATION:\n")
        f.write("=" * 80 + "\n")
        f.write(df_pat.to_string(index=False))

print(f"\nğŸ“„ Complete report saved: {final_report_path.name}")
print(f"ğŸ“‚ Location: {DRIVE_BASE}/results/")

print("\n" + "=" * 80)
print("ğŸš€ READY FOR DEPLOYMENT!")
print("=" * 80)
print("\nğŸ’¡ Next steps:")
print("   1. Review your portfolio recommendations above")
print("   2. Check backtest performance")
print("   3. Build the dashboard tomorrow!")
print("\nğŸŒ™ You can now close Colab - everything is saved to Google Drive!")
print("=" * 80)

