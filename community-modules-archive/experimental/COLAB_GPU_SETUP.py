"""
üöÄ GPU SETUP & CONFIGURATION
============================
Configures GPU for all ML models in the system
"""

import os
import sys

print("="*80)
print("üöÄ GPU SETUP & CONFIGURATION")
print("="*80)

# ============================================================================
# DETECT GPU
# ============================================================================
print("\n1Ô∏è‚É£ Detecting GPU...")

GPU_AVAILABLE = False
GPU_DEVICE = None
USE_GPU = False

try:
    import torch
    if torch.cuda.is_available():
        GPU_AVAILABLE = True
        GPU_DEVICE = torch.device('cuda')
        gpu_name = torch.cuda.get_device_name(0)
        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9
        print(f"‚úÖ GPU Detected: {gpu_name} ({gpu_memory:.1f} GB)")
        USE_GPU = True
        
        # Set default device
        torch.cuda.set_device(0)
        print(f"‚úÖ GPU device set to: cuda:0")
    else:
        print("‚ö†Ô∏è  No GPU detected - using CPU")
        GPU_DEVICE = torch.device('cpu')
except ImportError:
    print("‚ö†Ô∏è  PyTorch not installed")
    print("   Installing PyTorch with GPU support...")
    import subprocess
    subprocess.run([sys.executable, '-m', 'pip', 'install', '-q', 
                    'torch', 'torchvision', 'torchaudio', '--index-url', 
                    'https://download.pytorch.org/whl/cu118'])
    
    # Try again
    try:
        import torch
        if torch.cuda.is_available():
            GPU_AVAILABLE = True
            GPU_DEVICE = torch.device('cuda')
            USE_GPU = True
            print("‚úÖ PyTorch installed with GPU support!")
        else:
            GPU_DEVICE = torch.device('cpu')
            print("‚ö†Ô∏è  GPU not available after install")
    except:
        GPU_DEVICE = None
        print("‚ö†Ô∏è  Could not install PyTorch")

# ============================================================================
# CONFIGURE XGBOOST & LIGHTGBM FOR GPU
# ============================================================================
print("\n2Ô∏è‚É£ Configuring XGBoost & LightGBM for GPU...")

if USE_GPU:
    # Set environment variables for GPU
    os.environ['XGBOOST_GPU'] = '1'
    os.environ['LIGHTGBM_EXEC'] = 'gpu'
    
    print("‚úÖ Environment variables set for GPU acceleration")
    print("   XGBoost and LightGBM will use GPU if available")
else:
    print("‚ö†Ô∏è  CPU mode - XGBoost/LightGBM will use CPU")

# ============================================================================
# CREATE GPU CONFIG MODULE
# ============================================================================
print("\n3Ô∏è‚É£ Creating GPU configuration...")

gpu_config_code = f'''
"""
GPU Configuration for Quantum AI System
Auto-generated by COLAB_GPU_SETUP.py
"""

import os

# GPU Status
GPU_AVAILABLE = {GPU_AVAILABLE}
USE_GPU = {USE_GPU}

# Device configuration
try:
    import torch
    if torch.cuda.is_available():
        DEVICE = torch.device('cuda:0')
        GPU_NAME = torch.cuda.get_device_name(0)
        GPU_MEMORY_GB = torch.cuda.get_device_properties(0).total_memory / 1e9
    else:
        DEVICE = torch.device('cpu')
        GPU_NAME = None
        GPU_MEMORY_GB = 0
except:
    DEVICE = None
    GPU_NAME = None
    GPU_MEMORY_GB = 0

# XGBoost GPU parameters
XGBOOST_PARAMS = {{
    'tree_method': 'gpu_hist' if USE_GPU else 'hist',
    'predictor': 'gpu_predictor' if USE_GPU else 'cpu_predictor',
    'gpu_id': 0 if USE_GPU else None,
}}

# LightGBM GPU parameters
LIGHTGBM_PARAMS = {{
    'device': 'gpu' if USE_GPU else 'cpu',
    'gpu_platform_id': 0 if USE_GPU else None,
    'gpu_device_id': 0 if USE_GPU else None,
}}

# Scikit-learn (no GPU support, but can use joblib with GPU)
SKLEARN_N_JOBS = -1  # Use all CPU cores

def get_device():
    """Get the appropriate device for PyTorch models"""
    return DEVICE if DEVICE else 'cpu'

def to_device(tensor_or_model, device=None):
    """Move tensor or model to device"""
    if device is None:
        device = get_device()
    try:
        import torch
        return tensor_or_model.to(device)
    except:
        return tensor_or_model

def print_gpu_status():
    """Print current GPU status"""
    if USE_GPU:
        print(f"‚úÖ GPU Active: {{GPU_NAME}} ({{GPU_MEMORY_GB:.1f}} GB)")
    else:
        print("‚ö†Ô∏è  GPU Not Available - Using CPU")
'''

# Save to modules directory
from pathlib import Path
BASE_DIR = Path('/content/drive/MyDrive/QuantumAI')
MODULES_DIR = BASE_DIR / 'backend' / 'modules'

gpu_config_file = MODULES_DIR / 'gpu_config.py'

try:
    with open(gpu_config_file, 'w') as f:
        f.write(gpu_config_code)
    print(f"‚úÖ GPU config saved to: {gpu_config_file}")
except Exception as e:
    print(f"‚ö†Ô∏è  Could not save GPU config: {e}")

# ============================================================================
# TEST GPU ACCELERATION
# ============================================================================
print("\n4Ô∏è‚É£ Testing GPU acceleration...")

if USE_GPU:
    try:
        import torch
        # Simple test
        x = torch.randn(1000, 1000).to(GPU_DEVICE)
        y = torch.randn(1000, 1000).to(GPU_DEVICE)
        z = torch.matmul(x, y)
        print("‚úÖ PyTorch GPU test passed")
        
        # Test XGBoost
        try:
            import xgboost as xgb
            print("‚úÖ XGBoost available")
            # Note: XGBoost GPU requires specific build
        except:
            print("‚ö†Ô∏è  XGBoost not installed")
        
        # Test LightGBM
        try:
            import lightgbm as lgb
            print("‚úÖ LightGBM available")
        except:
            print("‚ö†Ô∏è  LightGBM not installed")
            
    except Exception as e:
        print(f"‚ö†Ô∏è  GPU test error: {e}")

# ============================================================================
# SUMMARY
# ============================================================================
print("\n" + "="*80)
print("‚úÖ GPU SETUP COMPLETE")
print("="*80)

if USE_GPU:
    print(f"\nüéØ GPU Status: ACTIVE")
    try:
        import torch
        if torch.cuda.is_available():
            gpu_name = torch.cuda.get_device_name(0)
            gpu_mem = torch.cuda.get_device_properties(0).total_memory / 1e9
            print(f"   Device: {gpu_name}")
            print(f"   Memory: {gpu_mem:.1f} GB")
        else:
            print(f"   Device: GPU (detected but not available)")
    except:
        print(f"   Device: GPU (configured)")
    print(f"\n‚úÖ Models will use GPU acceleration:")
    print(f"   ‚Ä¢ PyTorch models ‚Üí GPU")
    print(f"   ‚Ä¢ XGBoost ‚Üí GPU (if available)")
    print(f"   ‚Ä¢ LightGBM ‚Üí GPU (if available)")
else:
    print(f"\n‚ö†Ô∏è  GPU Status: NOT AVAILABLE")
    print(f"   All models will use CPU")
    print(f"\nüí° To enable GPU:")
    print(f"   1. Runtime ‚Üí Change runtime type")
    print(f"   2. Select 'GPU' (T4 or better)")
    print(f"   3. Re-run this script")

print("\n" + "="*80)

