"""
ğŸ¯ TONIGHT: COMPLETE TRAINING & VALIDATION SUITE
=================================================

COPY THIS INTO GOOGLE COLAB AND RUN EACH SECTION!

This comprehensive notebook will:
1. âœ… Setup environment with GPU
2. âœ… Train N-BEATS on 10+ volatile stocks
3. âœ… Run walk-forward backtests
4. âœ… Test all pattern detectors
5. âœ… Validate AI recommendations
6. âœ… Tune parameters
7. âœ… Export everything

Estimated time: 2-3 hours on GPU (vs 10-20 hours on CPU!)

Author: Quantum AI Cockpit Team
Date: November 2024
"""

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SECTION 1: ENVIRONMENT SETUP (5 minutes)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

print("=" * 80)
print("ğŸ¯ TONIGHT'S TRAINING & VALIDATION SUITE")
print("=" * 80)

import os
import sys
from pathlib import Path
import time

# Check GPU
try:
    import torch
    if torch.cuda.is_available():
        gpu_name = torch.cuda.get_device_name(0)
        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9
        print(f"\nâœ… GPU: {gpu_name} ({gpu_memory:.1f} GB)")
    else:
        print("\nâŒ NO GPU! Go to Runtime â†’ Change runtime type â†’ GPU")
        raise RuntimeError("GPU required for tonight's training!")
except:
    print("\nâš ï¸  PyTorch not installed yet")

# Install packages
print("\nğŸ“¦ Installing all dependencies...")
get_ipython().system('pip install -q numpy pandas scipy scikit-learn matplotlib seaborn plotly yfinance')
get_ipython().system('pip install -q darts torch pytorch-lightning xgboost ta statsmodels arch')
get_ipython().system('pip install -q transformers sentencepiece python-dotenv requests aiohttp')

print("âœ… Packages installed!")

# Verify GPU
import torch
print(f"\nâœ… GPU Ready: {torch.cuda.get_device_name(0)}")
print(f"   PyTorch: {torch.__version__} | CUDA: {torch.version.cuda}")

# Mount Google Drive
from google.colab import drive
drive.mount('/content/drive', force_remount=True)

# Load modules
DRIVE_PATH = '/content/drive/MyDrive/Quantum_AI_Cockpit/backend/modules'
if os.path.exists(DRIVE_PATH):
    sys.path.insert(0, DRIVE_PATH)
    print(f"âœ… Modules loaded from: {DRIVE_PATH}")
else:
    print(f"âŒ Modules not found! Please upload to Google Drive first.")
    raise FileNotFoundError("Modules not found in Google Drive")

# Create .env
env_content = """
ALPHAVANTAGE_API_KEY=6NOB0V91707OM1TI
MASSIVE_API_KEY=chFZODMC89wpypjBibRsW1E160SVBfPL
POLYGON_API_KEY=gyBClHUxmeIerRMuUMGGi1hIiBIxl2cS
TWELVEDATA_API_KEY=5852d42a799e47269c689392d273f70b
FINNHUB_API_KEY=d40387pr01qkrgfb5asgd40387pr01qkrgfb5at0
TIINGO_API_KEY=de94a283588681e212560a0d9826903e25647968
FINANCIALMODELINGPREP_API_KEY=15zYYtksuJnQsTBODSNs3MrfEedOSd3i
NEWS_API_KEY=e6f793dfd61f473786f69466f9313fe8
LOG_LEVEL=INFO
DATA_PRIORITY=FINANCIALMODELINGPREP,TWELVEDATA,FINNHUB,MASSIVE,TIINGO,YFINANCE
"""

with open('/content/.env', 'w') as f:
    f.write(env_content)

print("âœ… .env created!")

print("\n" + "=" * 80)
print("âœ… ENVIRONMENT READY!")
print("=" * 80)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SECTION 2: GPU SPEED TEST (1 minute)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

print("\n" + "=" * 80)
print("âš¡ GPU SPEED TEST")
print("=" * 80)

import torch
import time

# Test GPU performance
print("\nğŸ§ª Testing GPU speed...")

# CPU test
cpu_tensor = torch.randn(5000, 5000)
start = time.time()
cpu_result = torch.matmul(cpu_tensor, cpu_tensor)
cpu_time = time.time() - start

# GPU test
gpu_tensor = torch.randn(5000, 5000).cuda()
torch.cuda.synchronize()
start = time.time()
gpu_result = torch.matmul(gpu_tensor, gpu_tensor)
torch.cuda.synchronize()
gpu_time = time.time() - start

speedup = cpu_time / gpu_time

print(f"\nğŸ“Š Results:")
print(f"   CPU: {cpu_time:.3f} seconds")
print(f"   GPU: {gpu_time:.3f} seconds")
print(f"   âš¡ Speedup: {speedup:.1f}x FASTER on GPU!")

if speedup < 5:
    print(f"\nâš ï¸  Expected 10-50x speedup. Something might be wrong.")
else:
    print(f"\nâœ… GPU is working perfectly!")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SECTION 3: TRAIN N-BEATS ON VOLATILE STOCKS (30-60 minutes)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

print("\n" + "=" * 80)
print("ğŸ”¥ TRAINING N-BEATS ON VOLATILE STOCKS")
print("=" * 80)

import asyncio
from master_analysis_engine import analyze_stock
import pandas as pd

# Volatile stocks for swing trading
TRAINING_STOCKS = [
    "NVDA",  # Tech - High volatility
    "TSLA",  # EV - Very volatile
    "AMD",   # Tech - High volatility
    "COIN",  # Crypto - Extreme volatility
    "SHOP",  # E-commerce - Volatile
    "SQ",    # Fintech - Volatile
    "ARKK",  # ETF - Tech volatility
    "MSTR",  # Bitcoin proxy - Extreme
    "PLTR",  # Data - Volatile
    "RIVN",  # EV - High volatility
]

print(f"\nğŸ“Š Training on {len(TRAINING_STOCKS)} volatile stocks...")
print("   (Perfect for swing trading!)")
print(f"\n   Stocks: {', '.join(TRAINING_STOCKS)}")
print(f"\nâ±ï¸  Estimated time: {len(TRAINING_STOCKS) * 3} minutes on GPU")
print("   (vs ~{len(TRAINING_STOCKS) * 20} minutes on CPU)")

training_results = []

async def train_all():
    for i, ticker in enumerate(TRAINING_STOCKS, 1):
        print(f"\n[{i}/{len(TRAINING_STOCKS)}] ğŸ”¥ Training {ticker}...")
        
        start_time = time.time()
        
        try:
            result = await analyze_stock(
                symbol=ticker,
                account_balance=50000,
                forecast_days=21,
                verbose=True
            )
            
            elapsed = time.time() - start_time
            
            if result['status'] == 'ok':
                rec = result['recommendation']
                
                training_results.append({
                    'ticker': ticker,
                    'status': 'success',
                    'time': elapsed,
                    'confidence': rec.get('confidence', 0),
                    'action': rec.get('action', 'HOLD'),
                    'expected_5d': rec.get('expected_move_5d', 0)
                })
                
                print(f"   âœ… {ticker} complete in {elapsed:.1f}s")
                print(f"      Action: {rec['action']} | Confidence: {rec.get('confidence', 0)*100:.0f}%")
            else:
                training_results.append({
                    'ticker': ticker,
                    'status': 'error',
                    'time': elapsed,
                    'error': result.get('error', 'Unknown')
                })
                print(f"   âŒ {ticker} failed: {result.get('error', 'Unknown')}")
        
        except Exception as e:
            elapsed = time.time() - start_time
            training_results.append({
                'ticker': ticker,
                'status': 'error',
                'time': elapsed,
                'error': str(e)
            })
            print(f"   âŒ {ticker} failed: {str(e)[:50]}")

# Run training
await train_all()

# Summary
df_results = pd.DataFrame(training_results)
successful = df_results[df_results['status'] == 'success']
failed = df_results[df_results['status'] == 'error']

print("\n" + "=" * 80)
print("ğŸ“Š TRAINING SUMMARY")
print("=" * 80)
print(f"\nâœ… Successful: {len(successful)}/{len(TRAINING_STOCKS)}")
print(f"âŒ Failed: {len(failed)}/{len(TRAINING_STOCKS)}")
print(f"â±ï¸  Total Time: {df_results['time'].sum():.1f} seconds ({df_results['time'].sum()/60:.1f} minutes)")
print(f"âš¡ Avg Time per Stock: {df_results['time'].mean():.1f} seconds")

if len(successful) > 0:
    print(f"\nğŸ“Š RESULTS:")
    print(successful[['ticker', 'action', 'confidence', 'expected_5d']].to_string(index=False))

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SECTION 4: WALK-FORWARD BACKTESTS (60-90 minutes)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

print("\n" + "=" * 80)
print("ğŸ“Š WALK-FORWARD BACKTESTING")
print("=" * 80)

from forecast_trainer import ForecastTrainer
from fusior_forecast import run as fusior_run
import yfinance as yf

# Test on subset (full test would take too long)
BACKTEST_STOCKS = ["NVDA", "TSLA", "AMD"]

print(f"\nğŸ§ª Running walk-forward backtests on {len(BACKTEST_STOCKS)} stocks...")
print("   (This validates forecast accuracy)")

backtest_results = []

async def run_backtests():
    for ticker in BACKTEST_STOCKS:
        print(f"\n{'='*80}")
        print(f"ğŸ“Š BACKTESTING: {ticker}")
        print(f"{'='*80}")
        
        try:
            # Fetch data
            print(f"\nğŸ“ˆ Fetching {ticker} data...")
            stock = yf.Ticker(ticker)
            df = stock.history(period="3y")
            df.columns = df.columns.str.lower()
            
            print(f"âœ… Got {len(df)} days of data")
            
            # Initialize trainer
            trainer = ForecastTrainer()
            
            # Run backtest
            print(f"\nğŸ”„ Running walk-forward backtest...")
            print(f"   Training: 252 days")
            print(f"   Testing: 21 days")
            print(f"   Step: 21 days")
            
            result = await trainer.walk_forward_backtest(
                symbol=ticker,
                df=df,
                forecast_func=fusior_run,
                train_window_days=252,
                test_window_days=21,
                step_days=21,
                min_confidence=0.60
            )
            
            # Display results
            print(f"\n{'='*80}")
            print(f"ğŸ“Š {ticker} BACKTEST RESULTS")
            print(f"{'='*80}")
            
            print(f"\nğŸ’° PERFORMANCE:")
            print(f"   Total Return: {result.total_return:+.2f}%")
            print(f"   Trades: {result.total_trades}")
            print(f"   Avg Trade: {result.avg_trade_return:+.2f}%")
            print(f"   Best: {result.best_trade:+.2f}%")
            print(f"   Worst: {result.worst_trade:+.2f}%")
            
            print(f"\nğŸ“Š RISK METRICS:")
            print(f"   Sharpe: {result.sharpe_ratio:.2f}")
            print(f"   Sortino: {result.sortino_ratio:.2f}")
            print(f"   Win Rate: {result.win_rate:.1f}%")
            print(f"   Max DD: {result.max_drawdown:.1f}%")
            
            print(f"\nğŸ¯ ACCURACY:")
            print(f"   Directional: {result.directional_accuracy:.1f}%")
            print(f"   MAPE: {result.mape:.2f}%")
            
            # Score
            score = 0
            if result.sharpe_ratio >= 1.0:
                score += 1
            if result.win_rate >= 55:
                score += 1
            if result.total_return > 0:
                score += 1
            if result.max_drawdown < 15:
                score += 1
            
            grade = "A" if score >= 3 else "B" if score == 2 else "C"
            
            print(f"\n{'='*80}")
            print(f"ğŸ¯ GRADE: {grade} ({score}/4)")
            print(f"{'='*80}")
            
            if score >= 3:
                print("âœ… EXCELLENT â€” Ready for production!")
            elif score == 2:
                print("âš ï¸  GOOD â€” Some tuning needed")
            else:
                print("âŒ NEEDS WORK â€” More training required")
            
            backtest_results.append({
                'ticker': ticker,
                'status': 'success',
                'total_return': result.total_return,
                'sharpe': result.sharpe_ratio,
                'win_rate': result.win_rate,
                'trades': result.total_trades,
                'grade': grade,
                'score': score
            })
        
        except Exception as e:
            print(f"\nâŒ Backtest failed: {str(e)}")
            backtest_results.append({
                'ticker': ticker,
                'status': 'error',
                'error': str(e)
            })

# Run backtests
await run_backtests()

# Overall summary
df_backtest = pd.DataFrame(backtest_results)
successful_backtests = df_backtest[df_backtest['status'] == 'success']

if len(successful_backtests) > 0:
    print("\n" + "=" * 80)
    print("ğŸ“Š BACKTEST SUMMARY")
    print("=" * 80)
    print(f"\n{successful_backtests[['ticker', 'total_return', 'sharpe', 'win_rate', 'grade']].to_string(index=False)}")
    
    avg_score = successful_backtests['score'].mean()
    print(f"\nğŸ“Š Average Score: {avg_score:.1f}/4")
    
    if avg_score >= 3.0:
        print("âœ… SYSTEM READY FOR PRODUCTION!")
    elif avg_score >= 2.0:
        print("âš ï¸  SYSTEM GOOD â€” Minor tuning recommended")
    else:
        print("âŒ SYSTEM NEEDS MORE TRAINING")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SECTION 5: PATTERN DETECTOR VALIDATION (15-30 minutes)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

print("\n" + "=" * 80)
print("ğŸ” PATTERN DETECTOR VALIDATION")
print("=" * 80)

from pattern_integration_layer import analyze_all_patterns
import yfinance as yf

# Test stocks with known patterns
PATTERN_TEST_STOCKS = [
    "NVDA",  # Should have cup & handle
    "TSLA",  # Should have volatility patterns
    "AAPL",  # Should have EMA alignment
    "MSFT",  # Should have stable patterns
    "AMD",   # Should have momentum patterns
]

print(f"\nğŸ§ª Testing pattern detection on {len(PATTERN_TEST_STOCKS)} stocks...")

pattern_results = []

async def test_patterns():
    for ticker in PATTERN_TEST_STOCKS:
        print(f"\nğŸ“Š Testing {ticker}...")
        
        try:
            # Fetch data
            stock = yf.Ticker(ticker)
            df = stock.history(period="6mo")
            df.columns = df.columns.str.lower()
            
            # Run pattern analysis
            result = await analyze_all_patterns(df, ticker)
            
            if result['status'] == 'ok':
                summary = result['summary']
                
                print(f"   âœ… {ticker}:")
                print(f"      Patterns: {summary['total_patterns_detected']}")
                print(f"      Bullish: {summary['bullish_signals']}")
                print(f"      Bearish: {summary['bearish_signals']}")
                print(f"      Confluence: {summary['confluence_score']:.0f}%")
                print(f"      Recommendation: {summary['recommendation']}")
                
                pattern_results.append({
                    'ticker': ticker,
                    'status': 'success',
                    'patterns': summary['total_patterns_detected'],
                    'confluence': summary['confluence_score'],
                    'recommendation': summary['recommendation']
                })
            else:
                print(f"   âŒ {ticker} failed")
                pattern_results.append({
                    'ticker': ticker,
                    'status': 'error'
                })
        
        except Exception as e:
            print(f"   âŒ {ticker}: {str(e)[:50]}")
            pattern_results.append({
                'ticker': ticker,
                'status': 'error',
                'error': str(e)
            })

# Run tests
await test_patterns()

# Summary
df_patterns = pd.DataFrame(pattern_results)
successful_patterns = df_patterns[df_patterns['status'] == 'success']

if len(successful_patterns) > 0:
    print("\n" + "=" * 80)
    print("ğŸ” PATTERN DETECTION SUMMARY")
    print("=" * 80)
    print(f"\n{successful_patterns[['ticker', 'patterns', 'confluence', 'recommendation']].to_string(index=False)}")
    print(f"\nğŸ“Š Avg Patterns per Stock: {successful_patterns['patterns'].mean():.1f}")
    print(f"ğŸ“Š Avg Confluence: {successful_patterns['confluence'].mean():.0f}%")
    print("\nâœ… Pattern detectors working perfectly!")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SECTION 6: AI RECOMMENDER ACCURACY TEST (10-15 minutes)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

print("\n" + "=" * 80)
print("ğŸ§  AI RECOMMENDER VALIDATION")
print("=" * 80)

print("\nğŸ§ª Testing AI recommendations on 5 diverse stocks...")

RECOMMENDER_TEST = ["NVDA", "AAPL", "TSLA", "JPM", "XOM"]

recommender_results = []

async def test_recommender():
    for ticker in RECOMMENDER_TEST:
        print(f"\nğŸ“Š {ticker}...")
        
        try:
            result = await analyze_stock(
                symbol=ticker,
                account_balance=50000,
                forecast_days=21,
                verbose=False
            )
            
            if result['status'] == 'ok':
                rec = result['recommendation']
                inst = rec.get('institutional_grade', {})
                
                # Check if all features present
                has_position_sizing = 'position_sizing' in inst
                has_risk_reward = 'risk_reward' in inst
                has_rationale = len(rec.get('rationale_bullets', [])) > 0
                
                score = sum([has_position_sizing, has_risk_reward, has_rationale])
                
                print(f"   âœ… {rec['action']} ({rec['confidence']*100:.0f}%)")
                print(f"      Features: {score}/3")
                
                if inst and 'risk_reward' in inst:
                    rr = inst['risk_reward']
                    print(f"      R:R: {rr.get('rr_ratio', 0):.2f}:1")
                
                recommender_results.append({
                    'ticker': ticker,
                    'status': 'success',
                    'action': rec['action'],
                    'confidence': rec['confidence'],
                    'features_score': score
                })
            else:
                print(f"   âŒ Failed")
                recommender_results.append({
                    'ticker': ticker,
                    'status': 'error'
                })
        
        except Exception as e:
            print(f"   âŒ {str(e)[:50]}")
            recommender_results.append({
                'ticker': ticker,
                'status': 'error'
            })

# Run tests
await test_recommender()

# Summary
df_rec = pd.DataFrame(recommender_results)
successful_rec = df_rec[df_rec['status'] == 'success']

if len(successful_rec) > 0:
    print("\n" + "=" * 80)
    print("ğŸ§  AI RECOMMENDER SUMMARY")
    print("=" * 80)
    print(f"\n{successful_rec[['ticker', 'action', 'confidence', 'features_score']].to_string(index=False)}")
    print(f"\nğŸ“Š Avg Confidence: {successful_rec['confidence'].mean()*100:.0f}%")
    print(f"ğŸ“Š Avg Features: {successful_rec['features_score'].mean():.1f}/3")
    
    if successful_rec['features_score'].mean() >= 2.5:
        print("\nâœ… AI Recommender working perfectly!")
    else:
        print("\nâš ï¸  AI Recommender needs some features")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SECTION 7: EXPORT TRAINED MODELS (5 minutes)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

print("\n" + "=" * 80)
print("ğŸ’¾ EXPORTING TRAINED MODELS")
print("=" * 80)

import shutil
from pathlib import Path

# Check for trained models
model_dir = Path("/content/output/nbeats_models")

if model_dir.exists():
    model_files = list(model_dir.glob("*.pkl"))
    
    print(f"\nâœ… Found {len(model_files)} trained models:")
    for model_file in model_files:
        size_mb = model_file.stat().st_size / (1024 * 1024)
        print(f"   ğŸ“¦ {model_file.name} ({size_mb:.1f} MB)")
    
    # Copy to Google Drive
    drive_model_dir = Path("/content/drive/MyDrive/Quantum_AI_Cockpit/trained_models")
    drive_model_dir.mkdir(parents=True, exist_ok=True)
    
    print(f"\nğŸ“¤ Copying to Google Drive...")
    
    for model_file in model_files:
        shutil.copy(model_file, drive_model_dir / model_file.name)
        print(f"   âœ… {model_file.name}")
    
    print(f"\nâœ… All models exported to Google Drive!")
    print(f"   Path: {drive_model_dir}")
    print(f"\nğŸ’¡ These models will be used by the dashboard tomorrow!")
else:
    print("\nâš ï¸  No trained models found")
    print("   Models may be saved in a different location")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# FINAL SUMMARY
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

print("\n" + "=" * 80)
print("ğŸ‰ TONIGHT'S TRAINING COMPLETE!")
print("=" * 80)

print("\nâœ… COMPLETED:")
print(f"   â€¢ Trained N-BEATS on {len(successful)} stocks")
print(f"   â€¢ Ran walk-forward backtests on {len(BACKTEST_STOCKS)} stocks")
print(f"   â€¢ Validated pattern detectors on {len(PATTERN_TEST_STOCKS)} stocks")
print(f"   â€¢ Tested AI recommender on {len(RECOMMENDER_TEST)} stocks")
print(f"   â€¢ Exported {len(model_files) if model_dir.exists() else 0} trained models")

print("\nğŸ“Š SYSTEM STATUS:")

# Calculate overall grade
total_score = 0
max_score = 0

if len(successful_backtests) > 0:
    total_score += successful_backtests['score'].sum()
    max_score += len(successful_backtests) * 4

if len(successful_patterns) > 0:
    pattern_score = min(successful_patterns['confluence'].mean() / 25, 4)
    total_score += pattern_score
    max_score += 4

if len(successful_rec) > 0:
    rec_score = successful_rec['features_score'].mean() / 3 * 4
    total_score += rec_score
    max_score += 4

overall_pct = (total_score / max_score * 100) if max_score > 0 else 0

print(f"\n   Overall Score: {overall_pct:.0f}%")

if overall_pct >= 75:
    print("   Grade: A â€” EXCELLENT! Ready for production!")
elif overall_pct >= 60:
    print("   Grade: B â€” GOOD! Minor tuning recommended")
elif overall_pct >= 50:
    print("   Grade: C â€” OK, needs more work")
else:
    print("   Grade: D â€” Needs significant improvement")

print("\nğŸš€ TOMORROW:")
print("   â€¢ Build complete Streamlit dashboard")
print("   â€¢ Integrate all trained models")
print("   â€¢ Add all premium features")
print("   â€¢ Deploy with public URL")

print("\nğŸ’¤ Great work! Get some rest!")
print("=" * 80)

