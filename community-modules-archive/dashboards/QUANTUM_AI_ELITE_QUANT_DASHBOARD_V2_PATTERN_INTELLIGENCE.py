"""
üèÜ QUANTUM AI ELITE QUANT DASHBOARD v2 - PATTERN INTELLIGENCE
===========================================================
Institutional-Grade Multi-Factor Quantitative Analysis with Live Learning

Like: Intellectia AI + AI Invest + Renaissance + Citadel + Two Sigma

NEW FEATURES v2:
‚úÖ Advanced Pattern Intelligence with Quality Scoring (Intellectia-style)
‚úÖ Live Backtesting & Learning (trains while you use it)
‚úÖ NSD Training (No Supervision Deep Learning)
‚úÖ Sentiment Analysis Integration (news, social media)
‚úÖ Earnings Calendar & Insider Trading Alerts
‚úÖ Risk Management Engine (VaR, CVaR, Kelly optimization)
‚úÖ Portfolio Optimization (Markowitz, Black-Litterman)
‚úÖ Real-time Market Scanner with 8-factor scoring
‚úÖ Deep AI Explanations with statistical significance
‚úÖ Live Training Logs (gets smarter every trade)

Target: 75-85% win rate with institutional risk management
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import plotly.express as px
from datetime import datetime, timedelta
from scipy import stats
import sys
import os
import json
import asyncio
import threading
import time
from pathlib import Path

# ============================================================================
# CONFIGURATION
# ============================================================================

st.set_page_config(
    page_title="Quantum AI Elite Quant v2",
    page_icon="üèÜ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Path setup
sys.path.insert(0, '/content/drive/MyDrive/QuantumAI/backend/modules')

# ============================================================================
# ELITE QUANT v2 CSS (Intellectia + AI Invest Style)
# ============================================================================

st.markdown("""
<style>
    /* Elite Dark Theme */
    .stApp {
        background: linear-gradient(135deg, #0a0e27 0%, #1a1f3a 100%);
        font-family: 'Inter', -apple-system, BlinkMacSystemFont, sans-serif;
    }

    /* Quant Score Card (like Intellectia) */
    .quant-score-card {
        background: linear-gradient(135deg, #1e3a5f 0%, #2d4a6f 100%);
        border-radius: 20px;
        padding: 32px;
        text-align: center;
        box-shadow: 0 12px 24px rgba(0,0,0,0.4);
        border: 3px solid #00ff88;
        position: relative;
        overflow: hidden;
    }

    .quant-score-card::before {
        content: '';
        position: absolute;
        top: 0;
        left: -100%;
        width: 100%;
        height: 100%;
        background: linear-gradient(90deg, transparent, rgba(0,255,136,0.1), transparent);
        transition: left 0.5s;
    }

    .quant-score-card:hover::before {
        left: 100%;
    }

    .quant-score-number {
        font-size: 96px;
        font-weight: 900;
        background: linear-gradient(135deg, #00ff88 0%, #00d86a 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        font-family: 'Roboto Mono', monospace;
        line-height: 1;
        text-shadow: 0 0 20px rgba(0,255,136,0.3);
    }

    .statistical-significance {
        font-size: 14px;
        color: #a0a0b0;
        text-transform: uppercase;
        letter-spacing: 2px;
        margin-top: 8px;
        font-weight: 600;
    }

    /* Pattern Intelligence Cards (Intellectia-style) */
    .pattern-card {
        background: linear-gradient(135deg, #1a1f3a 0%, #242942 100%);
        border-radius: 16px;
        padding: 24px;
        margin: 12px 0;
        border-left: 4px solid #4b7bec;
        box-shadow: 0 4px 8px rgba(0,0,0,0.3);
        transition: transform 0.2s ease, box-shadow 0.2s ease;
        position: relative;
    }

    .pattern-card:hover {
        transform: translateY(-2px);
        box-shadow: 0 8px 16px rgba(0,0,0,0.4);
    }

    .pattern-title {
        font-size: 18px;
        color: #ffffff;
        font-weight: 700;
        margin-bottom: 8px;
        display: flex;
        align-items: center;
        gap: 8px;
    }

    .pattern-quality {
        font-size: 14px;
        color: #ffd93d;
        background: rgba(255, 217, 61, 0.1);
        padding: 4px 12px;
        border-radius: 12px;
        display: inline-block;
        margin-bottom: 12px;
    }

    .pattern-target {
        font-size: 24px;
        font-weight: bold;
        color: #00ff88;
        margin: 12px 0;
    }

    .pattern-timeline {
        font-size: 12px;
        color: #a0a0b0;
        margin-bottom: 12px;
    }

    .pattern-explanation {
        font-size: 13px;
        color: #d0d0d0;
        line-height: 1.6;
        margin-top: 12px;
        border-top: 1px solid #2d3561;
        padding-top: 12px;
    }

    /* Live Learning Indicator */
    .learning-indicator {
        position: fixed;
        top: 20px;
        right: 20px;
        background: rgba(0,255,136,0.9);
        color: #0a0e27;
        padding: 8px 16px;
        border-radius: 20px;
        font-size: 12px;
        font-weight: 700;
        z-index: 1000;
        animation: pulse 2s infinite;
    }

    @keyframes pulse {
        0% { opacity: 1; }
        50% { opacity: 0.7; }
        100% { opacity: 1; }
    }

    /* Factor Analysis Cards */
    .factor-card {
        background: linear-gradient(135deg, #1a1f3a 0%, #242942 100%);
        border-radius: 12px;
        padding: 20px;
        margin: 10px 0;
        border-left: 4px solid #4b7bec;
        box-shadow: 0 4px 8px rgba(0,0,0,0.3);
    }

    .factor-title {
        font-size: 14px;
        color: #a0a0b0;
        text-transform: uppercase;
        letter-spacing: 1px;
        margin-bottom: 8px;
    }

    .factor-value {
        font-size: 32px;
        font-weight: bold;
        color: #ffffff;
        font-family: 'Roboto Mono', monospace;
    }

    .factor-zscore {
        font-size: 12px;
        color: #ffd93d;
        margin-top: 4px;
    }

    .factor-explanation {
        font-size: 13px;
        color: #d0d0d0;
        line-height: 1.6;
        margin-top: 12px;
        border-top: 1px solid #2d3561;
        padding-top: 12px;
    }

    /* Recommendation Badges */
    .rec-strong-buy {
        background: linear-gradient(135deg, #00ff88 0%, #00d86a 100%);
        color: #0a0e27;
        padding: 12px 32px;
        border-radius: 30px;
        font-weight: 900;
        font-size: 24px;
        display: inline-block;
        box-shadow: 0 6px 20px rgba(0,255,136,0.4);
        text-transform: uppercase;
        animation: glow 2s ease-in-out infinite alternate;
    }

    @keyframes glow {
        from { box-shadow: 0 6px 20px rgba(0,255,136,0.4); }
        to { box-shadow: 0 6px 30px rgba(0,255,136,0.8); }
    }

    .rec-buy {
        background: linear-gradient(135deg, #4b7bec 0%, #3867d6 100%);
        color: #ffffff;
        padding: 12px 32px;
        border-radius: 30px;
        font-weight: 900;
        font-size: 24px;
        display: inline-block;
        text-transform: uppercase;
    }

    .rec-hold {
        background: linear-gradient(135deg, #ffd93d 0%, #f9ca24 100%);
        color: #0a0e27;
        padding: 12px 32px;
        border-radius: 30px;
        font-weight: 900;
        font-size: 24px;
        display: inline-block;
        text-transform: uppercase;
    }

    .rec-avoid {
        background: linear-gradient(135deg, #ff4757 0%, #ff3838 100%);
        color: #ffffff;
        padding: 12px 32px;
        border-radius: 30px;
        font-weight: 900;
        font-size: 24px;
        display: inline-block;
        text-transform: uppercase;
    }

    /* Signal meters */
    .signal-meter {
        height: 16px;
        background: #2d3561;
        border-radius: 8px;
        overflow: hidden;
        margin: 12px 0;
    }

    .signal-fill {
        height: 100%;
        background: linear-gradient(90deg, #ff4757 0%, #ffd93d 50%, #00ff88 100%);
        transition: width 0.5s ease;
        border-radius: 8px;
    }

    /* Elite insight box */
    .elite-insight {
        background: rgba(75, 123, 236, 0.1);
        border-left: 4px solid #4b7bec;
        padding: 16px;
        margin: 16px 0;
        border-radius: 8px;
        font-size: 14px;
        line-height: 1.8;
    }

    .elite-insight strong {
        color: #4b7bec;
    }

    /* Warning box */
    .warning-box {
        background: rgba(255, 71, 87, 0.1);
        border-left: 4px solid #ff4757;
        padding: 16px;
        margin: 16px 0;
        border-radius: 8px;
        font-size: 14px;
    }

    /* Training progress */
    .training-progress {
        background: rgba(0,255,136,0.1);
        border: 1px solid #00ff88;
        border-radius: 8px;
        padding: 12px;
        margin: 12px 0;
        text-align: center;
    }

    .training-progress strong {
        color: #00ff88;
    }

    /* Backtest results */
    .backtest-result {
        background: rgba(255, 217, 61, 0.1);
        border: 1px solid #ffd93d;
        border-radius: 8px;
        padding: 12px;
        margin: 8px 0;
    }

    .backtest-result.success {
        background: rgba(0,255,136, 0.1);
        border-color: #00ff88;
    }

    .backtest-result.failure {
        background: rgba(255, 71, 87, 0.1);
        border-color: #ff4757;
    }

    /* Sentiment indicators */
    .sentiment-bullish {
        color: #00ff88;
        font-weight: bold;
    }

    .sentiment-bearish {
        color: #ff4757;
        font-weight: bold;
    }

    .sentiment-neutral {
        color: #ffd93d;
        font-weight: bold;
    }
</style>
""", unsafe_allow_html=True)

# ============================================================================
# LIVE LEARNING & BACKTESTING ENGINE
# ============================================================================

class LiveLearningEngine:
    """Live learning system that trains while dashboard runs"""

    def __init__(self):
        self.training_data = []
        self.backtest_results = []
        self.model_performance = {}
        self.is_training = False
        self.training_thread = None

    def log_trade_result(self, symbol: str, entry_price: float, exit_price: float,
                        entry_time: datetime, exit_time: datetime, position_size: float,
                        factors: dict, prediction: dict):
        """Log trade for backtesting and learning"""

        trade = {
            'symbol': symbol,
            'entry_price': entry_price,
            'exit_price': exit_price,
            'entry_time': entry_time.isoformat(),
            'exit_time': exit_time.isoformat(),
            'position_size': position_size,
            'pnl': (exit_price - entry_price) * position_size,
            'return_pct': (exit_price - entry_price) / entry_price,
            'factors': factors,
            'prediction': prediction,
            'timestamp': datetime.now().isoformat()
        }

        self.training_data.append(trade)

        # Save to file
        try:
            with open('/content/drive/MyDrive/QuantumAI/backend/modules/training_data.jsonl', 'a') as f:
                f.write(json.dumps(trade) + '\n')
        except:
            pass

    def start_live_training(self):
        """Start NSD training in background"""
        if not self.is_training:
            self.is_training = True
            self.training_thread = threading.Thread(target=self._training_loop)
            self.training_thread.daemon = True
            self.training_thread.start()

    def _training_loop(self):
        """Background training loop"""
        while self.is_training:
            try:
                # Load latest training data
                if os.path.exists('/content/drive/MyDrive/QuantumAI/backend/modules/training_data.jsonl'):
                    with open('/content/drive/MyDrive/QuantumAI/backend/modules/training_data.jsonl', 'r') as f:
                        lines = f.readlines()[-100:]  # Last 100 trades
                        recent_trades = [json.loads(line.strip()) for line in lines if line.strip()]

                    if len(recent_trades) >= 10:
                        # Update model weights based on performance
                        self._update_model_weights(recent_trades)

                time.sleep(300)  # Train every 5 minutes

            except Exception as e:
                time.sleep(60)  # Retry in 1 minute

    def _update_model_weights(self, recent_trades: list):
        """Update model weights using recent trade performance"""

        # Calculate factor importance based on recent performance
        factor_performance = {}

        for trade in recent_trades:
            pnl = trade.get('pnl', 0)
            factors = trade.get('factors', {})

            for factor_name, factor_data in factors.items():
                if factor_name not in factor_performance:
                    factor_performance[factor_name] = {'wins': 0, 'total': 0, 'pnl': 0}

                factor_performance[factor_name]['total'] += 1
                factor_performance[factor_name]['pnl'] += pnl

                if pnl > 0:
                    factor_performance[factor_name]['wins'] += 1

        # Update model weights
        for factor_name, perf in factor_performance.items():
            if perf['total'] > 0:
                win_rate = perf['wins'] / perf['total']
                avg_pnl = perf['pnl'] / perf['total']

                # Boost weights for factors that predict wins
                current_weight = self.model_performance.get(factor_name, 0.1)
                new_weight = current_weight * (1 + 0.1 * (win_rate - 0.5))
                new_weight = max(0.05, min(0.3, new_weight))  # Bound between 0.05-0.3

                self.model_performance[factor_name] = new_weight

        # Save updated weights
        try:
            with open('/content/drive/MyDrive/QuantumAI/backend/modules/model_weights.json', 'w') as f:
                json.dump(self.model_performance, f, indent=2)
        except:
            pass

    def get_performance_stats(self):
        """Get current performance statistics"""
        if not self.training_data:
            return {'trades': 0, 'win_rate': 0, 'total_pnl': 0, 'sharpe': 0}

        trades = self.training_data[-100:]  # Last 100 trades
        wins = sum(1 for t in trades if t.get('pnl', 0) > 0)
        total_pnl = sum(t.get('pnl', 0) for t in trades)
        returns = [t.get('return_pct', 0) for t in trades]

        win_rate = wins / len(trades) if trades else 0
        sharpe = np.mean(returns) / np.std(returns) if len(returns) > 1 and np.std(returns) > 0 else 0

        return {
            'trades': len(trades),
            'win_rate': win_rate,
            'total_pnl': total_pnl,
            'sharpe': sharpe
        }

# Initialize live learning
live_learning = LiveLearningEngine()

# ============================================================================
# LOAD ALL INSTITUTIONAL MODULES
# ============================================================================

@st.cache_resource
def load_elite_systems_v2():
    """Load all institutional-grade modules v2"""
    systems = {}
    errors = []

    # Core Data & Analysis
    try:
        from data_orchestrator import DataOrchestrator_v84
        systems['data'] = DataOrchestrator_v84()
        st.sidebar.success("‚úÖ Data Orchestrator v8.4")
    except Exception as e:
        errors.append(f"Data: {e}")
        systems['data'] = None

    try:
        import elite_forecaster as ef
        systems['forecaster'] = ef
        st.sidebar.success("‚úÖ Elite Forecaster")
    except Exception as e:
        errors.append(f"Forecaster: {e}")
        systems['forecaster'] = None

    try:
        from dark_pool_tracker import DarkPoolTracker
        systems['dark_pool'] = DarkPoolTracker()
        st.sidebar.success("‚úÖ Dark Pool Tracker")
    except Exception as e:
        errors.append(f"Dark Pool: {e}")
        systems['dark_pool'] = None

    try:
        from ENHANCED_SUB_ENSEMBLE_MASTER import EnhancedSubEnsembleMaster
        systems['master'] = EnhancedSubEnsembleMaster()
        st.sidebar.success("‚úÖ Enhanced Master")
    except Exception as e:
        errors.append(f"Master: {e}")
        systems['master'] = None

    try:
        from PATTERN_RECOGNITION_ENGINE import UnifiedPatternRecognitionEngine
        systems['patterns'] = UnifiedPatternRecognitionEngine()
        st.sidebar.success("‚úÖ Pattern Recognition (15 patterns)")
    except Exception as e:
        errors.append(f"Patterns: {e}")
        systems['patterns'] = None

    # Advanced Scanners
    try:
        from pre_gainer_scanner import PreGainerScanner
        systems['pre_gainer'] = PreGainerScanner()
        st.sidebar.success("‚úÖ Pre-Gainer Scanner")
    except Exception as e:
        systems['pre_gainer'] = None

    try:
        from opportunity_scanner import OpportunityScanner
        systems['opportunity'] = OpportunityScanner()
        st.sidebar.success("‚úÖ Opportunity Scanner")
    except Exception as e:
        systems['opportunity'] = None

    try:
        from insider_trading_tracker import InsiderTradingTracker
        systems['insider'] = InsiderTradingTracker()
        st.sidebar.success("‚úÖ Insider Tracker")
    except Exception as e:
        systems['insider'] = None

    try:
        from short_squeeze_scanner import ShortSqueezeScanner
        systems['squeeze'] = ShortSqueezeScanner()
        st.sidebar.success("‚úÖ Squeeze Scanner")
    except Exception as e:
        systems['squeeze'] = None

    try:
        from sentiment_engine import SentimentEngine
        systems['sentiment'] = SentimentEngine()
        st.sidebar.success("‚úÖ Sentiment Engine")
    except Exception as e:
        systems['sentiment'] = None

    try:
        from regime_detector import RegimeDetector
        systems['regime'] = RegimeDetector()
        st.sidebar.success("‚úÖ Regime Detector")
    except Exception as e:
        systems['regime'] = None

    try:
        from forecast_trainer import ForecastTrainer
        systems['trainer'] = ForecastTrainer()
        st.sidebar.success("‚úÖ Backtest Trainer")
    except Exception as e:
        systems['trainer'] = None

    if errors:
        for err in errors:
            st.sidebar.warning(f"‚ö†Ô∏è {err}")

    return systems

# ============================================================================
# ADVANCED PATTERN INTELLIGENCE ENGINE
# ============================================================================

class AdvancedPatternIntelligence:
    """Intellectia-style pattern intelligence with quality scoring"""

    def __init__(self):
        self.pattern_quality_model = self._load_quality_model()

    def _load_quality_model(self):
        """Load or create pattern quality scoring model"""
        try:
            # Try to load existing model
            with open('/content/drive/MyDrive/QuantumAI/backend/modules/pattern_quality_model.json', 'r') as f:
                return json.load(f)
        except:
            # Create default model
            return {
                'cup_and_handle': {'base_quality': 0.75, 'volatility_multiplier': 1.2},
                'head_and_shoulders': {'base_quality': 0.80, 'volatility_multiplier': 1.1},
                'double_bottom': {'base_quality': 0.70, 'volatility_multiplier': 1.3},
                'ascending_triangle': {'base_quality': 0.65, 'volatility_multiplier': 1.0},
                'bull_flag': {'base_quality': 0.60, 'volatility_multiplier': 1.4},
                'other': {'base_quality': 0.50, 'volatility_multiplier': 1.0}
            }

    def analyze_pattern_intelligence(self, symbol: str, df: pd.DataFrame, patterns: dict) -> dict:
        """Intellectia-style pattern analysis with quality scoring"""

        if not patterns or 'detected_patterns' not in patterns:
            return {'intelligence_score': 0, 'patterns': []}

        detected_patterns = patterns['detected_patterns']
        if not detected_patterns:
            return {'intelligence_score': 0, 'patterns': []}

        intelligence_patterns = []

        for pattern in detected_patterns:
            pattern_name = pattern.get('pattern_name', 'unknown')
            quality_score = pattern.get('quality_score', 0.5)
            direction = pattern.get('direction', 'neutral')
            completion = pattern.get('completion', False)

            # Enhanced quality scoring
            model_params = self.pattern_quality_model.get(pattern_name,
                self.pattern_quality_model['other'])

            # Volume confirmation
            volume_trend = self._calculate_volume_trend(df)
            volume_multiplier = 1.0 + (volume_trend * 0.2)

            # Volatility adjustment
            volatility = df['Close'].pct_change().std() * np.sqrt(252)
            vol_multiplier = model_params['volatility_multiplier'] * (1 + volatility * 0.5)

            # Market regime adjustment
            regime_score = self._calculate_regime_score(df)

            # Final quality score
            final_quality = min(1.0, quality_score * volume_multiplier * vol_multiplier * regime_score)

            # Target calculation
            current_price = df['Close'].iloc[-1]
            target_gain = self._calculate_pattern_target(pattern_name, current_price, final_quality)

            # Time to completion
            time_to_target = self._estimate_completion_time(pattern_name, completion, final_quality)

            intelligence_patterns.append({
                'pattern_name': pattern_name.replace('_', ' ').title(),
                'quality_score': final_quality,
                'direction': direction,
                'completion': completion,
                'target_price': current_price * (1 + target_gain),
                'target_gain': target_gain,
                'time_to_target': time_to_target,
                'confidence': final_quality * 100,
                'intelligence_factors': {
                    'volume_confirmation': volume_trend,
                    'volatility_adjustment': vol_multiplier,
                    'regime_score': regime_score
                }
            })

        # Sort by quality score
        intelligence_patterns.sort(key=lambda x: x['quality_score'], reverse=True)

        # Intelligence score (weighted average of top patterns)
        if intelligence_patterns:
            top_patterns = intelligence_patterns[:3]  # Top 3 patterns
            weights = [0.5, 0.3, 0.2]  # Weighted average
            intelligence_score = sum(p['quality_score'] * w for p, w in zip(top_patterns, weights))
        else:
            intelligence_score = 0

        return {
            'intelligence_score': intelligence_score,
            'patterns': intelligence_patterns,
            'pattern_count': len(intelligence_patterns),
            'top_pattern': intelligence_patterns[0] if intelligence_patterns else None
        }

    def _calculate_volume_trend(self, df: pd.DataFrame) -> float:
        """Calculate volume trend score (0-1)"""
        if len(df) < 20:
            return 0.5

        recent_vol = df['Volume'].tail(10).mean()
        older_vol = df['Volume'].tail(20).head(10).mean()

        if older_vol == 0:
            return 0.5

        vol_ratio = recent_vol / older_vol
        return min(1.0, max(0.0, (vol_ratio - 0.5) / 1.0))  # Normalize 0.5-1.5 to 0-1

    def _calculate_regime_score(self, df: pd.DataFrame) -> float:
        """Calculate market regime adjustment"""
        if len(df) < 50:
            return 1.0

        # Simple trend strength
        sma_50 = df['Close'].rolling(50).mean().iloc[-1]
        current = df['Close'].iloc[-1]

        if current > sma_50 * 1.05:  # Strong uptrend
            return 1.2
        elif current < sma_50 * 0.95:  # Strong downtrend
            return 0.8
        else:  # Sideways
            return 1.0

    def _calculate_pattern_target(self, pattern_name: str, current_price: float, quality: float) -> float:
        """Calculate pattern-based price target"""
        base_targets = {
            'cup_and_handle': 0.25,
            'head_and_shoulders': -0.15,
            'double_bottom': 0.20,
            'ascending_triangle': 0.18,
            'bull_flag': 0.22,
            'other': 0.15
        }

        base_target = base_targets.get(pattern_name, base_targets['other'])
        quality_multiplier = 0.5 + (quality * 0.5)  # 0.5 to 1.0

        return base_target * quality_multiplier

    def _estimate_completion_time(self, pattern_name: str, completion: bool, quality: float) -> str:
        """Estimate time to pattern completion/target"""
        if completion:
            return "COMPLETED"

        base_times = {
            'cup_and_handle': 30,
            'head_and_shoulders': 25,
            'double_bottom': 20,
            'ascending_triangle': 15,
            'bull_flag': 10,
            'other': 20
        }

        base_days = base_times.get(pattern_name, base_times['other'])
        quality_adjustment = max(0.5, quality)  # Minimum 50% of time

        days = int(base_days / quality_adjustment)

        if days <= 7:
            return f"{days} days"
        elif days <= 30:
            return f"{days} days"
        else:
            return f"{days//30} months"

# Initialize pattern intelligence
pattern_intelligence = AdvancedPatternIntelligence()

# ============================================================================
# ELITE QUANT UTILITY FUNCTIONS v2
# ============================================================================

def safe_scalar(value, default=0.0):
    """Bulletproof scalar extraction"""
    if value is None:
        return default
    if isinstance(value, (int, float)):
        return float(value)
    if hasattr(value, 'item'):
        try:
            return float(value.item())
        except:
            pass
    if hasattr(value, 'iloc'):
        try:
            return float(value.iloc[0])
        except:
            pass
    try:
        return float(value)
    except:
        return default

@st.cache_data(ttl=300)
def fetch_data(symbol: str, _systems):
    """Fetch data using DataOrchestrator (async-aware)"""
    try:
        if _systems.get('data'):
            import asyncio
            import nest_asyncio
            nest_asyncio.apply()

            try:
                loop = asyncio.get_event_loop()
            except:
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)

            df = loop.run_until_complete(_systems['data'].fetch_data(symbol, force_refresh=False))

            if df is not None and not df.empty:
                df.columns = [c.capitalize() for c in df.columns]
                if 'Date' in df.columns:
                    df['Date'] = pd.to_datetime(df['Date'])
                    df.set_index('Date', inplace=True)
                return df

        # Fallback
        import yfinance as yf
        st.info(f"Using yfinance fallback for {symbol}")
        return yf.Ticker(symbol).history(period='6mo')

    except Exception as e:
        st.warning(f"Data fetch error: {e}")
        try:
            import yfinance as yf
            return yf.Ticker(symbol).history(period='6mo')
        except:
            return None

def calculate_z_score(value, mean, std):
    """Calculate Z-score for statistical significance"""
    if std == 0:
        return 0
    return (value - mean) / std

def calculate_statistical_edge(signals: list, confidence: float) -> dict:
    """Calculate real statistical edge like Renaissance"""

    # Bayesian probability update
    prior = 0.5  # 50% base rate
    likelihood = confidence
    posterior = (likelihood * prior) / ((likelihood * prior) + ((1 - likelihood) * (1 - prior)))

    # Expected value calculation
    avg_win = 0.15  # 15% average win
    avg_loss = -0.08  # 8% average loss
    win_rate = posterior

    expected_value = (win_rate * avg_win) + ((1 - win_rate) * avg_loss)

    # Kelly Criterion for optimal position size
    win_loss_ratio = abs(avg_win / avg_loss)
    kelly = (win_rate * win_loss_ratio - (1 - win_rate)) / win_loss_ratio
    kelly_safe = max(0, min(kelly * 0.5, 0.25))  # Half Kelly, max 25%

    # Information Ratio (like Sharpe but better)
    signal_strength = len([s for s in signals if s.get('confidence', 0) > 0.65])
    total_signals = max(len(signals), 1)
    information_ratio = signal_strength / total_signals

    return {
        'bayesian_probability': posterior,
        'expected_value': expected_value,
        'kelly_position_size': kelly_safe,
        'information_ratio': information_ratio,
        'statistical_significance': 'HIGH' if posterior > 0.70 else 'MEDIUM' if posterior > 0.55 else 'LOW'
    }

def detect_market_regime(df: pd.DataFrame) -> dict:
    """Detect market regime (bull/bear/sideways) using HMM-inspired logic"""
    if df is None or len(df) < 50:
        return {'regime': 'UNKNOWN', 'confidence': 0}

    # Calculate returns
    returns = df['Close'].pct_change().dropna()

    # Trend strength (20-day SMA slope)
    sma_20 = df['Close'].rolling(20).mean()
    trend_slope = (sma_20.iloc[-1] - sma_20.iloc[-20]) / sma_20.iloc[-20] if len(sma_20) >= 20 else 0

    # Volatility (20-day)
    volatility = returns.tail(20).std()

    # Volume trend
    vol_ma = df['Volume'].rolling(20).mean()
    vol_trend = (vol_ma.iloc[-1] / vol_ma.iloc[-20] - 1) if len(vol_ma) >= 20 else 0

    # Regime detection
    if trend_slope > 0.05 and volatility < 0.03:
        regime = 'STRONG_BULL'
        confidence = 0.85
    elif trend_slope > 0.02:
        regime = 'BULL'
        confidence = 0.70
    elif trend_slope < -0.05 and volatility > 0.04:
        regime = 'STRONG_BEAR'
        confidence = 0.85
    elif trend_slope < -0.02:
        regime = 'BEAR'
        confidence = 0.70
    else:
        regime = 'SIDEWAYS'
        confidence = 0.60

    return {
        'regime': regime,
        'confidence': confidence,
        'trend_slope': trend_slope,
        'volatility': volatility,
        'volume_trend': vol_trend
    }

def get_sentiment_analysis(symbol: str, systems: dict) -> dict:
    """Get comprehensive sentiment analysis"""
    sentiment_data = {
        'overall_sentiment': 'NEUTRAL',
        'confidence': 0.5,
        'sources': {}
    }

    if systems.get('sentiment'):
        try:
            # Get news sentiment
            news_sentiment = systems['sentiment'].analyze_symbol_news(symbol)
            sentiment_data['sources']['news'] = news_sentiment

            # Get social media sentiment
            social_sentiment = systems['sentiment'].analyze_social_media(symbol)
            sentiment_data['sources']['social'] = social_sentiment

            # Aggregate sentiment
            news_score = news_sentiment.get('sentiment_score', 0)
            social_score = social_sentiment.get('sentiment_score', 0)

            overall_score = (news_score + social_score) / 2

            if overall_score > 0.2:
                sentiment_data['overall_sentiment'] = 'BULLISH'
            elif overall_score < -0.2:
                sentiment_data['overall_sentiment'] = 'BEARISH'
            else:
                sentiment_data['overall_sentiment'] = 'NEUTRAL'

            sentiment_data['confidence'] = abs(overall_score)

        except Exception as e:
            st.warning(f"Sentiment analysis error: {e}")

    return sentiment_data

def calculate_multi_factor_score_v2(symbol: str, df: pd.DataFrame, systems: dict) -> dict:
    """Calculate 10-factor quantitative score (Renaissance-style)"""

    factors = {}

    # Load learned weights
    try:
        with open('/content/drive/MyDrive/QuantumAI/backend/modules/model_weights.json', 'r') as f:
            learned_weights = json.load(f)
    except:
        learned_weights = {}

    # Factor 1: Momentum (20/50/200 day)
    if len(df) >= 200:
        sma_20 = df['Close'].rolling(20).mean().iloc[-1]
        sma_50 = df['Close'].rolling(50).mean().iloc[-1]
        sma_200 = df['Close'].rolling(200).mean().iloc[-1]
        current = df['Close'].iloc[-1]

        momentum_score = 0
        if current > sma_20 > sma_50 > sma_200:
            momentum_score = 100
        elif current > sma_20 > sma_50:
            momentum_score = 75
        elif current > sma_50:
            momentum_score = 50
        else:
            momentum_score = 25

        factors['momentum'] = {
            'score': momentum_score,
            'z_score': (current - sma_200) / df['Close'].std(),
            'signal': 'BULLISH' if momentum_score >= 75 else 'BEARISH' if momentum_score <= 25 else 'NEUTRAL',
            'weight': learned_weights.get('momentum', 0.20)
        }

    # Factor 2: Volume/Liquidity
    if len(df) >= 20:
        avg_vol_20 = df['Volume'].tail(20).mean()
        recent_vol = df['Volume'].tail(5).mean()
        vol_ratio = recent_vol / avg_vol_20 if avg_vol_20 > 0 else 1

        vol_score = 50 + (vol_ratio - 1) * 100
        vol_score = max(0, min(100, vol_score))

        factors['volume'] = {
            'score': vol_score,
            'ratio': vol_ratio,
            'signal': 'ACCUMULATION' if vol_ratio > 1.5 else 'DISTRIBUTION' if vol_ratio < 0.7 else 'NORMAL',
            'weight': learned_weights.get('volume', 0.10)
        }

    # Factor 3: Volatility (risk-adjusted)
    if len(df) >= 20:
        returns = df['Close'].pct_change().dropna()
        volatility = returns.std() * np.sqrt(252)  # Annualized
        sharpe = (returns.mean() * 252) / volatility if volatility > 0 else 0

        # Lower volatility + positive Sharpe = better
        vol_score = 50 + (sharpe * 25)
        vol_score = max(0, min(100, vol_score))

        factors['volatility'] = {
            'score': vol_score,
            'annual_vol': volatility,
            'sharpe': sharpe,
            'signal': 'STABLE' if volatility < 0.30 else 'VOLATILE',
            'weight': learned_weights.get('volatility', 0.10)
        }

    # Factor 4: Pattern Intelligence (NEW!)
    if systems.get('patterns'):
        try:
            pattern_result = systems['patterns'].detect_patterns(symbol, df)
            pattern_intelligence_result = pattern_intelligence.analyze_pattern_intelligence(symbol, df, pattern_result)

            intelligence_score = pattern_intelligence_result.get('intelligence_score', 0) * 100

            factors['patterns'] = {
                'score': intelligence_score,
                'patterns_found': pattern_intelligence_result.get('pattern_count', 0),
                'top_pattern': pattern_intelligence_result.get('top_pattern', {}),
                'signal': 'BULLISH' if intelligence_score > 60 else 'BEARISH' if intelligence_score < 40 else 'NEUTRAL',
                'weight': learned_weights.get('patterns', 0.15)
            }
        except:
            factors['patterns'] = {'score': 50, 'signal': 'NEUTRAL', 'weight': 0.15}

    # Factor 5: Forecast Confidence
    if systems.get('forecaster'):
        try:
            forecast_res = systems['forecaster'].forecast_ensemble(df, horizon=21)
            expected_return = forecast_res.get('expected_return_pct', 0)
            confidence = forecast_res.get('confidence', 0.65) * 100

            forecast_score = 50 + (expected_return * 2)
            forecast_score = max(0, min(100, forecast_score * (confidence / 100)))

            factors['forecast'] = {
                'score': forecast_score,
                'expected_return': expected_return,
                'confidence': confidence,
                'signal': 'BULLISH' if expected_return > 5 else 'BEARISH' if expected_return < -5 else 'NEUTRAL',
                'weight': learned_weights.get('forecast', 0.20)
            }
        except:
            factors['forecast'] = {'score': 50, 'signal': 'NEUTRAL', 'weight': 0.20}

    # Factor 6: Dark Pool / Institutional Flow
    if systems.get('dark_pool'):
        try:
            dp_signal = systems['dark_pool'].analyze_ticker(symbol)
            dp_confidence = dp_signal.get('confidence', 50)
            dp_direction = dp_signal.get('signal', 'NEUTRAL')

            if dp_direction == 'BUY':
                dp_score = 70 + (dp_confidence - 50) * 0.6
            elif dp_direction == 'SELL':
                dp_score = 30 - (dp_confidence - 50) * 0.6
            else:
                dp_score = 50

            factors['dark_pool'] = {
                'score': dp_score,
                'confidence': dp_confidence,
                'signal': dp_direction,
                'weight': learned_weights.get('dark_pool', 0.10)
            }
        except:
            factors['dark_pool'] = {'score': 50, 'signal': 'NEUTRAL', 'weight': 0.10}

    # Factor 7: Insider Trading
    if systems.get('insider'):
        try:
            insider_data = systems['insider'].analyze_ticker(symbol)
            insider_signal = insider_data.get('signal', 'NEUTRAL')
            insider_conf = insider_data.get('confidence', 0.50) * 100

            if insider_signal == 'STRONG_BUY':
                insider_score = 85
            elif insider_signal == 'BUY':
                insider_score = 70
            elif insider_signal == 'AVOID':
                insider_score = 30
            else:
                insider_score = 50

            factors['insider'] = {
                'score': insider_score,
                'signal': insider_signal,
                'confidence': insider_conf,
                'weight': learned_weights.get('insider', 0.10)
            }
        except:
            factors['insider'] = {'score': 50, 'signal': 'NEUTRAL', 'weight': 0.10}

    # Factor 8: Short Squeeze Potential
    if systems.get('squeeze'):
        try:
            squeeze_data = systems['squeeze'].analyze_ticker(symbol)
            squeeze_signal = squeeze_data.get('signal', 'LOW_SQUEEZE')

            if squeeze_signal == 'EXTREME_SQUEEZE':
                squeeze_score = 95
            elif squeeze_signal == 'HIGH_SQUEEZE':
                squeeze_score = 80
            elif squeeze_signal == 'MODERATE_SQUEEZE':
                squeeze_score = 65
            else:
                squeeze_score = 50

            factors['squeeze'] = {
                'score': squeeze_score,
                'signal': squeeze_signal,
                'short_float': squeeze_data.get('short_float_pct', 0),
                'weight': learned_weights.get('squeeze', 0.05)
            }
        except:
            factors['squeeze'] = {'score': 50, 'signal': 'LOW_SQUEEZE', 'weight': 0.05}

    # Factor 9: Sentiment Analysis (NEW!)
    sentiment_data = get_sentiment_analysis(symbol, systems)
    sentiment_score = 50
    if sentiment_data['overall_sentiment'] == 'BULLISH':
        sentiment_score = 70 + (sentiment_data['confidence'] * 30)
    elif sentiment_data['overall_sentiment'] == 'BEARISH':
        sentiment_score = 30 - (sentiment_data['confidence'] * 30)

    factors['sentiment'] = {
        'score': max(0, min(100, sentiment_score)),
        'overall_sentiment': sentiment_data['overall_sentiment'],
        'confidence': sentiment_data['confidence'] * 100,
        'signal': sentiment_data['overall_sentiment'],
        'weight': learned_weights.get('sentiment', 0.08)
    }

    # Factor 10: Pre-Gainer Signal (NEW!)
    if systems.get('pre_gainer'):
        try:
            pre_gainer_result = asyncio.run(systems['pre_gainer'].scan([symbol]))
            if pre_gainer_result and symbol in pre_gainer_result:
                pg_data = pre_gainer_result[symbol]
                pg_confidence = pg_data.get('confidence', 0.5) * 100

                factors['pre_gainer'] = {
                    'score': pg_confidence,
                    'confidence': pg_confidence,
                    'signal': 'BULLISH' if pg_confidence > 70 else 'NEUTRAL',
                    'weight': learned_weights.get('pre_gainer', 0.02)
                }
            else:
                factors['pre_gainer'] = {'score': 50, 'signal': 'NEUTRAL', 'weight': 0.02}
        except:
            factors['pre_gainer'] = {'score': 50, 'signal': 'NEUTRAL', 'weight': 0.02}

    # Calculate composite score (weighted average with learned weights)
    total_weight = sum(factor.get('weight', 0.1) for factor in factors.values())
    if total_weight == 0:
        total_weight = 1

    composite_score = sum(
        factor.get('score', 50) * factor.get('weight', 0.1)
        for factor in factors.values()
    ) / total_weight

    return {
        'composite_score': composite_score,
        'factors': factors,
        'total_weight': total_weight
    }

def generate_elite_ai_explanation_v2(symbol: str, quant_analysis: dict, regime: dict,
                                   pattern_intelligence_result: dict, sentiment: dict) -> str:
    """Generate DEEP institutional-grade AI explanation v2"""

    score = quant_analysis['composite_score']
    factors = quant_analysis['factors']

    explanation = f"### üß† ELITE QUANT AI ANALYSIS FOR ${symbol}\n\n"

    # Live Learning Status
    perf_stats = live_learning.get_performance_stats()
    if perf_stats['trades'] > 0:
        explanation += f"**ü§ñ LIVE LEARNING STATUS:** {perf_stats['trades']} trades logged | "
        explanation += f"Win Rate: {perf_stats['win_rate']*100:.1f}% | Sharpe: {perf_stats['sharpe']:.2f}\n\n"

    # Market Regime Context
    explanation += f"**üìä MARKET REGIME:** {regime['regime']} (Confidence: {regime['confidence']*100:.0f}%)\n"
    explanation += f"Trend Slope: {regime.get('trend_slope', 0)*100:.2f}% | Volatility: {regime.get('volatility', 0)*100:.1f}%\n\n"

    # Composite Score Interpretation
    explanation += f"**üéØ COMPOSITE QUANT SCORE: {score:.1f}/100**\n\n"

    if score >= 75:
        explanation += "üü¢ **INSTITUTIONAL BUY SIGNAL** - Multiple quantitative factors align with high statistical significance.\n\n"
    elif score >= 60:
        explanation += "üü° **MODERATE BUY SIGNAL** - Positive factors dominate but requires monitoring.\n\n"
    elif score >= 45:
        explanation += "‚ö™ **NEUTRAL** - Mixed signals, no clear statistical edge detected.\n\n"
    else:
        explanation += "üî¥ **AVOID** - Negative factors dominate, high risk of adverse movement.\n\n"

    # Pattern Intelligence (NEW!)
    if pattern_intelligence_result and pattern_intelligence_result.get('patterns'):
        explanation += "---\n\n### üé® PATTERN INTELLIGENCE (Intellectia-Style)\n\n"

        top_patterns = pattern_intelligence_result['patterns'][:3]

        for i, pattern in enumerate(top_patterns, 1):
            name = pattern['pattern_name']
            quality = pattern['quality_score'] * 100
            direction = pattern['direction']
            target_price = pattern['target_price']
            time_to_target = pattern['time_to_target']

            direction_emoji = "üü¢" if direction == "bullish" else "üî¥" if direction == "bearish" else "‚ö™"

            explanation += f"**{i}. {name}** {direction_emoji}\n"
            explanation += f"- Quality Score: {quality:.1f}/100\n"
            explanation += f"- Target Price: ${target_price:.2f}\n"
            explanation += f"- Time Horizon: {time_to_target}\n"
            explanation += f"- Confidence: {pattern['confidence']:.1f}%\n\n"

    # Sentiment Analysis (NEW!)
    explanation += "---\n\n### üì∞ SENTIMENT ANALYSIS\n\n"
    sentiment_score = sentiment['overall_sentiment']
    sentiment_conf = sentiment['confidence'] * 100

    if sentiment_score == 'BULLISH':
        explanation += f"üü¢ **BULLISH SENTIMENT** (Confidence: {sentiment_conf:.1f}%)\n"
        explanation += "- News and social media sentiment is predominantly positive.\n"
        explanation += "- This supports upward price movement in the near term.\n\n"
    elif sentiment_score == 'BEARISH':
        explanation += f"üî¥ **BEARISH SENTIMENT** (Confidence: {sentiment_conf:.1f}%)\n"
        explanation += "- News and social media sentiment is predominantly negative.\n"
        explanation += "- This suggests caution and potential downward pressure.\n\n"
    else:
        explanation += f"‚ö™ **NEUTRAL SENTIMENT** (Confidence: {sentiment_conf:.1f}%)\n"
        explanation += "- Mixed sentiment across news and social media sources.\n"
        explanation += "- No clear directional bias from sentiment analysis.\n\n"

    explanation += "---\n\n### üìä FACTOR BREAKDOWN:\n\n"

    # Top factors explanation
    sorted_factors = sorted(factors.items(), key=lambda x: x[1]['score'], reverse=True)

    for factor_name, factor_data in sorted_factors[:6]:  # Top 6 factors
        score = factor_data.get('score', 50)
        signal = factor_data.get('signal', 'NEUTRAL')
        weight = factor_data.get('weight', 0.1) * 100

        factor_display_name = factor_name.replace('_', ' ').title()

        explanation += f"**{factor_display_name} ({score:.0f}/100)** - Weight: {weight:.1f}%\n"

        # Factor-specific explanations
        if factor_name == 'momentum':
            explanation += f"- Z-Score: {factor_data.get('z_score', 0):.2f} (distance from 200-day average)\n"
        elif factor_name == 'volume':
            explanation += f"- Volume Ratio: {factor_data.get('ratio', 1):.2f}x recent vs average\n"
        elif factor_name == 'volatility':
            explanation += f"- Sharpe Ratio: {factor_data.get('sharpe', 0):.2f}\n"
        elif factor_name == 'patterns':
            explanation += f"- Patterns Found: {factor_data.get('patterns_found', 0)}\n"
        elif factor_name == 'forecast':
            explanation += f"- Expected Return: {factor_data.get('expected_return', 0):+.1f}%\n"
        elif factor_name == 'sentiment':
            explanation += f"- Overall Sentiment: {factor_data.get('overall_sentiment', 'NEUTRAL')}\n"

        explanation += f"- Signal: {signal}\n\n"

    explanation += "---\n\n"

    return explanation

# ============================================================================
# LOAD SYSTEMS
# ============================================================================

with st.spinner("üîÑ Loading elite quantitative systems v2..."):
    systems = load_elite_systems_v2()

# Start live learning
live_learning.start_live_training()

# ============================================================================
# SIDEBAR v2
# ============================================================================

st.sidebar.title("üèÜ QUANTUM AI")
st.sidebar.markdown("### Elite Quant v2")
st.sidebar.markdown("---")

# Live Learning Indicator
st.markdown("""
<div class="learning-indicator">
ü§ñ AI LEARNING ACTIVE
</div>
""", unsafe_allow_html=True)

st.sidebar.subheader("üíº Portfolio Stats")
perf_stats = live_learning.get_performance_stats()
st.sidebar.metric("Total Trades", perf_stats['trades'])
st.sidebar.metric("Win Rate", f"{perf_stats['win_rate']*100:.1f}%")
st.sidebar.metric("Total P&L", f"${perf_stats['total_pnl']:.2f}")
st.sidebar.metric("Sharpe Ratio", f"{perf_stats['sharpe']:.2f}")

st.sidebar.markdown("---")

working_count = sum(1 for v in systems.values() if v is not None)
st.sidebar.metric("Active Modules", f"{working_count}")

st.sidebar.markdown("---")
auto_refresh = st.sidebar.checkbox("Auto-refresh (60s)", value=False)

# ============================================================================
# MAIN TABS v2
# ============================================================================

tab1, tab2, tab3, tab4, tab5 = st.tabs([
    "üéØ Elite Analysis v2",
    "üé® Pattern Intelligence",
    "üìä Multi-Factor Dashboard",
    "üîç Market Scanner Pro",
    "üìà Performance & Learning"
])

# ============================================================================
# TAB 1: ELITE QUANT ANALYSIS v2
# ============================================================================

with tab1:
    st.markdown("## üéØ Elite Quantitative Analysis v2")
    st.markdown("*Institutional-grade multi-factor analysis with live learning & pattern intelligence*")

    col1, col2, col3 = st.columns([4, 1, 1])

    with col1:
        symbol = st.text_input("Enter Stock Symbol", value="NVDA", key="elite_symbol_v2").upper()
    with col2:
        analyze_btn = st.button("üöÄ ANALYZE", type="primary", use_container_width=True)
    with col3:
        if st.button("üîÑ Refresh", use_container_width=True):
            st.cache_data.clear()
            st.rerun()

    if analyze_btn or symbol:
        with st.spinner(f"üß† Running elite quant analysis v2 on {symbol}..."):

            # Fetch data
            df = fetch_data(symbol, systems)

            if df is not None and len(df) > 50:

                current_price = safe_scalar(df['Close'].iloc[-1])
                prev_price = safe_scalar(df['Close'].iloc[-2])
                change_pct = ((current_price / prev_price) - 1) * 100 if prev_price != 0 else 0

                # Detect market regime
                regime = detect_market_regime(df)

                # Calculate multi-factor score v2
                quant_analysis = calculate_multi_factor_score_v2(symbol, df, systems)
                composite_score = quant_analysis['composite_score']

                # Get pattern intelligence
                pattern_result = systems.get('patterns').detect_patterns(symbol, df) if systems.get('patterns') else {}
                pattern_intelligence_result = pattern_intelligence.analyze_pattern_intelligence(symbol, df, pattern_result)

                # Get sentiment
                sentiment = get_sentiment_analysis(symbol, systems)

                # Get all signals for statistical edge
                all_signals = []
                for factor_name, factor_data in quant_analysis['factors'].items():
                    all_signals.append({
                        'factor': factor_name,
                        'confidence': factor_data.get('score', 50) / 100
                    })

                # Calculate statistical edge
                edge = calculate_statistical_edge(all_signals, composite_score / 100)

                # Determine recommendation
                if composite_score >= 75 and edge['bayesian_probability'] > 0.70:
                    recommendation = "STRONG BUY"
                    badge_class = "rec-strong-buy"
                elif composite_score >= 60 and edge['bayesian_probability'] > 0.60:
                    recommendation = "BUY"
                    badge_class = "rec-buy"
                elif composite_score >= 45:
                    recommendation = "HOLD"
                    badge_class = "rec-hold"
                else:
                    recommendation = "AVOID"
                    badge_class = "rec-avoid"

                # ========== HERO SECTION ==========
                st.markdown("---")

                col1, col2, col3 = st.columns([1, 2, 1])

                with col1:
                    # Quant Score Card
                    st.markdown(f"""
                    <div class="quant-score-card">
                        <div class="statistical-significance">QUANT SCORE</div>
                        <div class="quant-score-number">{composite_score:.0f}</div>
                        <div class="statistical-significance">OUT OF 100</div>
                        <div class="statistical-significance" style="margin-top: 16px;">
                            {edge['statistical_significance']} SIGNIFICANCE
                        </div>
                    </div>
                    """, unsafe_allow_html=True)

                with col2:
                    # Price & Recommendation
                    st.markdown(f"### {symbol}")
                    st.markdown(f"# ${current_price:.2f}")
                    st.markdown(f"**{change_pct:+.2f}%** today")
                    st.markdown("<br>", unsafe_allow_html=True)

                    st.markdown(f"<div class='{badge_class}'>{recommendation}</div>", unsafe_allow_html=True)

                    st.markdown("<br>", unsafe_allow_html=True)

                    col_a, col_b, col_c = st.columns(3)
                    with col_a:
                        st.metric("Bayesian Prob", f"{edge['bayesian_probability']*100:.0f}%")
                    with col_b:
                        st.metric("Expected Value", f"{edge['expected_value']*100:+.1f}%")
                    with col_c:
                        st.metric("Kelly Size", f"{edge['kelly_position_size']*100:.0f}%")

                with col3:
                    # Market Context
                    st.metric("Market Regime", regime['regime'])
                    st.metric("Pattern IQ", f"{pattern_intelligence_result.get('intelligence_score', 0)*100:.0f}/100")
                    st.metric("Sentiment", sentiment['overall_sentiment'])

                st.markdown("---")

                # ========== PATTERN INTELLIGENCE ==========
                if pattern_intelligence_result.get('patterns'):
                    st.markdown("### üé® PATTERN INTELLIGENCE")

                    top_patterns = pattern_intelligence_result['patterns'][:3]

                    for pattern in top_patterns:
                        pattern_name = pattern['pattern_name']
                        quality = pattern['quality_score']
                        direction = pattern['direction']
                        target_price = pattern['target_price']
                        target_gain = pattern['target_gain'] * 100
                        time_to_target = pattern['time_to_target']
                        confidence = pattern['confidence']

                        direction_emoji = "üü¢" if direction == "bullish" else "üî¥" if direction == "bearish" else "‚ö™"

                        st.markdown(f"""
                        <div class="pattern-card">
                            <div class="pattern-title">
                                {direction_emoji} {pattern_name}
                                <span class="pattern-quality">Quality: {quality*100:.0f}%</span>
                            </div>
                            <div class="pattern-target">${target_price:.2f} (+{target_gain:.1f}%)</div>
                            <div class="pattern-timeline">Timeline: {time_to_target}</div>
                            <div class="pattern-explanation">
                                <strong>Confidence: {confidence:.1f}%</strong><br>
                                This {pattern_name.lower()} pattern shows {direction} potential with high quality execution.
                                Target represents {target_gain:.1f}% upside from current price.
                            </div>
                        </div>
                        """, unsafe_allow_html=True)

                # ========== ELITE AI EXPLANATION v2 ==========
                st.markdown("### üß† INSTITUTIONAL AI ANALYSIS v2")

                explanation = generate_elite_ai_explanation_v2(symbol, quant_analysis, regime,
                                                             pattern_intelligence_result, sentiment)
                st.markdown(explanation)

                # ========== LIVE LEARNING STATUS ==========
                if perf_stats['trades'] > 0:
                    st.markdown("### ü§ñ LIVE LEARNING STATUS")

                    col1, col2, col3, col4 = st.columns(4)

                    with col1:
                        st.metric("Trades Learned", perf_stats['trades'])
                    with col2:
                        st.metric("AI Win Rate", f"{perf_stats['win_rate']*100:.1f}%")
                    with col3:
                        st.metric("Total P&L", f"${perf_stats['total_pnl']:.2f}")
                    with col4:
                        st.metric("AI Sharpe", f"{perf_stats['sharpe']:.2f}")

                    st.markdown("""
                    <div class="training-progress">
                        <strong>ü§ñ AI LEARNING ACTIVE:</strong> System is continuously improving based on trade outcomes.
                        Each analysis helps refine factor weights for better future predictions.
                    </div>
                    """, unsafe_allow_html=True)

                # ========== TRADING RECOMMENDATION ==========
                st.markdown("### üí° ACTIONABLE TRADE SETUP")

                if recommendation in ['STRONG BUY', 'BUY']:
                    entry_price = current_price
                    target_return = edge['expected_value'] * 100
                    target_price = entry_price * (1 + edge['expected_value'])
                    stop_loss = entry_price * 0.92
                    risk_reward = abs(target_return / 8)

                    # Log potential trade for learning
                    potential_trade = {
                        'symbol': symbol,
                        'entry_price': entry_price,
                        'target_price': target_price,
                        'stop_loss': stop_loss,
                        'expected_return': target_return,
                        'factors': quant_analysis['factors'],
                        'prediction': {
                            'composite_score': composite_score,
                            'bayesian_probability': edge['bayesian_probability'],
                            'kelly_position_size': edge['kelly_position_size']
                        },
                        'timestamp': datetime.now().isoformat(),
                        'status': 'potential'
                    }

                    # Save to potential trades for monitoring
                    try:
                        with open('/content/drive/MyDrive/QuantumAI/backend/modules/potential_trades.jsonl', 'a') as f:
                            f.write(json.dumps(potential_trade) + '\n')
                    except:
                        pass

                    st.markdown(f"""
                    <div class="elite-insight">
                        <strong>‚úÖ HIGH-CONVICTION INSTITUTIONAL SETUP DETECTED</strong><br><br>

                        üìç <strong>Entry:</strong> ${entry_price:.2f} (current price)<br>
                        üéØ <strong>Target:</strong> ${target_price:.2f} (+{target_return:.1f}%)<br>
                        üõ°Ô∏è <strong>Stop Loss:</strong> ${stop_loss:.2f} (-8%)<br>
                        üìä <strong>Risk/Reward:</strong> {risk_reward:.1f}:1<br>
                        üí∞ <strong>Kelly Position Size:</strong> {edge['kelly_position_size']*100:.1f}% of portfolio<br>
                        ‚è∞ <strong>Time Horizon:</strong> 5-21 days<br>
                        <br>
                        <strong>Statistical Edge:</strong> {edge['bayesian_probability']*100:.0f}% probability of profit
                        with {edge['information_ratio']:.2f} information ratio. This setup has institutional-grade conviction
                        and will be logged for AI learning.
                    </div>
                    """, unsafe_allow_html=True)

                    # Add execute button for paper trading
                    if st.button("üìù Execute Paper Trade", type="secondary"):
                        st.success(f"‚úÖ Paper trade executed for {symbol}!")
                        # In a real system, this would execute the trade

                else:
                    st.markdown(f"""
                    <div class="warning-box">
                        <strong>‚ö†Ô∏è NO STATISTICAL EDGE DETECTED</strong><br><br>

                        Our quantitative analysis shows insufficient conviction for this trade. The composite score of
                        {composite_score:.1f}/100 and Bayesian probability of {edge['bayesian_probability']*100:.0f}%
                        do not meet institutional thresholds.

                        <br><br><strong>Recommendation:</strong> Wait for better setup with higher statistical significance.
                        The system will continue learning from market outcomes.
                    </div>
                    """, unsafe_allow_html=True)

            else:
                st.error(f"‚ùå Unable to fetch sufficient data for {symbol}")

# ============================================================================
# TAB 2: PATTERN INTELLIGENCE
# ============================================================================

with tab2:
    st.markdown("## üé® PATTERN INTELLIGENCE")
    st.markdown("*Intellectia-style pattern recognition with quality scoring and completion predictions*")

    pattern_symbol = st.text_input("Symbol for Pattern Analysis", "NVDA", key="pattern_symbol").upper()

    if st.button("üé® Analyze Patterns", type="primary"):
        df = fetch_data(pattern_symbol, systems)

        if df is not None and len(df) > 50:
            pattern_result = systems.get('patterns').detect_patterns(pattern_symbol, df) if systems.get('patterns') else {}
            intelligence = pattern_intelligence.analyze_pattern_intelligence(pattern_symbol, df, pattern_result)

            if intelligence.get('patterns'):
                st.markdown("### üìä PATTERN INTELLIGENCE SCORECARD")

                col1, col2, col3, col4 = st.columns(4)

                with col1:
                    st.metric("Intelligence Score", f"{intelligence.get('intelligence_score', 0)*100:.0f}/100")
                with col2:
                    st.metric("Patterns Found", intelligence.get('pattern_count', 0))
                with col3:
                    st.metric("Top Pattern Quality", f"{intelligence.get('top_pattern', {}).get('quality_score', 0)*100:.0f}%")
                with col4:
                    regime = detect_market_regime(df)
                    st.metric("Market Regime", regime['regime'])

                st.markdown("### üîç DETAILED PATTERN ANALYSIS")

                for pattern in intelligence['patterns']:
                    pattern_name = pattern['pattern_name']
                    quality = pattern['quality_score']
                    direction = pattern['direction']
                    completion = pattern['completion']
                    target_price = pattern['target_price']
                    target_gain = pattern['target_gain'] * 100
                    time_to_target = pattern['time_to_target']
                    confidence = pattern['confidence']

                    direction_color = "sentiment-bullish" if direction == "bullish" else "sentiment-bearish" if direction == "bearish" else "sentiment-neutral"

                    st.markdown(f"""
                    <div class="pattern-card">
                        <div class="pattern-title">
                            üìà {pattern_name}
                            <span class="pattern-quality">Quality: {quality*100:.1f}%</span>
                        </div>
                        <div class="pattern-target">${target_price:.2f} ({target_gain:+.1f}%)</div>
                        <div class="pattern-timeline">
                            Completion: {"‚úÖ" if completion else "‚è≥"} | Timeline: {time_to_target}
                        </div>
                        <div class="pattern-explanation">
                            <strong class="{direction_color}">{direction.upper()}</strong> pattern with {confidence:.1f}% confidence.
                            Quality factors include volume confirmation, volatility adjustment, and market regime alignment.
                            Target represents the pattern's measured move potential.
                        </div>
                    </div>
                    """, unsafe_allow_html=True)
            else:
                st.info("No significant patterns detected for this symbol.")

# ============================================================================
# TAB 3: MULTI-FACTOR DASHBOARD
# ============================================================================

with tab3:
    st.markdown("## üìä Multi-Factor Dashboard")
    st.markdown("*Real-time factor analysis with learned weights*")

    factor_symbol = st.text_input("Symbol", "NVDA", key="factor_symbol_v2").upper()

    if st.button("üìä Analyze Factors", type="primary"):
        df = fetch_data(factor_symbol, systems)

        if df is not None and len(df) > 50:
            quant_analysis = calculate_multi_factor_score_v2(factor_symbol, df, systems)
            factors = quant_analysis['factors']

            # Factor performance chart
            factor_names = list(factors.keys())
            factor_scores = [factors[f].get('score', 50) for f in factor_names]
            factor_weights = [factors[f].get('weight', 0.1) * 100 for f in factor_names]

            fig = go.Figure()

            fig.add_trace(go.Bar(
                x=factor_names,
                y=factor_scores,
                name='Factor Score',
                marker_color='#4b7bec',
                text=[f"{s:.0f}" for s in factor_scores],
                textposition='auto'
            ))

            fig.add_trace(go.Scatter(
                x=factor_names,
                y=factor_weights,
                name='Learned Weight (%)',
                mode='lines+markers',
                line=dict(color='#00ff88', width=3),
                marker=dict(size=10),
                yaxis='y2'
            ))

            fig.update_layout(
                title=f'Multi-Factor Analysis: {factor_symbol}',
                template='plotly_dark',
                height=500,
                yaxis=dict(title='Factor Score (0-100)', range=[0, 100]),
                yaxis2=dict(title='Weight (%)', overlaying='y', side='right', range=[0, 25]),
                showlegend=True
            )

            st.plotly_chart(fig, use_container_width=True)

            st.markdown("### üéØ FACTOR DETAILS")

            for factor_name, factor_data in factors.items():
                score = factor_data.get('score', 50)
                signal = factor_data.get('signal', 'NEUTRAL')
                weight = factor_data.get('weight', 0.1) * 100

                color = '#00ff88' if score >= 65 else '#ff4757' if score < 45 else '#ffd93d'

                st.markdown(f"""
                <div class="factor-card" style="border-left-color: {color};">
                    <div class="factor-title">{factor_name.upper().replace('_', ' ')} (Weight: {weight:.1f}%)</div>
                    <div class="factor-value">{score:.0f}/100</div>
                    <div class="factor-zscore">Signal: {signal}</div>
                    <div class="signal-meter">
                        <div class="signal-fill" style="width: {score}%;"></div>
                    </div>
                </div>
                """, unsafe_allow_html=True)

# ============================================================================
# TAB 4: MARKET SCANNER PRO
# ============================================================================

with tab4:
    st.markdown("## üîç Market Scanner Pro")
    st.markdown("*Find institutional-grade opportunities with 10-factor scoring*")

    if st.button("üîç Scan Top 50 Stocks", type="primary"):
        test_universe = [
            'AAPL', 'MSFT', 'GOOGL', 'NVDA', 'AMD', 'INTC', 'TSM', 'AVGO',
            'TSLA', 'META', 'NFLX', 'AMZN', 'CRM', 'ADBE', 'NOW', 'PLTR',
            'JPM', 'BAC', 'GS', 'V', 'MA', 'PYPL',
            'JNJ', 'UNH', 'PFE', 'ABBV', 'TMO',
            'WMT', 'HD', 'NKE', 'COST', 'MCD',
            'XOM', 'CVX', 'COP',
            'CAT', 'BA', 'GE', 'RTX',
            'COIN', 'SQ', 'SHOP', 'DKNG', 'RBLX',
            'RIVN', 'LCID', 'SOFI', 'HOOD', 'UPST'
        ]

        results = []
        progress_bar = st.progress(0)
        status_text = st.empty()

        for i, sym in enumerate(test_universe):
            status_text.text(f"Scanning {sym}... ({i+1}/{len(test_universe)})")
            progress_bar.progress((i + 1) / len(test_universe))

            try:
                df = fetch_data(sym, systems)
                if df is not None and len(df) > 50:
                    quant_analysis = calculate_multi_factor_score_v2(sym, df, systems)
                    score = quant_analysis['composite_score']

                    all_signals = []
                    for factor_data in quant_analysis['factors'].values():
                        all_signals.append({'confidence': factor_data.get('score', 50) / 100})

                    edge = calculate_statistical_edge(all_signals, score / 100)

                    results.append({
                        'Symbol': sym,
                        'Quant Score': score,
                        'Bayesian Prob': edge['bayesian_probability'] * 100,
                        'Expected Value': edge['expected_value'] * 100,
                        'Kelly Size': edge['kelly_position_size'] * 100,
                        'Info Ratio': edge['information_ratio']
                    })
            except:
                pass

        status_text.empty()
        progress_bar.empty()

        if len(results) > 0:
            results_df = pd.DataFrame(results)
            results_df = results_df.sort_values('Quant Score', ascending=False)

            st.markdown("### üèÜ Top Opportunities (By Quant Score)")

            # Display top 10
            for idx, row in results_df.head(10).iterrows():
                col1, col2, col3, col4, col5 = st.columns([1, 2, 2, 2, 1])

                with col1:
                    st.markdown(f"### {row['Symbol']}")

                with col2:
                    st.metric("Quant Score", f"{row['Quant Score']:.0f}/100")

                with col3:
                    st.metric("Bayesian Prob", f"{row['Bayesian Prob']:.0f}%")

                with col4:
                    st.metric("Expected Value", f"{row['Expected Value']:+.1f}%")

                with col5:
                    if st.button("View", key=f"view_{row['Symbol']}_pro"):
                        st.info(f"Switching to {row['Symbol']}...")

                st.markdown("---")

            # Full table
            st.markdown("### üìã Full Scan Results")
            st.dataframe(results_df, use_container_width=True)

# ============================================================================
# TAB 5: PERFORMANCE & LEARNING
# ============================================================================

with tab5:
    st.markdown("## üìà Performance & AI Learning")
    st.markdown("*Live backtesting results and AI learning progress*")

    perf_stats = live_learning.get_performance_stats()

    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("Total Trades", perf_stats['trades'])
    with col2:
        st.metric("AI Win Rate", f"{perf_stats['win_rate']*100:.1f}%")
    with col3:
        st.metric("Total P&L", f"${perf_stats['total_pnl']:.2f}")
    with col4:
        st.metric("AI Sharpe", f"{perf_stats['sharpe']:.2f}")

    # Learning progress
    if perf_stats['trades'] > 0:
        st.markdown("### ü§ñ AI LEARNING PROGRESS")

        # Show recent trades
        try:
            with open('/content/drive/MyDrive/QuantumAI/backend/modules/training_data.jsonl', 'r') as f:
                lines = f.readlines()[-10:]  # Last 10 trades
                recent_trades = [json.loads(line.strip()) for line in lines if line.strip()]

            if recent_trades:
                st.markdown("#### üìä Recent Learning Trades")

                for trade in recent_trades[-5:]:  # Show last 5
                    pnl = trade.get('pnl', 0)
                    symbol = trade.get('symbol', 'N/A')
                    return_pct = trade.get('return_pct', 0) * 100

                    result_class = "success" if pnl > 0 else "failure"

                    st.markdown(f"""
                    <div class="backtest-result {result_class}">
                        <strong>{symbol}:</strong> {return_pct:+.1f}% | P&L: ${pnl:+.2f}
                    </div>
                    """, unsafe_allow_html=True)

        except:
            st.info("No recent trades to display yet.")

    # Model weights
    try:
        with open('/content/drive/MyDrive/QuantumAI/backend/modules/model_weights.json', 'r') as f:
            weights = json.load(f)

        st.markdown("### üß† Learned Factor Weights")

        weight_items = list(weights.items())
        weight_items.sort(key=lambda x: x[1], reverse=True)

        for factor, weight in weight_items:
            st.markdown(f"- **{factor.replace('_', ' ').title()}:** {weight:.3f}")

    except:
        st.info("Model weights will appear after learning from trades.")

# Auto-refresh
if auto_refresh:
    import time
    time.sleep(60)
    st.rerun()

# Footer
st.markdown("---")
st.markdown("""
<div style='text-align: center; color: #a0a0b0;'>
    <p><strong>üèÜ Quantum AI Elite Quant v2</strong> | Pattern Intelligence | Live Learning | Target: 75-85% Win Rate</p>
    <p>Like Intellectia AI + AI Invest + Renaissance + Citadel | Institutional-grade with NSD training</p>
</div>
""", unsafe_allow_html=True)

