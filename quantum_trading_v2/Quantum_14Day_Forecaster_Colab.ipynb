{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24003ff0",
   "metadata": {},
   "source": [
    "## üîß Setup & Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2674b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if running in Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"‚úÖ Running in Google Colab\")\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "    print(\"‚ö†Ô∏è  Not in Colab - some features may not work\")\n",
    "\n",
    "# Mount Google Drive (if in Colab)\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    # Set working directory\n",
    "    import os\n",
    "    PROJECT_DIR = '/content/drive/MyDrive/quantum-forecaster'\n",
    "    os.makedirs(PROJECT_DIR, exist_ok=True)\n",
    "    os.chdir(PROJECT_DIR)\n",
    "    print(f\"üìÅ Working directory: {PROJECT_DIR}\")\n",
    "else:\n",
    "    PROJECT_DIR = './quantum-forecaster'\n",
    "\n",
    "# Check GPU availability\n",
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"‚úÖ GPU Available: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No GPU detected - training will be slower\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f831dae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q torch torchvision torchaudio\n",
    "!pip install -q yfinance pandas numpy scikit-learn matplotlib seaborn\n",
    "!pip install -q pandas-ta\n",
    "\n",
    "# Optional: Quantum computing libraries (for advanced features)\n",
    "# !pip install -q pennylane qiskit\n",
    "\n",
    "print(\"‚úÖ All packages installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4260066a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download model files from your repository\n",
    "# If you uploaded to Google Drive, copy files to working directory\n",
    "\n",
    "if IN_COLAB:\n",
    "    # Upload the three Python files:\n",
    "    # 1. quantum_forecaster_14day.py\n",
    "    # 2. feature_engineering.py\n",
    "    # 3. training_pipeline.py\n",
    "    \n",
    "    from google.colab import files\n",
    "    print(\"üì§ Upload model files (or copy from Drive)\")\n",
    "    # uploaded = files.upload()\n",
    "    \n",
    "    # Alternative: Copy from your Drive folder\n",
    "    # !cp /content/drive/MyDrive/your-folder/*.py .\n",
    "    \n",
    "print(\"‚úÖ Model files ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e97f258",
   "metadata": {},
   "source": [
    "## üìä Define Portfolio Universe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a249584a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20-ticker institutional portfolio (optimized for ML)\n",
    "PORTFOLIO = [\n",
    "    # Tier 1: Mega-Cap AI Leaders (70-76% accuracy expected)\n",
    "    'AAPL', 'MSFT', 'GOOGL', 'AMZN', 'TSLA', 'NVDA', 'META', 'AVGO',\n",
    "    \n",
    "    # Tier 2: AI/Cloud Growth (62-70% accuracy)\n",
    "    'AMD', 'MRVL', 'CRM', 'DDOG', 'PLTR', 'COIN',\n",
    "    \n",
    "    # Tier 3: Diversified Large-Cap (58-65% accuracy)\n",
    "    'JPM', 'XOM',\n",
    "    \n",
    "    # Your holdings\n",
    "    'MU', 'IONQ'\n",
    "]\n",
    "\n",
    "# For quick testing, start with smaller subset\n",
    "TEST_PORTFOLIO = ['NVDA', 'AAPL', 'MSFT', 'TSLA', 'AMD']\n",
    "\n",
    "print(f\"üìä Full Portfolio: {len(PORTFOLIO)} tickers\")\n",
    "print(f\"üß™ Test Portfolio: {len(TEST_PORTFOLIO)} tickers\")\n",
    "print(\"\\nRecommendation: Train on TEST_PORTFOLIO first (30-60 min on T4)\")\n",
    "print(\"                Then scale to full PORTFOLIO (2-3 hours)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab7bcc1",
   "metadata": {},
   "source": [
    "## üèóÔ∏è Initialize Model & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed949dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from quantum_forecaster_14day import QuantumForecastConfig, QuantumForecaster14Day\n",
    "from training_pipeline import QuantumForecasterTrainer\n",
    "from feature_engineering import QuantumFeatureEngineer\n",
    "\n",
    "# Configuration\n",
    "config = QuantumForecastConfig(\n",
    "    # Model architecture\n",
    "    d_model=256,\n",
    "    nhead=8,\n",
    "    num_encoder_layers=6,\n",
    "    num_decoder_layers=4,\n",
    "    \n",
    "    # Quantum parameters\n",
    "    n_qubits=8,\n",
    "    n_quantum_layers=4,\n",
    "    \n",
    "    # Training\n",
    "    batch_size=32,  # Reduce to 16 if GPU memory issues\n",
    "    learning_rate=1e-4,\n",
    "    num_epochs=50,  # Increase to 100 for production\n",
    "    warmup_epochs=5,\n",
    "    \n",
    "    # Forecasting\n",
    "    sequence_length=60,  # 60 days of history\n",
    "    prediction_horizon=14,  # 14-day forecast\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Configuration created\")\n",
    "print(f\"   - Model dimension: {config.d_model}\")\n",
    "print(f\"   - Quantum qubits: {config.n_qubits}\")\n",
    "print(f\"   - Prediction horizon: {config.prediction_horizon} days\")\n",
    "print(f\"   - Batch size: {config.batch_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2253e8b6",
   "metadata": {},
   "source": [
    "## üîÑ Data Preparation & Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1baa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize trainer\n",
    "trainer = QuantumForecasterTrainer(config, device='cuda')\n",
    "\n",
    "# Prepare data (choose TEST_PORTFOLIO for faster iteration)\n",
    "USE_TEST_PORTFOLIO = True  # Set to False for full training\n",
    "\n",
    "tickers = TEST_PORTFOLIO if USE_TEST_PORTFOLIO else PORTFOLIO\n",
    "\n",
    "print(f\"üîÑ Preparing data for {len(tickers)} tickers...\")\n",
    "print(\"   This may take 5-15 minutes depending on network speed\\n\")\n",
    "\n",
    "train_loader, val_loader, test_loader = trainer.prepare_data(\n",
    "    tickers=tickers,\n",
    "    test_size=0.2,\n",
    "    val_size=0.1\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Data preparation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0953c87",
   "metadata": {},
   "source": [
    "## üöÄ Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e29d8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "print(\"üöÄ Starting training...\\n\")\n",
    "print(\"‚è±Ô∏è  Estimated time:\")\n",
    "print(\"   - Test portfolio (5 tickers): 30-60 minutes on T4\")\n",
    "print(\"   - Full portfolio (20 tickers): 2-3 hours on T4\\n\")\n",
    "\n",
    "history = trainer.train(\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    num_epochs=config.num_epochs,\n",
    "    patience=15\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bdca4a",
   "metadata": {},
   "source": [
    "## üìä Evaluate Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c10e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "results = trainer.evaluate(test_loader)\n",
    "\n",
    "# Display metrics\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìà TEST SET PERFORMANCE\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nüìä Forecast Accuracy:\")\n",
    "print(f\"   - MAE (Mean Absolute Error): {results['mae']:.4f}\")\n",
    "print(f\"   - RMSE (Root Mean Squared Error): {results['rmse']:.4f}\")\n",
    "print(f\"   - Directional Accuracy: {results['directional_accuracy']:.2%}\")\n",
    "\n",
    "print(f\"\\nüìâ Uncertainty Estimation:\")\n",
    "print(f\"   - Mean Uncertainty: {results['mean_uncertainty']:.4f}\")\n",
    "\n",
    "# Target benchmarks\n",
    "print(f\"\\nüéØ Target Benchmarks:\")\n",
    "print(f\"   - Directional Accuracy: 74-82%\")\n",
    "print(f\"   - MAE: < 0.02 (2%)\")\n",
    "\n",
    "if results['directional_accuracy'] >= 0.74:\n",
    "    print(\"\\n‚úÖ EXCELLENT: Directional accuracy meets institutional target!\")\n",
    "elif results['directional_accuracy'] >= 0.65:\n",
    "    print(\"\\n‚ö†Ô∏è  GOOD: Directional accuracy is promising but below target\")\n",
    "else:\n",
    "    print(\"\\n‚ùå NEEDS IMPROVEMENT: Consider retraining with more data/epochs\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0321e33",
   "metadata": {},
   "source": [
    "## üìà Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff0c382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "trainer.plot_training_history(f'{PROJECT_DIR}/training_history.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cefea24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction vs Actual scatter plot\n",
    "import numpy as np\n",
    "\n",
    "predictions = results['predictions'][:, 0]  # First day of 14-day forecast\n",
    "targets = results['targets'][:, 0]\n",
    "uncertainties = results['uncertainties'][:, 0]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Scatter plot\n",
    "axes[0].scatter(targets, predictions, alpha=0.5, s=20)\n",
    "axes[0].plot([-0.2, 0.2], [-0.2, 0.2], 'r--', label='Perfect prediction')\n",
    "axes[0].set_xlabel('Actual 14-Day Return')\n",
    "axes[0].set_ylabel('Predicted 14-Day Return')\n",
    "axes[0].set_title('Predictions vs Actuals')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Uncertainty distribution\n",
    "axes[1].hist(uncertainties, bins=50, alpha=0.7, edgecolor='black')\n",
    "axes[1].set_xlabel('Prediction Uncertainty')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_title('Uncertainty Distribution')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{PROJECT_DIR}/predictions_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"üìä Visualizations saved to Drive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af92e5f",
   "metadata": {},
   "source": [
    "## üíæ Save Model & Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199bb838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained model\n",
    "import os\n",
    "\n",
    "model_dir = f'{PROJECT_DIR}/models/quantum_forecaster_v1'\n",
    "trainer.save_model(model_dir)\n",
    "\n",
    "# Save results\n",
    "import json\n",
    "\n",
    "results_to_save = {\n",
    "    'mae': float(results['mae']),\n",
    "    'rmse': float(results['rmse']),\n",
    "    'directional_accuracy': float(results['directional_accuracy']),\n",
    "    'mean_uncertainty': float(results['mean_uncertainty']),\n",
    "    'tickers': tickers,\n",
    "    'config': config.__dict__\n",
    "}\n",
    "\n",
    "with open(f'{model_dir}/results.json', 'w') as f:\n",
    "    json.dump(results_to_save, f, indent=2)\n",
    "\n",
    "print(f\"‚úÖ Model and results saved to: {model_dir}\")\n",
    "print(\"\\nYou can now use this model for:\")\n",
    "print(\"  1. Real-time 14-day forecasting\")\n",
    "print(\"  2. Trading strategy backtesting\")\n",
    "print(\"  3. Portfolio optimization\")\n",
    "print(\"  4. Risk management\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3d2c75",
   "metadata": {},
   "source": [
    "## üîÆ Make Predictions on New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fbe26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to forecast any ticker\n",
    "def forecast_ticker(ticker, model, scaler, config):\n",
    "    \"\"\"\n",
    "    Generate 14-day forecast for a ticker\n",
    "    \"\"\"\n",
    "    from feature_engineering import QuantumFeatureEngineer\n",
    "    import torch\n",
    "    \n",
    "    print(f\"üîÆ Forecasting {ticker} for next 14 days...\")\n",
    "    \n",
    "    # Get latest data\n",
    "    engineer = QuantumFeatureEngineer()\n",
    "    features = engineer.engineer_all_features(ticker, period='1y')\n",
    "    X_price, X_micro, X_alt, X_sent, y = engineer.prepare_model_inputs(\n",
    "        features,\n",
    "        sequence_length=config.sequence_length,\n",
    "        prediction_horizon=config.prediction_horizon\n",
    "    )\n",
    "    \n",
    "    # Use most recent sequence\n",
    "    X_price_latest = X_price[-1:]\n",
    "    X_micro_latest = X_micro[-1:]\n",
    "    X_alt_latest = X_alt[-1:]\n",
    "    X_sent_latest = X_sent[-1:]\n",
    "    \n",
    "    # Scale features\n",
    "    X_price_scaled, X_micro_scaled, X_alt_scaled, X_sent_scaled = scaler.transform(\n",
    "        X_price_latest, X_micro_latest, X_alt_latest, X_sent_latest\n",
    "    )\n",
    "    \n",
    "    # Convert to tensors\n",
    "    X_price_t = torch.FloatTensor(X_price_scaled).to(model.device)\n",
    "    X_micro_t = torch.FloatTensor(X_micro_scaled).to(model.device)\n",
    "    X_alt_t = torch.FloatTensor(X_alt_scaled).to(model.device)\n",
    "    X_sent_t = torch.FloatTensor(X_sent_scaled).to(model.device)\n",
    "    \n",
    "    # Generate forecast\n",
    "    model.model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model.model(X_price_t, X_micro_t, X_alt_t, X_sent_t)\n",
    "    \n",
    "    # Extract predictions\n",
    "    median_forecast = output['median_forecast'].cpu().numpy()[0]\n",
    "    uncertainty = output['uncertainty'].cpu().numpy()[0]\n",
    "    \n",
    "    # Get quantile predictions\n",
    "    quantiles = {}\n",
    "    for q_name, q_pred in output['quantile_predictions'].items():\n",
    "        quantiles[q_name] = q_pred.cpu().numpy()[0]\n",
    "    \n",
    "    # Current price\n",
    "    current_price = features['all_features']['Close'].iloc[-1]\n",
    "    \n",
    "    print(f\"\\nüìä 14-Day Forecast for {ticker}:\")\n",
    "    print(f\"   Current Price: ${current_price:.2f}\")\n",
    "    print(f\"   Expected Return: {median_forecast[0]*100:.2f}%\")\n",
    "    print(f\"   Uncertainty: ¬±{uncertainty[0]*100:.2f}%\")\n",
    "    print(f\"\\n   Confidence Intervals:\")\n",
    "    print(f\"   - 10th percentile: {quantiles['q10'][0]*100:+.2f}%\")\n",
    "    print(f\"   - 25th percentile: {quantiles['q25'][0]*100:+.2f}%\")\n",
    "    print(f\"   - 50th percentile (median): {quantiles['q50'][0]*100:+.2f}%\")\n",
    "    print(f\"   - 75th percentile: {quantiles['q75'][0]*100:+.2f}%\")\n",
    "    print(f\"   - 90th percentile: {quantiles['q90'][0]*100:+.2f}%\")\n",
    "    \n",
    "    # Trading signal\n",
    "    if median_forecast[0] > 0.02 and uncertainty[0] < 0.05:\n",
    "        signal = \"üü¢ STRONG BUY\"\n",
    "    elif median_forecast[0] > 0:\n",
    "        signal = \"üü° BUY\"\n",
    "    elif median_forecast[0] < -0.02 and uncertainty[0] < 0.05:\n",
    "        signal = \"üî¥ STRONG SELL\"\n",
    "    elif median_forecast[0] < 0:\n",
    "        signal = \"üü† SELL\"\n",
    "    else:\n",
    "        signal = \"‚ö™ HOLD\"\n",
    "    \n",
    "    print(f\"\\n   Trading Signal: {signal}\")\n",
    "    \n",
    "    return {\n",
    "        'ticker': ticker,\n",
    "        'current_price': current_price,\n",
    "        'median_forecast': median_forecast[0],\n",
    "        'uncertainty': uncertainty[0],\n",
    "        'quantiles': quantiles,\n",
    "        'signal': signal\n",
    "    }\n",
    "\n",
    "# Example: Forecast NVDA\n",
    "nvda_forecast = forecast_ticker('NVDA', trainer, trainer.scaler, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a5ae24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecast entire portfolio\n",
    "print(\"üîÆ Generating forecasts for entire portfolio...\\n\")\n",
    "\n",
    "portfolio_forecasts = []\n",
    "for ticker in tickers:\n",
    "    try:\n",
    "        forecast = forecast_ticker(ticker, trainer, trainer.scaler, config)\n",
    "        portfolio_forecasts.append(forecast)\n",
    "        print(\"\\n\" + \"-\"*70 + \"\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Error forecasting {ticker}: {str(e)}\\n\")\n",
    "\n",
    "# Create summary DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "summary_df = pd.DataFrame([\n",
    "    {\n",
    "        'Ticker': f['ticker'],\n",
    "        'Current Price': f['current_price'],\n",
    "        '14-Day Return': f'{f[\"median_forecast\"]*100:.2f}%',\n",
    "        'Uncertainty': f'{f[\"uncertainty\"]*100:.2f}%',\n",
    "        'Signal': f['signal']\n",
    "    }\n",
    "    for f in portfolio_forecasts\n",
    "])\n",
    "\n",
    "print(\"\\nüìä PORTFOLIO FORECAST SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(summary_df.to_string(index=False))\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Save summary\n",
    "summary_df.to_csv(f'{PROJECT_DIR}/portfolio_forecast.csv', index=False)\n",
    "print(f\"\\nüíæ Portfolio forecast saved to {PROJECT_DIR}/portfolio_forecast.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63dc4300",
   "metadata": {},
   "source": [
    "## üìö Next Steps\n",
    "\n",
    "### üéØ Production Deployment\n",
    "1. **Scale to Full Portfolio**: Train on all 20 tickers for maximum diversification\n",
    "2. **Increase Epochs**: Train for 100-200 epochs for production-grade accuracy\n",
    "3. **Hyperparameter Tuning**: Optimize d_model, nhead, quantum layers\n",
    "4. **Walk-Forward Validation**: Implement rolling window retraining\n",
    "\n",
    "### üîÑ Continuous Improvement\n",
    "1. **Alternative Data Integration**: Add real satellite/credit card data sources\n",
    "2. **Sentiment Enhancement**: Integrate Twitter/Reddit/News APIs\n",
    "3. **Ensemble Methods**: Combine multiple model variants\n",
    "4. **Regime Detection**: Add market regime classification\n",
    "\n",
    "### üí∞ Trading Integration\n",
    "1. **Alpaca API**: Connect for paper/live trading\n",
    "2. **Position Sizing**: Implement Kelly criterion\n",
    "3. **Risk Management**: Stop-loss, portfolio limits\n",
    "4. **Performance Tracking**: Sharpe, Sortino, Max Drawdown\n",
    "\n",
    "### üìñ Resources\n",
    "- **Research Papers**: Temporal Fusion Transformers, Quantum ML Finance\n",
    "- **Data Sources**: Polygon.io, IEX Cloud, Finnhub\n",
    "- **Community**: r/algotrading, Quantopian forums\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ö†Ô∏è Risk Disclaimer\n",
    "This is an educational/research implementation. Past performance does not guarantee future results. Always:\n",
    "- Start with paper trading\n",
    "- Use proper risk management\n",
    "- Never invest more than you can afford to lose\n",
    "- Consult a financial advisor before live trading\n",
    "\n",
    "---\n",
    "\n",
    "**Built with ‚ù§Ô∏è by AI Trading Research Team**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
